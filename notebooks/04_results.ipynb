{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries, methods and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kate\\AppData\\Local\\miniconda3\\envs\\master\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import datasets\n",
    "import json\n",
    "import torch\n",
    "import codecs\n",
    "import os\n",
    "from os import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from data_prepossessing import create_datasets_for_plants, get_labels\n",
    "from data_visualization import visualize_annotation, visualize_annotation_for_image\n",
    "from constants import crop_indices, weed_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # use GPU if available, otherwise use a CPU\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop indicies:  [2, 5, 6, 11, 14, 15, 18]\n",
      "Weed indicies:  [3, 4, 7, 8, 9, 10, 12, 13, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "print(\"Crop indicies: \", crop_indices)\n",
    "print(\"Weed indicies: \", weed_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['broad_bean', 'corn_spurry', 'red-root_amaranth', 'red_fingergrass', 'common_wild_oat', 'cornflower', 'corn_cockle', 'milk_thistle', 'rye_brome', 'narrow-leaved_plantain', 'small-flower_geranium']\n"
     ]
    }
   ],
   "source": [
    "crop = 'broad_bean'\n",
    "# crop = 'common_buckwheat'\n",
    "# crop = 'pea'\n",
    "# crop = 'corn'\n",
    "# crop = 'soybean'\n",
    "# crop = 'sunflower'\n",
    "# crop = 'sugar_beet'\n",
    "\n",
    "# model_type = 'multiclass'\n",
    "model_type = 'binary'\n",
    "\n",
    "model_plant_names = [crop] + weed_plants\n",
    "print(model_plant_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img_00173.png', 'img_00174.png', 'img_00175.png', 'img_00176.png', 'img_00177.png', 'img_00178.png', 'img_00672.png', 'img_00673.png', 'img_00674.png', 'img_00675.png', 'img_00676.png', 'img_00677.png', 'img_00678.png', 'img_00679.png', 'img_00680.png', 'img_00681.png', 'img_00682.png', 'img_00683.png', 'img_00684.png', 'img_00882.png', 'img_00883.png', 'img_00884.png', 'img_00885.png', 'img_00886.png', 'img_00887.png', 'img_00938.png', 'img_00980.png', 'img_00981.png', 'img_00982.png', 'img_00983.png', 'img_00984.png', 'img_00985.png', 'img_00986.png', 'img_00987.png', 'img_00988.png', 'img_00989.png', 'img_01070.png', 'img_01071.png', 'img_01072.png', 'img_01073.png', 'img_01074.png', 'img_01075.png', 'img_01076.png', 'img_01077.png', 'img_01078.png', 'img_01079.png', 'img_01219.png', 'img_01220.png', 'img_01221.png', 'img_01222.png', 'img_01223.png', 'img_01224.png', 'img_01225.png', 'img_01226.png', 'img_01227.png', 'img_01228.png', 'img_01279.png', 'img_01280.png', 'img_01281.png', 'img_01282.png', 'img_01283.png', 'img_01284.png', 'img_01285.png', 'img_01286.png', 'img_01287.png', 'img_01288.png', 'img_01455.png', 'img_01456.png', 'img_01457.png', 'img_01458.png', 'img_01459.png', 'img_01460.png', 'img_01461.png', 'img_01462.png', 'img_01463.png', 'img_01464.png', 'img_01465.png', 'img_01466.png', 'img_01467.png', 'img_01468.png', 'img_01469.png', 'img_01825.png', 'img_01826.png', 'img_01827.png', 'img_01828.png', 'img_01829.png', 'img_01830.png', 'img_01831.png', 'img_01832.png', 'img_01833.png', 'img_01834.png', 'img_01835.png', 'img_01836.png', 'img_01837.png', 'img_01928.png', 'img_01929.png', 'img_01930.png', 'img_01931.png', 'img_01932.png', 'img_01933.png', 'img_01934.png', 'img_01935.png', 'img_01936.png', 'img_01937.png', 'img_01938.png', 'img_01939.png', 'img_01940.png', 'img_01941.png', 'img_01942.png', 'img_01943.png', 'img_01944.png', 'img_01945.png', 'img_01946.png', 'img_01947.png', 'img_01948.png', 'img_01949.png', 'img_01950.png', 'img_01951.png', 'img_01952.png', 'img_01953.png', 'img_01954.png', 'img_01955.png', 'img_02099.png', 'img_02100.png', 'img_02101.png', 'img_02102.png', 'img_02103.png', 'img_02104.png', 'img_02105.png', 'img_02106.png', 'img_02107.png', 'img_02108.png', 'img_02109.png', 'img_02110.png', 'img_02111.png', 'img_02112.png', 'img_02113.png', 'img_02114.png', 'img_02115.png', 'img_02116.png', 'img_02117.png', 'img_02118.png', 'img_02119.png', 'img_02120.png', 'img_02121.png', 'img_02122.png', 'img_02123.png', 'img_02124.png', 'img_02125.png', 'img_02126.png', 'img_02127.png', 'img_02128.png', 'img_02129.png', 'img_02130.png', 'img_02131.png', 'img_02132.png', 'img_02133.png', 'img_02134.png', 'img_02135.png', 'img_02136.png', 'img_02137.png', 'img_02138.png', 'img_02139.png', 'img_02140.png', 'img_02348.png', 'img_02349.png', 'img_02350.png', 'img_02351.png', 'img_02352.png', 'img_02353.png', 'img_02354.png', 'img_02355.png', 'img_02356.png', 'img_02357.png', 'img_02358.png', 'img_02359.png', 'img_02360.png', 'img_02361.png', 'img_02362.png', 'img_02363.png', 'img_02364.png', 'img_02365.png', 'img_02366.png', 'img_02367.png', 'img_02368.png', 'img_02369.png', 'img_02370.png', 'img_02371.png', 'img_02372.png', 'img_02373.png', 'img_02374.png', 'img_02375.png', 'img_02376.png', 'img_02377.png', 'img_02378.png', 'img_02379.png', 'img_02380.png', 'img_02381.png', 'img_02382.png', 'img_02383.png', 'img_02384.png', 'img_02385.png', 'img_02543.png', 'img_02544.png', 'img_02545.png', 'img_02546.png', 'img_02547.png', 'img_02548.png', 'img_02549.png', 'img_02550.png']\n",
      "Number of plant images for plant broad_bean : 210\n",
      "['img_01790.png', 'img_01799.png', 'img_01804.png', 'img_01807.png', 'img_01796.png', 'img_01788.png', 'img_01803.png', 'img_01802.png', 'img_01806.png', 'img_01801.png', 'img_01794.png', 'img_01789.png', 'img_01793.png', 'img_01795.png', 'img_01805.png', 'img_01792.png', 'img_01797.png', 'img_01800.png', 'img_01791.png', 'img_01798.png']\n",
      "Number of plant images for plant corn_spurry : 20\n",
      "['img_01796.png', 'img_01767.png', 'img_01768.png']\n",
      "Number of plant images for plant red-root_amaranth : 3\n",
      "['img_01813.png', 'img_01812.png', 'img_01809.png', 'img_01808.png', 'img_01810.png', 'img_01811.png', 'img_01815.png', 'img_01814.png']\n",
      "Number of plant images for plant red_fingergrass : 8\n",
      "['img_00712.png', 'img_00659.png', 'img_00209.png', 'img_00657.png', 'img_00419.png', 'img_00208.png', 'img_00717.png', 'img_00424.png', 'img_00204.png', 'img_00658.png', 'img_00715.png', 'img_00206.png', 'img_00421.png', 'img_00203.png', 'img_00434.png', 'img_00713.png', 'img_00430.png', 'img_00420.png', 'img_00710.png', 'img_00716.png', 'img_00709.png', 'img_00429.png', 'img_00431.png', 'img_00435.png', 'img_00714.png']\n",
      "Number of plant images for plant common_wild_oat : 25\n",
      "['img_01259.png', 'img_00465.png', 'img_00857.png', 'img_00377.png', 'img_00076.png', 'img_01263.png', 'img_00222.png', 'img_00617.png', 'img_00612.png', 'img_01145.png', 'img_00953.png', 'img_00440.png', 'img_00907.png', 'img_00362.png', 'img_00223.png', 'img_00558.png', 'img_01262.png', 'img_00569.png', 'img_01754.png', 'img_01147.png', 'img_00375.png', 'img_00361.png', 'img_01148.png', 'img_00812.png', 'img_00450.png', 'img_00370.png', 'img_00364.png', 'img_01766.png', 'img_00855.png', 'img_00116.png', 'img_00369.png', 'img_01270.png', 'img_00121.png', 'img_00811.png', 'img_01762.png', 'img_00954.png', 'img_00608.png', 'img_00077.png', 'img_00079.png', 'img_01141.png', 'img_01049.png', 'img_00611.png', 'img_00613.png', 'img_01197.png', 'img_01140.png', 'img_00619.png', 'img_00219.png', 'img_00810.png', 'img_01142.png', 'img_00620.png', 'img_01752.png', 'img_01194.png', 'img_00454.png', 'img_00374.png', 'img_00955.png', 'img_00123.png', 'img_01196.png', 'img_01144.png', 'img_01264.png', 'img_00366.png', 'img_00118.png', 'img_00363.png', 'img_00086.png', 'img_01044.png', 'img_01198.png', 'img_01751.png', 'img_00561.png', 'img_00224.png', 'img_01042.png', 'img_01266.png', 'img_01046.png', 'img_00556.png', 'img_01190.png', 'img_00618.png', 'img_00804.png', 'img_01261.png', 'img_00457.png', 'img_01191.png', 'img_00555.png', 'img_00082.png', 'img_00448.png', 'img_00456.png', 'img_01045.png', 'img_00447.png', 'img_01767.png', 'img_00609.png', 'img_00073.png', 'img_01043.png', 'img_00856.png', 'img_00957.png', 'img_01758.png', 'img_00078.png', 'img_00371.png', 'img_00616.png', 'img_01756.png', 'img_01048.png', 'img_00225.png', 'img_01753.png', 'img_01267.png', 'img_01871.png', 'img_01260.png', 'img_00615.png', 'img_01750.png', 'img_01768.png', 'img_00959.png', 'img_00956.png', 'img_00610.png', 'img_01765.png', 'img_01757.png', 'img_00068.png', 'img_01877.png', 'img_01760.png', 'img_01271.png', 'img_00360.png', 'img_00228.png', 'img_01759.png', 'img_00365.png', 'img_00122.png', 'img_01764.png', 'img_00466.png', 'img_01146.png', 'img_00449.png', 'img_00614.png', 'img_00372.png', 'img_00726.png', 'img_00378.png', 'img_01189.png', 'img_00958.png', 'img_01755.png', 'img_01763.png', 'img_00081.png', 'img_00070.png', 'img_00936.png', 'img_00821.png', 'img_00367.png', 'img_00859.png', 'img_01047.png', 'img_01265.png', 'img_00359.png', 'img_00952.png', 'img_00075.png', 'img_00080.png', 'img_01041.png', 'img_00069.png', 'img_00368.png', 'img_01143.png', 'img_00376.png', 'img_01040.png', 'img_00452.png', 'img_00950.png', 'img_01192.png', 'img_00373.png', 'img_00729.png', 'img_01193.png', 'img_00451.png', 'img_00567.png', 'img_01195.png', 'img_01761.png', 'img_01268.png', 'img_00951.png', 'img_00858.png', 'img_01873.png']\n",
      "Number of plant images for plant cornflower : 162\n",
      "['img_01349.png', 'img_02495.png', 'img_00625.png', 'img_01000.png', 'img_00626.png', 'img_01128.png', 'img_02199.png', 'img_01600.png', 'img_01580.png', 'img_02010.png', 'img_01105.png', 'img_02204.png', 'img_01720.png', 'img_01003.png', 'img_01250.png', 'img_01635.png', 'img_01171.png', 'img_01009.png', 'img_00750.png', 'img_02190.png', 'img_01005.png', 'img_02006.png', 'img_01254.png', 'img_01646.png', 'img_00623.png', 'img_01007.png', 'img_01255.png', 'img_01641.png', 'img_02491.png', 'img_02005.png', 'img_01992.png', 'img_01002.png', 'img_01634.png', 'img_02202.png', 'img_00624.png', 'img_02003.png', 'img_01249.png', 'img_01597.png', 'img_01709.png', 'img_00631.png', 'img_01630.png', 'img_01998.png', 'img_01722.png', 'img_02494.png', 'img_01100.png', 'img_00272.png', 'img_01124.png', 'img_02011.png', 'img_01594.png', 'img_00756.png', 'img_01632.png', 'img_01129.png', 'img_00768.png', 'img_01716.png', 'img_02200.png', 'img_01103.png', 'img_01253.png', 'img_01643.png', 'img_01354.png', 'img_00627.png', 'img_00860.png', 'img_01633.png', 'img_00866.png', 'img_00639.png', 'img_02201.png', 'img_00752.png', 'img_01642.png', 'img_01645.png', 'img_01713.png', 'img_01715.png', 'img_02198.png', 'img_00262.png', 'img_00862.png', 'img_00494.png', 'img_01177.png', 'img_01256.png', 'img_01102.png', 'img_01107.png', 'img_01601.png', 'img_02007.png', 'img_01258.png', 'img_01714.png', 'img_00633.png', 'img_01996.png', 'img_01257.png', 'img_01348.png', 'img_01123.png', 'img_02192.png', 'img_01108.png', 'img_01724.png', 'img_02490.png', 'img_00918.png', 'img_00621.png', 'img_00635.png', 'img_01004.png', 'img_01121.png', 'img_01989.png', 'img_01172.png', 'img_02195.png', 'img_00263.png', 'img_01712.png', 'img_01599.png', 'img_00270.png', 'img_01101.png', 'img_00637.png', 'img_01126.png', 'img_01106.png', 'img_00861.png', 'img_01725.png', 'img_02012.png', 'img_01243.png', 'img_00632.png', 'img_01592.png', 'img_01006.png', 'img_02203.png', 'img_01994.png', 'img_00758.png', 'img_01637.png', 'img_01109.png', 'img_01644.png', 'img_01995.png', 'img_00629.png', 'img_00622.png', 'img_01251.png', 'img_00261.png', 'img_01178.png', 'img_01990.png', 'img_00630.png', 'img_01993.png', 'img_01647.png', 'img_01252.png', 'img_00503.png', 'img_00863.png', 'img_00492.png', 'img_00753.png', 'img_01596.png', 'img_00638.png', 'img_01631.png', 'img_00759.png', 'img_01999.png', 'img_01717.png', 'img_01104.png', 'img_01122.png', 'img_01710.png', 'img_01638.png', 'img_02009.png', 'img_02489.png', 'img_01595.png', 'img_01997.png', 'img_00770.png', 'img_00252.png', 'img_00755.png', 'img_01169.png', 'img_01246.png', 'img_01173.png', 'img_01629.png', 'img_01711.png', 'img_01723.png', 'img_00628.png', 'img_02197.png', 'img_00864.png', 'img_01170.png', 'img_02193.png', 'img_01648.png', 'img_01175.png', 'img_01598.png', 'img_01640.png', 'img_01719.png', 'img_01721.png', 'img_00253.png', 'img_02004.png', 'img_01008.png', 'img_01176.png', 'img_01127.png', 'img_02492.png', 'img_01636.png', 'img_00636.png', 'img_01356.png', 'img_01593.png', 'img_00493.png', 'img_01174.png', 'img_02000.png', 'img_01120.png', 'img_02191.png', 'img_02493.png', 'img_01001.png', 'img_00634.png', 'img_01639.png', 'img_02008.png', 'img_02194.png', 'img_00865.png', 'img_02002.png', 'img_02001.png', 'img_01991.png', 'img_01570.png', 'img_01718.png', 'img_01125.png', 'img_00501.png', 'img_00867.png', 'img_02196.png']\n",
      "Number of plant images for plant corn_cockle : 200\n",
      "['img_01742.png', 'img_02013.png', 'img_02024.png', 'img_02218.png', 'img_01614.png', 'img_01731.png', 'img_02026.png', 'img_02216.png', 'img_01744.png', 'img_01653.png', 'img_01737.png', 'img_01543.png', 'img_01612.png', 'img_02226.png', 'img_01743.png', 'img_01650.png', 'img_01664.png', 'img_01659.png', 'img_01682.png', 'img_01651.png', 'img_01699.png', 'img_01667.png', 'img_02019.png', 'img_02205.png', 'img_01617.png', 'img_01627.png', 'img_01665.png', 'img_01728.png', 'img_01739.png', 'img_01658.png', 'img_01606.png', 'img_02214.png', 'img_02498.png', 'img_01734.png', 'img_01655.png', 'img_01727.png', 'img_01021.png', 'img_02222.png', 'img_01619.png', 'img_01623.png', 'img_01858.png', 'img_01863.png', 'img_02017.png', 'img_01652.png', 'img_01624.png', 'img_02501.png', 'img_02213.png', 'img_01656.png', 'img_02215.png', 'img_02221.png', 'img_01662.png', 'img_02483.png', 'img_02208.png', 'img_01622.png', 'img_02502.png', 'img_01615.png', 'img_01733.png', 'img_01657.png', 'img_01736.png', 'img_02028.png', 'img_02476.png', 'img_01747.png', 'img_01745.png', 'img_01610.png', 'img_01701.png', 'img_02499.png', 'img_01654.png', 'img_01707.png', 'img_02212.png', 'img_01663.png', 'img_02016.png', 'img_02025.png', 'img_02470.png', 'img_01729.png', 'img_02022.png', 'img_01748.png', 'img_02228.png', 'img_02029.png', 'img_01730.png', 'img_01625.png', 'img_02211.png', 'img_01670.png', 'img_01740.png', 'img_02015.png', 'img_02207.png', 'img_02229.png', 'img_02497.png', 'img_01669.png', 'img_01649.png', 'img_01732.png', 'img_02454.png', 'img_02477.png', 'img_02021.png', 'img_01022.png', 'img_01689.png', 'img_02020.png', 'img_01726.png', 'img_01738.png', 'img_02488.png', 'img_01861.png', 'img_01024.png', 'img_02223.png', 'img_01735.png', 'img_01668.png', 'img_02014.png', 'img_01026.png', 'img_02220.png', 'img_01559.png', 'img_01020.png', 'img_02227.png', 'img_01602.png', 'img_01609.png', 'img_02217.png', 'img_01025.png', 'img_02496.png', 'img_02219.png', 'img_01628.png', 'img_01706.png', 'img_01741.png', 'img_02210.png', 'img_02500.png', 'img_02027.png', 'img_01608.png', 'img_01028.png', 'img_01702.png', 'img_01856.png', 'img_01746.png', 'img_01618.png', 'img_02209.png', 'img_02453.png', 'img_01616.png', 'img_01621.png', 'img_01027.png', 'img_01620.png', 'img_02224.png', 'img_01537.png', 'img_02206.png', 'img_01611.png', 'img_01613.png', 'img_01029.png', 'img_01605.png', 'img_01607.png', 'img_01603.png', 'img_01604.png', 'img_02030.png', 'img_01666.png', 'img_02018.png', 'img_01023.png', 'img_01626.png', 'img_02023.png', 'img_01749.png', 'img_01660.png', 'img_01661.png', 'img_02225.png']\n",
      "Number of plant images for plant milk_thistle : 154\n",
      "['img_01276.png', 'img_00963.png', 'img_00961.png', 'img_01054.png', 'img_01155.png', 'img_01157.png', 'img_01156.png', 'img_01154.png', 'img_01200.png', 'img_01769.png', 'img_01150.png', 'img_00967.png', 'img_01050.png', 'img_01158.png', 'img_01201.png', 'img_01275.png', 'img_01056.png', 'img_00965.png', 'img_01208.png', 'img_01773.png', 'img_01052.png', 'img_01771.png', 'img_01055.png', 'img_01152.png', 'img_00966.png', 'img_01199.png', 'img_01206.png', 'img_01269.png', 'img_01770.png', 'img_01202.png', 'img_01774.png', 'img_01153.png', 'img_00962.png', 'img_01059.png', 'img_01273.png', 'img_01776.png', 'img_01149.png', 'img_01207.png', 'img_01772.png', 'img_00960.png', 'img_01203.png', 'img_01271.png', 'img_00937.png', 'img_01277.png', 'img_00968.png', 'img_01278.png', 'img_01051.png', 'img_01777.png', 'img_01272.png', 'img_01058.png', 'img_01270.png', 'img_01775.png', 'img_01057.png', 'img_00964.png', 'img_01053.png', 'img_01151.png', 'img_01205.png', 'img_01204.png', 'img_01274.png', 'img_00969.png']\n",
      "Number of plant images for plant rye_brome : 60\n",
      "['img_01781.png', 'img_01786.png', 'img_00645.png', 'img_01783.png', 'img_00646.png', 'img_00647.png', 'img_01804.png', 'img_00649.png', 'img_00651.png', 'img_00650.png', 'img_01806.png', 'img_00648.png', 'img_00652.png', 'img_01782.png', 'img_01784.png', 'img_01779.png', 'img_00643.png', 'img_01785.png', 'img_01787.png', 'img_00644.png', 'img_01778.png', 'img_01780.png']\n",
      "Number of plant images for plant narrow-leaved_plantain : 22\n",
      "['img_00474.png', 'img_00796.png', 'img_00536.png', 'img_00144.png', 'img_00601.png', 'img_00532.png', 'img_00605.png', 'img_00745.png', 'img_00914.png', 'img_00528.png', 'img_00356.png', 'img_00346.png', 'img_00595.png', 'img_00148.png', 'img_00145.png', 'img_00354.png', 'img_00542.png', 'img_00096.png', 'img_00149.png', 'img_00351.png', 'img_00852.png', 'img_00478.png', 'img_00607.png', 'img_00479.png', 'img_00486.png', 'img_00357.png', 'img_00350.png', 'img_00737.png', 'img_00347.png', 'img_00348.png', 'img_00476.png', 'img_00742.png', 'img_00736.png', 'img_00468.png', 'img_00546.png', 'img_00482.png', 'img_00469.png', 'img_00529.png', 'img_00853.png', 'img_00547.png', 'img_00341.png', 'img_00352.png', 'img_00477.png', 'img_00850.png', 'img_00467.png', 'img_00147.png', 'img_00353.png', 'img_00480.png', 'img_00596.png', 'img_00358.png', 'img_00150.png', 'img_00342.png', 'img_00599.png', 'img_00851.png', 'img_00343.png', 'img_00355.png', 'img_00600.png', 'img_00791.png', 'img_00344.png', 'img_00854.png', 'img_00604.png', 'img_00345.png', 'img_00603.png', 'img_00146.png', 'img_00908.png', 'img_00602.png', 'img_00606.png', 'img_00598.png', 'img_00797.png', 'img_00597.png', 'img_00545.png', 'img_00349.png']\n",
      "Number of plant images for plant small-flower_geranium : 72\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = create_datasets_for_plants(model_plant_names, model_type, crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kate\\AppData\\Local\\miniconda3\\envs\\master\\Lib\\site-packages\\transformers\\models\\segformer\\image_processing_segformer.py:99: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SegformerImageProcessor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_reduce_labels\": false,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"SegformerFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_processor_type\": \"SegformerImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 512,\n",
       "    \"width\": 512\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import SegformerImageProcessor\n",
    "\n",
    "checkpoint = \"nvidia/mit-b0\"\n",
    "image_processor = SegformerImageProcessor.from_pretrained(checkpoint)\n",
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['void', 'soil', 'broad_bean', 'weeds']\n",
      "ids: [0, 1, 2, 3]\n",
      "num_labels: 4\n",
      "id2label: {0: 'void', 1: 'soil', 2: 'broad_bean', 3: 'weeds'}\n",
      "label2id: {'void': 0, 'soil': 1, 'broad_bean': 2, 'weeds': 3}\n"
     ]
    }
   ],
   "source": [
    "id2label, label2id = get_labels(crop)\n",
    "\n",
    "print('Number of classes:', len(id2label))\n",
    "print('id2label:', id2label)\n",
    "print('label2id:', label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegformerForSemanticSegmentation(\n",
       "  (segformer): SegformerModel(\n",
       "    (encoder): SegformerEncoder(\n",
       "      (patch_embeddings): ModuleList(\n",
       "        (0): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "          (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (block): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.014285714365541935)\n",
       "            (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.02857142873108387)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.04285714402794838)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (key): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (value): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.05714285746216774)\n",
       "            (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (key): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (value): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.0714285746216774)\n",
       "            (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.08571428805589676)\n",
       "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.10000000149011612)\n",
       "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): ModuleList(\n",
       "        (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decode_head): SegformerDecodeHead(\n",
       "    (linear_c): ModuleList(\n",
       "      (0): SegformerMLP(\n",
       "        (proj): Linear(in_features=32, out_features=256, bias=True)\n",
       "      )\n",
       "      (1): SegformerMLP(\n",
       "        (proj): Linear(in_features=64, out_features=256, bias=True)\n",
       "      )\n",
       "      (2): SegformerMLP(\n",
       "        (proj): Linear(in_features=160, out_features=256, bias=True)\n",
       "      )\n",
       "      (3): SegformerMLP(\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (linear_fuse): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSemanticSegmentation\n",
    "checkpoint = 'models/' + model_type + '/' + crop + '/'\n",
    "model = AutoModelForSemanticSegmentation.from_pretrained(checkpoint, id2label=id2label, label2id=label2id)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=test_ds[0][\"image\"]\n",
    "encoding = image_processor(image, return_tensors=\"pt\")\n",
    "pixel_values = encoding.pixel_values.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(pixel_values=pixel_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_logits = torch.nn.functional.interpolate(\n",
    "    logits,\n",
    "    size=image.size[::-1],\n",
    "    mode=\"bilinear\",\n",
    "    align_corners=False,\n",
    ")\n",
    "\n",
    "pred_seg = upsampled_logits.argmax(dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting following unique classes:  [1 3]\n",
      "The resolution of predicted image is  torch.Size([1144, 1600])\n",
      "which should be equal to the resolution of the original image (1144, 1600)\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting following unique classes: \", np.unique(pred_seg))\n",
    "print(\"The resolution of predicted image is \", pred_seg.shape)\n",
    "print(\"which should be equal to the resolution of the original image\", image.size[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pred_seg))\n",
    "print(type(pred_seg.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_annotation_for_image(pred_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_annotation(pred_seg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

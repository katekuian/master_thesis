{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if GPU is detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce GTX 960\n",
      "CUDA version: 11.7\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('CUDA version:', torch.version.cuda)\n",
    "    print('Memory Usage:') \n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries, methods and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/miniconda3/envs/master/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "import json\n",
    "from os import sys\n",
    "\n",
    "from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation, TrainingArguments, Trainer, EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from data_prepossessing import create_datasets_for_plants, get_labels\n",
    "from constants import seed, weed_plants, models_folder\n",
    "from config import model_type, crop\n",
    "from model_training import train_model_from_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a semantic segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_image_processor(checkpoint):\n",
    "#     image_processor = SegformerImageProcessor.from_pretrained(checkpoint)\n",
    "#     return image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_transforms(example_batch, image_processor):\n",
    "#     images = [x for x in example_batch[\"image\"]]\n",
    "#     labels = [x for x in example_batch[\"annotation\"]]\n",
    "#     inputs = image_processor(images, labels)\n",
    "#     return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(num_labels, metric, eval_pred):\n",
    "#     with torch.no_grad():\n",
    "#         logits, labels = eval_pred\n",
    "#         logits_tensor = torch.from_numpy(logits)\n",
    "#         logits_tensor = torch.nn.functional.interpolate(\n",
    "#             logits_tensor,\n",
    "#             size=labels.shape[-2:],\n",
    "#             mode=\"bilinear\",\n",
    "#             align_corners=False,\n",
    "#         ).argmax(dim=1)\n",
    "\n",
    "#         pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "#         metrics = metric.compute(\n",
    "#             predictions=pred_labels,\n",
    "#             references=labels,\n",
    "#             num_labels=num_labels,\n",
    "#             ignore_index=255,\n",
    "#             reduce_labels=False,\n",
    "#         )\n",
    "#         for key, value in metrics.items():\n",
    "#             if type(value) is np.ndarray:\n",
    "#                 metrics[key] = value.tolist()\n",
    "#         return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_training_arguments(prediction_loss_only):\n",
    "#     return TrainingArguments(\n",
    "#         output_dir=\"segformer-b0-scene-parse-150\",\n",
    "#         learning_rate=6e-5,\n",
    "#         num_train_epochs=1,\n",
    "#         per_device_train_batch_size=6,\n",
    "#         per_device_eval_batch_size=6,\n",
    "#         save_total_limit=3,\n",
    "#         evaluation_strategy=\"steps\",\n",
    "#         save_strategy=\"steps\",\n",
    "#         save_steps=30,\n",
    "#         eval_steps=30,\n",
    "#         logging_steps=1,\n",
    "#         prediction_loss_only=prediction_loss_only,\n",
    "#         remove_unused_columns=False,\n",
    "#         load_best_model_at_end=True,\n",
    "#         seed=seed,\n",
    "#     )\n",
    "\n",
    "\n",
    "# def init_training_arguments_for_training():\n",
    "#     return init_training_arguments(True)\n",
    "\n",
    "\n",
    "# def init_training_arguments_for_evaluation():\n",
    "#     return init_training_arguments(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initialize_trainer(model, training_args, num_labels, metric, train_ds, test_ds):\n",
    "#     return Trainer(\n",
    "#         model=model,\n",
    "#         args=training_args,\n",
    "#         train_dataset=train_ds,\n",
    "#         eval_dataset=test_ds,\n",
    "#         compute_metrics=lambda eval_pred: compute_metrics(num_labels, metric, eval_pred),\n",
    "#         callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model_of_type_for_crop(model_type, crop):\n",
    "#     # Define a model checkpoint to be finetuned\n",
    "#     checkpoint = \"nvidia/mit-b0\"\n",
    "\n",
    "#     # Prepare the data for the model training\n",
    "#     model_plant_names = [crop] + weed_plants\n",
    "#     train_ds, test_ds = create_datasets_for_plants(model_plant_names, model_type, crop)\n",
    "\n",
    "#     print(\"Training subset number of images: \" + str(train_ds.num_rows))\n",
    "#     print(\"Test subset number of images: \" + str(test_ds.num_rows))\n",
    "\n",
    "#     image_processor = init_image_processor(checkpoint)\n",
    "#     train_ds.set_transform(lambda example_batch: train_transforms(example_batch, image_processor))\n",
    "#     test_ds.set_transform(lambda example_batch: train_transforms(example_batch, image_processor))\n",
    "\n",
    "#     # Generate labels for the model\n",
    "#     id2label, label2id = get_labels(crop, model_type)\n",
    "#     num_classses = len(id2label)\n",
    "\n",
    "#     print('Number of classes:', num_classses)\n",
    "#     print('id2label:', id2label)\n",
    "#     print('label2id:', label2id)\n",
    "\n",
    "#     # Initialize and train model\n",
    "#     model = AutoModelForSemanticSegmentation.from_pretrained(checkpoint, id2label=id2label, label2id=label2id)\n",
    "#     training_args_for_training = init_training_arguments_for_training()\n",
    "#     metric = evaluate.load(\"mean_iou\")\n",
    "#     trainer = initialize_trainer(model, training_args_for_training, num_classses, metric, train_ds, test_ds)\n",
    "#     trainer.train()\n",
    "\n",
    "#     # Save the trained model, so that it can be used for inference later\n",
    "#     trainer.save_model(models_folder + model_type + '/' + crop)\n",
    "    \n",
    "#     # Save the log history, so that it can be used for plotting later\n",
    "#     with open(models_folder + model_type + '/' + crop + '/log_history.json', 'w') as file:\n",
    "#         log_history = trainer.state.lo0g_history\n",
    "#         json.dump(log_history, file)\n",
    "\n",
    "#     # Instantiate new trainer for evaluation that will use compute_metrics method\n",
    "#     training_args_for_evaluation = init_training_arguments_for_evaluation()\n",
    "#     eval_trainer = initialize_trainer(trainer.model, training_args_for_evaluation, num_classses, metric, train_ds, test_ds)\n",
    "#     test_metric = eval_trainer.evaluate(test_ds)\n",
    "#     with open(models_folder + model_type + '/' + crop + '/test_metric.json', 'w') as file:\n",
    "#         json.dump(test_metric, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model_from_config():\n",
    "#     train_model_of_type_for_crop(model_type, crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training subset number of images: 428\n",
      "Test subset number of images: 428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/miniconda3/envs/master/lib/python3.11/site-packages/transformers/models/segformer/image_processing_segformer.py:101: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 4\n",
      "id2label: {0: 'void', 1: 'soil', 2: 'broad_bean', 3: 'weeds'}\n",
      "label2id: {'void': 0, 'soil': 1, 'broad_bean': 2, 'weeds': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.0.proj.bias', 'decode_head.classifier.weight', 'decode_head.batch_norm.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.batch_norm.running_var', 'decode_head.linear_fuse.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 10/7200 [00:27<5:09:28,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3369, 'learning_rate': 5.991666666666667e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/7200 [00:51<4:53:09,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1535, 'learning_rate': 5.9833333333333335e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/7200 [01:15<4:46:42,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9956, 'learning_rate': 5.975e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "train_model_from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 210 images\n",
    "# train_model_of_type_for_crop(\"multiclass\", \"broad_bean\")\n",
    "# trainer = train_model_of_type_for_crop(\"binary\", \"broad_bean\")\n",
    "\n",
    "# 137 images\n",
    "# train_model_of_type_for_crop(\"multiclass\", \"common_buckwheat\")\n",
    "# train_model_of_type_for_crop(\"binary\", \"common_buckwheat\")\n",
    "\n",
    "# 207 images\n",
    "# train_model_of_type_for_crop(\"multiclass\", \"pea\")\n",
    "# train_model_of_type_for_crop(\"binary\", \"pea\")\n",
    "\n",
    "# 403 images\n",
    "# train_model_of_type_for_crop(\"multiclass\", \"corn\")\n",
    "# train_model_of_type_for_crop(\"binary\", \"corn\")\n",
    "\n",
    "# 303 images\n",
    "# train_model_of_type_for_crop(\"multiclass\", \"soybean\")\n",
    "# train_model_of_type_for_crop(\"binary\", \"soybean\")\n",
    "\n",
    "# 135 images\n",
    "# train_model_of_type_for_crop(\"multiclass\", \"sunflower\")\n",
    "# train_model_of_type_for_crop(\"binary\", \"sunflower\")\n",
    "\n",
    "# 410 images\n",
    "# train_model_of_type_for_crop(\"multiclass\", \"sugar_beet\")\n",
    "# train_model_of_type_for_crop(\"binary\", \"sugar_beet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# from typing import NoReturn\n",
    "\n",
    "# def shutdown_windows() -> NoReturn:\n",
    "#     subprocess.run([\"shutdown\", \"/s\", \"/t\", \"0\"])\n",
    "\n",
    "# shutdown_windows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce GTX 960\n",
      "CUDA version: 11.7\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('CUDA version:', torch.version.cuda)\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kate\\AppData\\Local\\miniconda3\\envs\\master\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import datasets\n",
    "import os\n",
    "import evaluate\n",
    "import torch\n",
    "import json\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 9876\n",
    "\n",
    "image_folder = './WE3DS/images/'\n",
    "annotation_folder = './WE3DS/annotations/'\n",
    "annotations_aggregated_folder = './WE3DS/annotations_aggregated/'\n",
    "# Define the paths to the images and annotations\n",
    "all_image_names = np.array(os.listdir(image_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop indicies:  [2, 5, 6, 11, 14, 15, 18]\n",
      "Weed indicies:  [3, 4, 7, 8, 9, 10, 12, 13, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "plant_classification = {\n",
    "    'void': 'void',\n",
    "    'soil': 'soil',\n",
    "    'broad bean': 'crop',\n",
    "    'corn spurry': 'weed',\n",
    "    'red-root amaranth': 'weed',\n",
    "    'common buckwheat': 'crop',\n",
    "    'pea': 'crop',\n",
    "    'red fingergrass': 'weed',\n",
    "    'common wild oat': 'weed',\n",
    "    'cornflower': 'weed',\n",
    "    'corn cockle': 'weed',\n",
    "    'corn': 'crop',\n",
    "    'milk thistle': 'weed',\n",
    "    'rye brome': 'weed',\n",
    "    'soybean': 'crop',\n",
    "    'sunflower': 'crop',\n",
    "    'narrow-leaved plantain': 'weed',\n",
    "    'small-flower geranium': 'weed',\n",
    "    'sugar beet': 'crop'\n",
    "}\n",
    "\n",
    "crop_indices = [index for index, value in enumerate(plant_classification) if plant_classification[value] == 'crop']\n",
    "weed_indices = [index for index, value in enumerate(plant_classification) if plant_classification[value] == 'weed']\n",
    "\n",
    "print(\"Crop indicies: \", crop_indices)\n",
    "print(\"Weed indicies: \", weed_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['broad_bean']\n"
     ]
    }
   ],
   "source": [
    "# This is a configuration that will determine which type of model and for which plants the following code will be executed\n",
    "# weed_plants = [plant_name.replace(\" \", \"_\") for plant_name, classification in plant_classification.items() if classification == 'weed']\n",
    "weed_plants = []\n",
    "\n",
    "crop = 'broad_bean'\n",
    "# crop = 'common_buckwheat'\n",
    "# crop = 'pea'\n",
    "# crop = 'corn'\n",
    "# crop = 'soybean'\n",
    "# crop = 'sunflower'\n",
    "# crop = 'sugar_beet'\n",
    "\n",
    "model_type = 'multiclass'\n",
    "# model_type = 'binary'\n",
    "\n",
    "model_plant_names = [crop] + weed_plants\n",
    "print(model_plant_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_meta_filepath(plant_name):\n",
    "    suffix = '_images.json'\n",
    "    if plant_name in weed_plants:\n",
    "        suffix = '_no_crop_images.json'\n",
    "    return './meta/' + plant_name + suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list_for_plant(plant_name, model_type):\n",
    "    # Create an empty list to store the dataset\n",
    "    image_list = []\n",
    "    plant_image_names = json.load(codecs.open(get_image_meta_filepath(plant_name), 'r', 'utf-8-sig'))\n",
    "\n",
    "    # Exclude images that contain more than one crop\n",
    "    image_names_to_exclude = ['img_01096.png' 'img_01098.png']\n",
    "    plant_image_names = [image_name for image_name in plant_image_names if image_name not in image_names_to_exclude]\n",
    "    print(plant_image_names)\n",
    "\n",
    "    # Iterate over the image and annotation paths\n",
    "    for image_name in plant_image_names:\n",
    "        # Load the image and annotation using PIL\n",
    "        image = Image.open(image_folder + image_name)\n",
    "        path = None\n",
    "        if model_type == 'multiclass':\n",
    "            path = 'WE3DS/annotations_multiclass/' + crop + '/' + image_name\n",
    "        elif model_type == 'binary':\n",
    "            path = 'WE3DS/annotations_binary/' + crop + '/' + image_name\n",
    "\n",
    "        annotation = Image.open(path)\n",
    "        \n",
    "        # Create a dictionary entry for the dataseta\n",
    "        entry = {'image': image, 'annotation': annotation}\n",
    "        \n",
    "        # Add the entry to the dataset\n",
    "        image_list.append(entry)\n",
    "\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_split_dataset_for_plant(plant_image_list):\n",
    "    dataset = datasets.Dataset.from_list(plant_image_list)\n",
    "    dataset = dataset.train_test_split(test_size=0.5, seed=seed)\n",
    "    train_ds = dataset[\"train\"]\n",
    "    val_ds, test_ds = dataset[\"test\"].train_test_split(test_size=0.5, seed=seed).values()\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets_for_plants(plant_names, model_type):\n",
    "    p0_image_list = get_image_list_for_plant(plant_names[0], model_type)\n",
    "    print(\"Number of plant images for plant\", plant_names[0], \":\", len(p0_image_list))\n",
    "    train_ds, val_ds, test_ds = create_and_split_dataset_for_plant(p0_image_list)\n",
    "\n",
    "    for plant_name in plant_names[1:]:\n",
    "        p_image_list = get_image_list_for_plant(plant_name, model_type)\n",
    "        print(\"Number of plant images for plant\", plant_name, \":\", len(p_image_list))\n",
    "        p_train_ds, p_val_ds, p_test_ds = create_and_split_dataset_for_plant(p_image_list)\n",
    "\n",
    "        train_ds = datasets.concatenate_datasets([train_ds, p_train_ds])\n",
    "        val_ds = datasets.concatenate_datasets([val_ds, p_val_ds])\n",
    "        test_ds = datasets.concatenate_datasets([test_ds, p_test_ds])\n",
    "\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img_00173.png', 'img_00174.png', 'img_00175.png', 'img_00176.png', 'img_00177.png', 'img_00178.png', 'img_00672.png', 'img_00673.png', 'img_00674.png', 'img_00675.png', 'img_00676.png', 'img_00677.png', 'img_00678.png', 'img_00679.png', 'img_00680.png', 'img_00681.png', 'img_00682.png', 'img_00683.png', 'img_00684.png', 'img_00882.png', 'img_00883.png', 'img_00884.png', 'img_00885.png', 'img_00886.png', 'img_00887.png', 'img_00938.png', 'img_00980.png', 'img_00981.png', 'img_00982.png', 'img_00983.png', 'img_00984.png', 'img_00985.png', 'img_00986.png', 'img_00987.png', 'img_00988.png', 'img_00989.png', 'img_01070.png', 'img_01071.png', 'img_01072.png', 'img_01073.png', 'img_01074.png', 'img_01075.png', 'img_01076.png', 'img_01077.png', 'img_01078.png', 'img_01079.png', 'img_01219.png', 'img_01220.png', 'img_01221.png', 'img_01222.png', 'img_01223.png', 'img_01224.png', 'img_01225.png', 'img_01226.png', 'img_01227.png', 'img_01228.png', 'img_01279.png', 'img_01280.png', 'img_01281.png', 'img_01282.png', 'img_01283.png', 'img_01284.png', 'img_01285.png', 'img_01286.png', 'img_01287.png', 'img_01288.png', 'img_01455.png', 'img_01456.png', 'img_01457.png', 'img_01458.png', 'img_01459.png', 'img_01460.png', 'img_01461.png', 'img_01462.png', 'img_01463.png', 'img_01464.png', 'img_01465.png', 'img_01466.png', 'img_01467.png', 'img_01468.png', 'img_01469.png', 'img_01825.png', 'img_01826.png', 'img_01827.png', 'img_01828.png', 'img_01829.png', 'img_01830.png', 'img_01831.png', 'img_01832.png', 'img_01833.png', 'img_01834.png', 'img_01835.png', 'img_01836.png', 'img_01837.png', 'img_01928.png', 'img_01929.png', 'img_01930.png', 'img_01931.png', 'img_01932.png', 'img_01933.png', 'img_01934.png', 'img_01935.png', 'img_01936.png', 'img_01937.png', 'img_01938.png', 'img_01939.png', 'img_01940.png', 'img_01941.png', 'img_01942.png', 'img_01943.png', 'img_01944.png', 'img_01945.png', 'img_01946.png', 'img_01947.png', 'img_01948.png', 'img_01949.png', 'img_01950.png', 'img_01951.png', 'img_01952.png', 'img_01953.png', 'img_01954.png', 'img_01955.png', 'img_02099.png', 'img_02100.png', 'img_02101.png', 'img_02102.png', 'img_02103.png', 'img_02104.png', 'img_02105.png', 'img_02106.png', 'img_02107.png', 'img_02108.png', 'img_02109.png', 'img_02110.png', 'img_02111.png', 'img_02112.png', 'img_02113.png', 'img_02114.png', 'img_02115.png', 'img_02116.png', 'img_02117.png', 'img_02118.png', 'img_02119.png', 'img_02120.png', 'img_02121.png', 'img_02122.png', 'img_02123.png', 'img_02124.png', 'img_02125.png', 'img_02126.png', 'img_02127.png', 'img_02128.png', 'img_02129.png', 'img_02130.png', 'img_02131.png', 'img_02132.png', 'img_02133.png', 'img_02134.png', 'img_02135.png', 'img_02136.png', 'img_02137.png', 'img_02138.png', 'img_02139.png', 'img_02140.png', 'img_02348.png', 'img_02349.png', 'img_02350.png', 'img_02351.png', 'img_02352.png', 'img_02353.png', 'img_02354.png', 'img_02355.png', 'img_02356.png', 'img_02357.png', 'img_02358.png', 'img_02359.png', 'img_02360.png', 'img_02361.png', 'img_02362.png', 'img_02363.png', 'img_02364.png', 'img_02365.png', 'img_02366.png', 'img_02367.png', 'img_02368.png', 'img_02369.png', 'img_02370.png', 'img_02371.png', 'img_02372.png', 'img_02373.png', 'img_02374.png', 'img_02375.png', 'img_02376.png', 'img_02377.png', 'img_02378.png', 'img_02379.png', 'img_02380.png', 'img_02381.png', 'img_02382.png', 'img_02383.png', 'img_02384.png', 'img_02385.png', 'img_02543.png', 'img_02544.png', 'img_02545.png', 'img_02546.png', 'img_02547.png', 'img_02548.png', 'img_02549.png', 'img_02550.png']\n",
      "Number of plant images for plant broad_bean : 210\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = create_datasets_for_plants(model_plant_names, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training subset number of images: 105\n",
      "Validation subset number of images: 52\n",
      "Test subset number of images: 53\n"
     ]
    }
   ],
   "source": [
    "print(\"Training subset number of images: \" + str(train_ds.num_rows))\n",
    "print(\"Validation subset number of images: \" + str(val_ds.num_rows))\n",
    "print(\"Test subset number of images: \" + str(test_ds.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "c:\\Users\\Kate\\AppData\\Local\\miniconda3\\envs\\master\\Lib\\site-packages\\transformers\\models\\segformer\\image_processing_segformer.py:99: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "checkpoint = \"nvidia/mit-b0\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transforms(example_batch):\n",
    "    images = [x for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"annotation\"]]\n",
    "    inputs = image_processor(images, labels)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"mean_iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['void', 'soil', 'broad_bean']\n",
      "ids: [0, 1, 2]\n",
      "num_labels: 3\n",
      "id2label: {0: 'void', 1: 'soil', 2: 'broad_bean'}\n",
      "label2id: {'void': 0, 'soil': 1, 'broad_bean': 2}\n"
     ]
    }
   ],
   "source": [
    "labels = ['void', 'soil', crop]\n",
    "\n",
    "if model_type == 'binary':\n",
    "    labels.append('weeds')\n",
    "elif model_type == 'multiclass':\n",
    "    for weed_plant in weed_plants:\n",
    "        labels.append(weed_plant)\n",
    "\n",
    "ids = list(range(0, len(labels)))\n",
    "\n",
    "id2label = dict(zip(ids, labels))\n",
    "label2id = dict(zip(labels, ids))\n",
    "\n",
    "num_labels = len(labels)\n",
    "\n",
    "print('labels:', labels)\n",
    "print('ids:', ids)\n",
    "print('num_labels:', num_labels)\n",
    "print('id2label:', id2label)\n",
    "print('label2id:', label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    with torch.no_grad():\n",
    "        logits, labels = eval_pred\n",
    "        logits_tensor = torch.from_numpy(logits)\n",
    "        logits_tensor = torch.nn.functional.interpolate(\n",
    "            logits_tensor,\n",
    "            size=labels.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        ).argmax(dim=1)\n",
    "\n",
    "        pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "        metrics = metric.compute(\n",
    "            predictions=pred_labels,\n",
    "            references=labels,\n",
    "            num_labels=num_labels,\n",
    "            ignore_index=255,\n",
    "            reduce_labels=False,\n",
    "        )\n",
    "        for key, value in metrics.items():\n",
    "            if type(value) is np.ndarray:\n",
    "                metrics[key] = value.tolist()\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.0.proj.bias', 'decode_head.batch_norm.weight', 'decode_head.batch_norm.running_var', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.classifier.bias', 'decode_head.linear_fuse.weight', 'decode_head.batch_norm.bias', 'decode_head.batch_norm.running_mean', 'decode_head.classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SegformerForSemanticSegmentation(\n",
       "  (segformer): SegformerModel(\n",
       "    (encoder): SegformerEncoder(\n",
       "      (patch_embeddings): ModuleList(\n",
       "        (0): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "          (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (block): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.014285714365541935)\n",
       "            (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.02857142873108387)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.04285714402794838)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (key): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (value): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.05714285746216774)\n",
       "            (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (key): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (value): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.0714285746216774)\n",
       "            (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.08571428805589676)\n",
       "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.10000000149011612)\n",
       "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): ModuleList(\n",
       "        (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decode_head): SegformerDecodeHead(\n",
       "    (linear_c): ModuleList(\n",
       "      (0): SegformerMLP(\n",
       "        (proj): Linear(in_features=32, out_features=256, bias=True)\n",
       "      )\n",
       "      (1): SegformerMLP(\n",
       "        (proj): Linear(in_features=64, out_features=256, bias=True)\n",
       "      )\n",
       "      (2): SegformerMLP(\n",
       "        (proj): Linear(in_features=160, out_features=256, bias=True)\n",
       "      )\n",
       "      (3): SegformerMLP(\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (linear_fuse): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSemanticSegmentation, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "model = AutoModelForSemanticSegmentation.from_pretrained(checkpoint, id2label=id2label, label2id=label2id)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try to remove eval_accumulation_steps\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"segformer-b0-scene-parse-150\",\n",
    "    learning_rate=6e-5,\n",
    "    num_train_epochs=100,\n",
    "    per_device_train_batch_size=5,\n",
    "    per_device_eval_batch_size=5,\n",
    "    save_total_limit=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=20,\n",
    "    eval_steps=20,\n",
    "    logging_steps=1,\n",
    "    eval_accumulation_steps=5,\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_trainer(train_ds, test_ds) :\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=test_ds,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_transform(train_transforms)\n",
    "val_ds.set_transform(train_transforms)\n",
    "test_ds.set_transform(train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kate\\AppData\\Local\\miniconda3\\envs\\master\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 1/2100 [00:06<3:57:42,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2701, 'learning_rate': 5.997142857142857e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2100 [00:10<2:52:56,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2204, 'learning_rate': 5.994285714285715e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2100 [00:13<2:26:40,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1782, 'learning_rate': 5.9914285714285716e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2100 [00:17<2:13:59,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1475, 'learning_rate': 5.988571428571429e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2100 [00:20<2:06:58,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1325, 'learning_rate': 5.9857142857142856e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2100 [00:23<2:03:10,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1781, 'learning_rate': 5.982857142857143e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2100 [00:26<2:01:01,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1076, 'learning_rate': 5.9800000000000003e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2100 [00:30<1:59:39,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1212, 'learning_rate': 5.977142857142857e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2100 [00:33<1:57:37,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0625, 'learning_rate': 5.9742857142857144e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2100 [00:36<1:56:24,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.101, 'learning_rate': 5.971428571428572e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2100 [00:40<1:55:35,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.114, 'learning_rate': 5.9685714285714284e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/2100 [00:43<1:55:10,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0103, 'learning_rate': 5.965714285714286e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/2100 [00:46<1:54:52,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.997, 'learning_rate': 5.962857142857143e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2100 [00:50<1:55:20,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9339, 'learning_rate': 5.96e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2100 [00:53<1:54:53,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9253, 'learning_rate': 5.957142857142857e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2100 [00:56<1:54:22,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9021, 'learning_rate': 5.9542857142857146e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2100 [00:59<1:54:37,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9424, 'learning_rate': 5.951428571428572e-05, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/2100 [01:03<1:54:37,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8931, 'learning_rate': 5.9485714285714286e-05, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2100 [01:06<1:54:48,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8871, 'learning_rate': 5.945714285714285e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2100 [01:09<1:54:37,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8524, 'learning_rate': 5.9428571428571434e-05, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  1%|          | 20/2100 [02:19<1:54:37,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0772571563720703, 'eval_mean_iou': 0.4197518151208867, 'eval_mean_accuracy': 0.6494130605636658, 'eval_overall_accuracy': 0.948817619910607, 'eval_per_category_iou': [3.407096983015622e-05, 0.947718486336521, 0.31150288805630905], 'eval_per_category_accuracy': [0.0012461059190031153, 0.9478396110241409, 0.9991534647478534], 'eval_runtime': 69.4116, 'eval_samples_per_second': 0.749, 'eval_steps_per_second': 0.158, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2100 [02:21<13:50:21, 23.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8507, 'learning_rate': 5.94e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/2100 [02:25<10:17:37, 17.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.812, 'learning_rate': 5.937142857142857e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 23/2100 [02:28<7:41:39, 13.34s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.838, 'learning_rate': 5.934285714285715e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/2100 [02:31<5:52:53, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8071, 'learning_rate': 5.9314285714285715e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 25/2100 [02:34<4:36:53,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8197, 'learning_rate': 5.928571428571429e-05, 'epoch': 1.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 26/2100 [02:37<3:43:50,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7535, 'learning_rate': 5.925714285714286e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 27/2100 [02:39<3:07:02,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7523, 'learning_rate': 5.922857142857143e-05, 'epoch': 1.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 28/2100 [02:42<2:40:53,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9478, 'learning_rate': 5.92e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 29/2100 [02:45<2:22:17,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7535, 'learning_rate': 5.917142857142857e-05, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 30/2100 [02:48<2:09:34,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7151, 'learning_rate': 5.914285714285715e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 31/2100 [02:51<2:00:29,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6585, 'learning_rate': 5.9114285714285717e-05, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 32/2100 [02:54<1:54:04,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7416, 'learning_rate': 5.9085714285714283e-05, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 33/2100 [02:57<1:49:46,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7008, 'learning_rate': 5.9057142857142864e-05, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 34/2100 [03:00<1:47:01,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6562, 'learning_rate': 5.902857142857143e-05, 'epoch': 1.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 35/2100 [03:03<1:44:32,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6443, 'learning_rate': 5.9e-05, 'epoch': 1.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 36/2100 [03:05<1:42:37,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6744, 'learning_rate': 5.897142857142857e-05, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 37/2100 [03:08<1:41:35,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.698, 'learning_rate': 5.8942857142857145e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 38/2100 [03:11<1:41:11,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6851, 'learning_rate': 5.891428571428572e-05, 'epoch': 1.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 39/2100 [03:14<1:43:30,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7036, 'learning_rate': 5.8885714285714285e-05, 'epoch': 1.86}\n"
     ]
    }
   ],
   "source": [
    "trainer = initialize_trainer(train_ds, val_ds)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.6935,\n",
       "  'learning_rate': 5.997142857142857e-05,\n",
       "  'epoch': 0.05,\n",
       "  'step': 1},\n",
       " {'loss': 0.676,\n",
       "  'learning_rate': 5.994285714285715e-05,\n",
       "  'epoch': 0.1,\n",
       "  'step': 2},\n",
       " {'loss': 0.6713,\n",
       "  'learning_rate': 5.9914285714285716e-05,\n",
       "  'epoch': 0.14,\n",
       "  'step': 3},\n",
       " {'loss': 0.6325,\n",
       "  'learning_rate': 5.988571428571429e-05,\n",
       "  'epoch': 0.19,\n",
       "  'step': 4},\n",
       " {'loss': 0.6404,\n",
       "  'learning_rate': 5.9857142857142856e-05,\n",
       "  'epoch': 0.24,\n",
       "  'step': 5},\n",
       " {'loss': 0.6362,\n",
       "  'learning_rate': 5.982857142857143e-05,\n",
       "  'epoch': 0.29,\n",
       "  'step': 6},\n",
       " {'loss': 0.5927,\n",
       "  'learning_rate': 5.9800000000000003e-05,\n",
       "  'epoch': 0.33,\n",
       "  'step': 7},\n",
       " {'loss': 0.5819,\n",
       "  'learning_rate': 5.977142857142857e-05,\n",
       "  'epoch': 0.38,\n",
       "  'step': 8},\n",
       " {'loss': 0.6365,\n",
       "  'learning_rate': 5.9742857142857144e-05,\n",
       "  'epoch': 0.43,\n",
       "  'step': 9},\n",
       " {'loss': 0.5707,\n",
       "  'learning_rate': 5.971428571428572e-05,\n",
       "  'epoch': 0.48,\n",
       "  'step': 10},\n",
       " {'loss': 0.5955,\n",
       "  'learning_rate': 5.9685714285714284e-05,\n",
       "  'epoch': 0.52,\n",
       "  'step': 11},\n",
       " {'loss': 0.5296,\n",
       "  'learning_rate': 5.965714285714286e-05,\n",
       "  'epoch': 0.57,\n",
       "  'step': 12},\n",
       " {'loss': 0.5508,\n",
       "  'learning_rate': 5.962857142857143e-05,\n",
       "  'epoch': 0.62,\n",
       "  'step': 13},\n",
       " {'loss': 0.4913, 'learning_rate': 5.96e-05, 'epoch': 0.67, 'step': 14},\n",
       " {'loss': 0.5106,\n",
       "  'learning_rate': 5.957142857142857e-05,\n",
       "  'epoch': 0.71,\n",
       "  'step': 15},\n",
       " {'loss': 0.491,\n",
       "  'learning_rate': 5.9542857142857146e-05,\n",
       "  'epoch': 0.76,\n",
       "  'step': 16},\n",
       " {'loss': 0.4402,\n",
       "  'learning_rate': 5.951428571428572e-05,\n",
       "  'epoch': 0.81,\n",
       "  'step': 17},\n",
       " {'loss': 0.4372,\n",
       "  'learning_rate': 5.9485714285714286e-05,\n",
       "  'epoch': 0.86,\n",
       "  'step': 18},\n",
       " {'loss': 0.4427,\n",
       "  'learning_rate': 5.945714285714285e-05,\n",
       "  'epoch': 0.9,\n",
       "  'step': 19},\n",
       " {'loss': 0.4039,\n",
       "  'learning_rate': 5.9428571428571434e-05,\n",
       "  'epoch': 0.95,\n",
       "  'step': 20},\n",
       " {'eval_loss': 0.63662189245224,\n",
       "  'eval_mean_iou': 0.6795294224024675,\n",
       "  'eval_mean_accuracy': 0.9831470234539732,\n",
       "  'eval_overall_accuracy': 0.9700734698549092,\n",
       "  'eval_per_category_iou': [0.9694907853272503, 0.38956805947768464],\n",
       "  'eval_per_category_accuracy': [0.9695524983968405, 0.996741548511106],\n",
       "  'eval_runtime': 79.2392,\n",
       "  'eval_samples_per_second': 0.656,\n",
       "  'eval_steps_per_second': 0.139,\n",
       "  'epoch': 0.95,\n",
       "  'step': 20},\n",
       " {'loss': 0.3884, 'learning_rate': 5.94e-05, 'epoch': 1.0, 'step': 21},\n",
       " {'loss': 0.4363,\n",
       "  'learning_rate': 5.937142857142857e-05,\n",
       "  'epoch': 1.05,\n",
       "  'step': 22},\n",
       " {'loss': 0.4968,\n",
       "  'learning_rate': 5.934285714285715e-05,\n",
       "  'epoch': 1.1,\n",
       "  'step': 23},\n",
       " {'loss': 0.4154,\n",
       "  'learning_rate': 5.9314285714285715e-05,\n",
       "  'epoch': 1.14,\n",
       "  'step': 24},\n",
       " {'loss': 0.3986,\n",
       "  'learning_rate': 5.928571428571429e-05,\n",
       "  'epoch': 1.19,\n",
       "  'step': 25},\n",
       " {'loss': 0.412,\n",
       "  'learning_rate': 5.925714285714286e-05,\n",
       "  'epoch': 1.24,\n",
       "  'step': 26},\n",
       " {'loss': 0.3972,\n",
       "  'learning_rate': 5.922857142857143e-05,\n",
       "  'epoch': 1.29,\n",
       "  'step': 27},\n",
       " {'loss': 0.4155, 'learning_rate': 5.92e-05, 'epoch': 1.33, 'step': 28},\n",
       " {'loss': 0.347,\n",
       "  'learning_rate': 5.917142857142857e-05,\n",
       "  'epoch': 1.38,\n",
       "  'step': 29},\n",
       " {'loss': 0.3346,\n",
       "  'learning_rate': 5.914285714285715e-05,\n",
       "  'epoch': 1.43,\n",
       "  'step': 30},\n",
       " {'loss': 0.3278,\n",
       "  'learning_rate': 5.9114285714285717e-05,\n",
       "  'epoch': 1.48,\n",
       "  'step': 31},\n",
       " {'loss': 0.3748,\n",
       "  'learning_rate': 5.9085714285714283e-05,\n",
       "  'epoch': 1.52,\n",
       "  'step': 32},\n",
       " {'loss': 0.373,\n",
       "  'learning_rate': 5.9057142857142864e-05,\n",
       "  'epoch': 1.57,\n",
       "  'step': 33},\n",
       " {'loss': 0.3925,\n",
       "  'learning_rate': 5.902857142857143e-05,\n",
       "  'epoch': 1.62,\n",
       "  'step': 34},\n",
       " {'loss': 0.3017, 'learning_rate': 5.9e-05, 'epoch': 1.67, 'step': 35},\n",
       " {'loss': 0.3389,\n",
       "  'learning_rate': 5.897142857142857e-05,\n",
       "  'epoch': 1.71,\n",
       "  'step': 36},\n",
       " {'loss': 0.2747,\n",
       "  'learning_rate': 5.8942857142857145e-05,\n",
       "  'epoch': 1.76,\n",
       "  'step': 37},\n",
       " {'loss': 0.3283,\n",
       "  'learning_rate': 5.891428571428572e-05,\n",
       "  'epoch': 1.81,\n",
       "  'step': 38},\n",
       " {'loss': 0.2895,\n",
       "  'learning_rate': 5.8885714285714285e-05,\n",
       "  'epoch': 1.86,\n",
       "  'step': 39},\n",
       " {'loss': 0.2815,\n",
       "  'learning_rate': 5.885714285714286e-05,\n",
       "  'epoch': 1.9,\n",
       "  'step': 40},\n",
       " {'eval_loss': 0.48622527718544006,\n",
       "  'eval_mean_iou': 0.7336882201519398,\n",
       "  'eval_mean_accuracy': 0.9842485343311962,\n",
       "  'eval_overall_accuracy': 0.980099529863361,\n",
       "  'eval_per_category_iou': [0.9797152984990913, 0.4876611418047882],\n",
       "  'eval_per_category_accuracy': [0.9799341950987339, 0.9885628735636585],\n",
       "  'eval_runtime': 80.0199,\n",
       "  'eval_samples_per_second': 0.65,\n",
       "  'eval_steps_per_second': 0.137,\n",
       "  'epoch': 1.9,\n",
       "  'step': 40},\n",
       " {'loss': 0.2944,\n",
       "  'learning_rate': 5.882857142857143e-05,\n",
       "  'epoch': 1.95,\n",
       "  'step': 41},\n",
       " {'loss': 0.3324, 'learning_rate': 5.88e-05, 'epoch': 2.0, 'step': 42},\n",
       " {'loss': 0.3047,\n",
       "  'learning_rate': 5.877142857142857e-05,\n",
       "  'epoch': 2.05,\n",
       "  'step': 43},\n",
       " {'loss': 0.3033,\n",
       "  'learning_rate': 5.874285714285715e-05,\n",
       "  'epoch': 2.1,\n",
       "  'step': 44},\n",
       " {'loss': 0.277,\n",
       "  'learning_rate': 5.8714285714285714e-05,\n",
       "  'epoch': 2.14,\n",
       "  'step': 45},\n",
       " {'loss': 0.2681,\n",
       "  'learning_rate': 5.868571428571429e-05,\n",
       "  'epoch': 2.19,\n",
       "  'step': 46},\n",
       " {'loss': 0.2596,\n",
       "  'learning_rate': 5.865714285714286e-05,\n",
       "  'epoch': 2.24,\n",
       "  'step': 47},\n",
       " {'loss': 0.2814,\n",
       "  'learning_rate': 5.862857142857143e-05,\n",
       "  'epoch': 2.29,\n",
       "  'step': 48},\n",
       " {'loss': 0.2957, 'learning_rate': 5.86e-05, 'epoch': 2.33, 'step': 49},\n",
       " {'loss': 0.2586,\n",
       "  'learning_rate': 5.857142857142857e-05,\n",
       "  'epoch': 2.38,\n",
       "  'step': 50},\n",
       " {'loss': 0.2457,\n",
       "  'learning_rate': 5.854285714285715e-05,\n",
       "  'epoch': 2.43,\n",
       "  'step': 51},\n",
       " {'loss': 0.2757,\n",
       "  'learning_rate': 5.8514285714285716e-05,\n",
       "  'epoch': 2.48,\n",
       "  'step': 52},\n",
       " {'loss': 0.3241,\n",
       "  'learning_rate': 5.848571428571428e-05,\n",
       "  'epoch': 2.52,\n",
       "  'step': 53},\n",
       " {'loss': 0.2525,\n",
       "  'learning_rate': 5.845714285714286e-05,\n",
       "  'epoch': 2.57,\n",
       "  'step': 54},\n",
       " {'loss': 0.263,\n",
       "  'learning_rate': 5.842857142857143e-05,\n",
       "  'epoch': 2.62,\n",
       "  'step': 55},\n",
       " {'loss': 0.249, 'learning_rate': 5.84e-05, 'epoch': 2.67, 'step': 56},\n",
       " {'loss': 0.23,\n",
       "  'learning_rate': 5.837142857142857e-05,\n",
       "  'epoch': 2.71,\n",
       "  'step': 57},\n",
       " {'loss': 0.2345,\n",
       "  'learning_rate': 5.8342857142857144e-05,\n",
       "  'epoch': 2.76,\n",
       "  'step': 58},\n",
       " {'loss': 0.2274,\n",
       "  'learning_rate': 5.831428571428572e-05,\n",
       "  'epoch': 2.81,\n",
       "  'step': 59},\n",
       " {'loss': 0.2434,\n",
       "  'learning_rate': 5.8285714285714284e-05,\n",
       "  'epoch': 2.86,\n",
       "  'step': 60},\n",
       " {'eval_loss': 0.21358658373355865,\n",
       "  'eval_mean_iou': 0.8495180171479861,\n",
       "  'eval_mean_accuracy': 0.9687688822607952,\n",
       "  'eval_overall_accuracy': 0.9924915334319387,\n",
       "  'eval_per_category_iou': [0.9923532029559954, 0.7066828313399769],\n",
       "  'eval_per_category_accuracy': [0.9934368635654971, 0.9441009009560932],\n",
       "  'eval_runtime': 78.1121,\n",
       "  'eval_samples_per_second': 0.666,\n",
       "  'eval_steps_per_second': 0.141,\n",
       "  'epoch': 2.86,\n",
       "  'step': 60},\n",
       " {'loss': 0.2543,\n",
       "  'learning_rate': 5.825714285714286e-05,\n",
       "  'epoch': 2.9,\n",
       "  'step': 61},\n",
       " {'loss': 0.2326,\n",
       "  'learning_rate': 5.822857142857143e-05,\n",
       "  'epoch': 2.95,\n",
       "  'step': 62},\n",
       " {'loss': 0.2081, 'learning_rate': 5.82e-05, 'epoch': 3.0, 'step': 63},\n",
       " {'loss': 0.241,\n",
       "  'learning_rate': 5.817142857142857e-05,\n",
       "  'epoch': 3.05,\n",
       "  'step': 64},\n",
       " {'loss': 0.2205,\n",
       "  'learning_rate': 5.8142857142857146e-05,\n",
       "  'epoch': 3.1,\n",
       "  'step': 65},\n",
       " {'loss': 0.1992,\n",
       "  'learning_rate': 5.811428571428571e-05,\n",
       "  'epoch': 3.14,\n",
       "  'step': 66},\n",
       " {'loss': 0.2024,\n",
       "  'learning_rate': 5.8085714285714286e-05,\n",
       "  'epoch': 3.19,\n",
       "  'step': 67},\n",
       " {'loss': 0.2006,\n",
       "  'learning_rate': 5.805714285714286e-05,\n",
       "  'epoch': 3.24,\n",
       "  'step': 68},\n",
       " {'loss': 0.2426,\n",
       "  'learning_rate': 5.8028571428571433e-05,\n",
       "  'epoch': 3.29,\n",
       "  'step': 69},\n",
       " {'loss': 0.2081, 'learning_rate': 5.8e-05, 'epoch': 3.33, 'step': 70},\n",
       " {'loss': 0.2236,\n",
       "  'learning_rate': 5.7971428571428574e-05,\n",
       "  'epoch': 3.38,\n",
       "  'step': 71},\n",
       " {'loss': 0.1782,\n",
       "  'learning_rate': 5.794285714285715e-05,\n",
       "  'epoch': 3.43,\n",
       "  'step': 72},\n",
       " {'loss': 0.2061,\n",
       "  'learning_rate': 5.7914285714285714e-05,\n",
       "  'epoch': 3.48,\n",
       "  'step': 73},\n",
       " {'loss': 0.1957,\n",
       "  'learning_rate': 5.788571428571428e-05,\n",
       "  'epoch': 3.52,\n",
       "  'step': 74},\n",
       " {'loss': 0.2013,\n",
       "  'learning_rate': 5.785714285714286e-05,\n",
       "  'epoch': 3.57,\n",
       "  'step': 75},\n",
       " {'loss': 0.2286,\n",
       "  'learning_rate': 5.782857142857143e-05,\n",
       "  'epoch': 3.62,\n",
       "  'step': 76},\n",
       " {'loss': 0.1933, 'learning_rate': 5.78e-05, 'epoch': 3.67, 'step': 77},\n",
       " {'loss': 0.1939,\n",
       "  'learning_rate': 5.7771428571428576e-05,\n",
       "  'epoch': 3.71,\n",
       "  'step': 78},\n",
       " {'loss': 0.2126,\n",
       "  'learning_rate': 5.774285714285714e-05,\n",
       "  'epoch': 3.76,\n",
       "  'step': 79},\n",
       " {'loss': 0.2078,\n",
       "  'learning_rate': 5.7714285714285716e-05,\n",
       "  'epoch': 3.81,\n",
       "  'step': 80},\n",
       " {'eval_loss': 0.269015371799469,\n",
       "  'eval_mean_iou': 0.8561760316445595,\n",
       "  'eval_mean_accuracy': 0.9766403321055664,\n",
       "  'eval_overall_accuracy': 0.9928356253228154,\n",
       "  'eval_per_category_iou': [0.9927013982378299, 0.7196506650512892],\n",
       "  'eval_per_category_accuracy': [0.9934809957997333, 0.9597996684113996],\n",
       "  'eval_runtime': 76.6313,\n",
       "  'eval_samples_per_second': 0.679,\n",
       "  'eval_steps_per_second': 0.144,\n",
       "  'epoch': 3.81,\n",
       "  'step': 80},\n",
       " {'loss': 0.1897,\n",
       "  'learning_rate': 5.768571428571428e-05,\n",
       "  'epoch': 3.86,\n",
       "  'step': 81},\n",
       " {'loss': 0.307,\n",
       "  'learning_rate': 5.7657142857142864e-05,\n",
       "  'epoch': 3.9,\n",
       "  'step': 82},\n",
       " {'loss': 0.2147,\n",
       "  'learning_rate': 5.762857142857143e-05,\n",
       "  'epoch': 3.95,\n",
       "  'step': 83},\n",
       " {'loss': 0.1799, 'learning_rate': 5.76e-05, 'epoch': 4.0, 'step': 84},\n",
       " {'loss': 0.1866,\n",
       "  'learning_rate': 5.757142857142858e-05,\n",
       "  'epoch': 4.05,\n",
       "  'step': 85},\n",
       " {'loss': 0.1883,\n",
       "  'learning_rate': 5.7542857142857145e-05,\n",
       "  'epoch': 4.1,\n",
       "  'step': 86},\n",
       " {'loss': 0.1761,\n",
       "  'learning_rate': 5.751428571428571e-05,\n",
       "  'epoch': 4.14,\n",
       "  'step': 87},\n",
       " {'loss': 0.1782,\n",
       "  'learning_rate': 5.7485714285714285e-05,\n",
       "  'epoch': 4.19,\n",
       "  'step': 88},\n",
       " {'loss': 0.1846,\n",
       "  'learning_rate': 5.745714285714286e-05,\n",
       "  'epoch': 4.24,\n",
       "  'step': 89},\n",
       " {'loss': 0.1697,\n",
       "  'learning_rate': 5.742857142857143e-05,\n",
       "  'epoch': 4.29,\n",
       "  'step': 90},\n",
       " {'loss': 0.1642, 'learning_rate': 5.74e-05, 'epoch': 4.33, 'step': 91},\n",
       " {'loss': 0.1863,\n",
       "  'learning_rate': 5.737142857142857e-05,\n",
       "  'epoch': 4.38,\n",
       "  'step': 92},\n",
       " {'loss': 0.1986,\n",
       "  'learning_rate': 5.7342857142857147e-05,\n",
       "  'epoch': 4.43,\n",
       "  'step': 93},\n",
       " {'loss': 0.1856,\n",
       "  'learning_rate': 5.7314285714285713e-05,\n",
       "  'epoch': 4.48,\n",
       "  'step': 94},\n",
       " {'loss': 0.1782,\n",
       "  'learning_rate': 5.728571428571429e-05,\n",
       "  'epoch': 4.52,\n",
       "  'step': 95},\n",
       " {'loss': 0.1721,\n",
       "  'learning_rate': 5.725714285714286e-05,\n",
       "  'epoch': 4.57,\n",
       "  'step': 96},\n",
       " {'loss': 0.1547,\n",
       "  'learning_rate': 5.722857142857143e-05,\n",
       "  'epoch': 4.62,\n",
       "  'step': 97},\n",
       " {'loss': 0.1698, 'learning_rate': 5.72e-05, 'epoch': 4.67, 'step': 98},\n",
       " {'loss': 0.1705,\n",
       "  'learning_rate': 5.7171428571428575e-05,\n",
       "  'epoch': 4.71,\n",
       "  'step': 99},\n",
       " {'loss': 0.207,\n",
       "  'learning_rate': 5.714285714285714e-05,\n",
       "  'epoch': 4.76,\n",
       "  'step': 100},\n",
       " {'eval_loss': 0.14042912423610687,\n",
       "  'eval_mean_iou': 0.8957092540271054,\n",
       "  'eval_mean_accuracy': 0.9628872500071797,\n",
       "  'eval_overall_accuracy': 0.9954395718880593,\n",
       "  'eval_per_category_iou': [0.9953569187132483, 0.7960615893409626],\n",
       "  'eval_per_category_accuracy': [0.9967367578800161, 0.9290377421343432],\n",
       "  'eval_runtime': 78.6655,\n",
       "  'eval_samples_per_second': 0.661,\n",
       "  'eval_steps_per_second': 0.14,\n",
       "  'epoch': 4.76,\n",
       "  'step': 100},\n",
       " {'loss': 0.1532,\n",
       "  'learning_rate': 5.7114285714285715e-05,\n",
       "  'epoch': 4.81,\n",
       "  'step': 101},\n",
       " {'loss': 0.1673,\n",
       "  'learning_rate': 5.708571428571428e-05,\n",
       "  'epoch': 4.86,\n",
       "  'step': 102},\n",
       " {'loss': 0.1585,\n",
       "  'learning_rate': 5.705714285714286e-05,\n",
       "  'epoch': 4.9,\n",
       "  'step': 103},\n",
       " {'loss': 0.1395,\n",
       "  'learning_rate': 5.702857142857143e-05,\n",
       "  'epoch': 4.95,\n",
       "  'step': 104},\n",
       " {'loss': 0.1765,\n",
       "  'learning_rate': 5.6999999999999996e-05,\n",
       "  'epoch': 5.0,\n",
       "  'step': 105},\n",
       " {'loss': 0.1438,\n",
       "  'learning_rate': 5.697142857142858e-05,\n",
       "  'epoch': 5.05,\n",
       "  'step': 106},\n",
       " {'loss': 0.1778,\n",
       "  'learning_rate': 5.6942857142857144e-05,\n",
       "  'epoch': 5.1,\n",
       "  'step': 107},\n",
       " {'loss': 0.1425,\n",
       "  'learning_rate': 5.691428571428572e-05,\n",
       "  'epoch': 5.14,\n",
       "  'step': 108},\n",
       " {'loss': 0.1626,\n",
       "  'learning_rate': 5.688571428571429e-05,\n",
       "  'epoch': 5.19,\n",
       "  'step': 109},\n",
       " {'loss': 0.1523,\n",
       "  'learning_rate': 5.685714285714286e-05,\n",
       "  'epoch': 5.24,\n",
       "  'step': 110},\n",
       " {'loss': 0.1508,\n",
       "  'learning_rate': 5.682857142857143e-05,\n",
       "  'epoch': 5.29,\n",
       "  'step': 111},\n",
       " {'loss': 0.1402, 'learning_rate': 5.68e-05, 'epoch': 5.33, 'step': 112},\n",
       " {'loss': 0.1567,\n",
       "  'learning_rate': 5.677142857142857e-05,\n",
       "  'epoch': 5.38,\n",
       "  'step': 113},\n",
       " {'loss': 0.1526,\n",
       "  'learning_rate': 5.6742857142857146e-05,\n",
       "  'epoch': 5.43,\n",
       "  'step': 114},\n",
       " {'loss': 0.1429,\n",
       "  'learning_rate': 5.671428571428571e-05,\n",
       "  'epoch': 5.48,\n",
       "  'step': 115},\n",
       " {'loss': 0.1442,\n",
       "  'learning_rate': 5.668571428571429e-05,\n",
       "  'epoch': 5.52,\n",
       "  'step': 116},\n",
       " {'loss': 0.1306,\n",
       "  'learning_rate': 5.665714285714286e-05,\n",
       "  'epoch': 5.57,\n",
       "  'step': 117},\n",
       " {'loss': 0.1336,\n",
       "  'learning_rate': 5.6628571428571427e-05,\n",
       "  'epoch': 5.62,\n",
       "  'step': 118},\n",
       " {'loss': 0.1456, 'learning_rate': 5.66e-05, 'epoch': 5.67, 'step': 119},\n",
       " {'loss': 0.1548,\n",
       "  'learning_rate': 5.6571428571428574e-05,\n",
       "  'epoch': 5.71,\n",
       "  'step': 120},\n",
       " {'eval_loss': 0.12579645216464996,\n",
       "  'eval_mean_iou': 0.8907797783412434,\n",
       "  'eval_mean_accuracy': 0.9696627211860793,\n",
       "  'eval_overall_accuracy': 0.9950955533643236,\n",
       "  'eval_per_category_iou': [0.9950052836489762, 0.7865542730335106],\n",
       "  'eval_per_category_accuracy': [0.9961090329483033, 0.9432164094238552],\n",
       "  'eval_runtime': 78.935,\n",
       "  'eval_samples_per_second': 0.659,\n",
       "  'eval_steps_per_second': 0.139,\n",
       "  'epoch': 5.71,\n",
       "  'step': 120},\n",
       " {'loss': 0.1408,\n",
       "  'learning_rate': 5.654285714285715e-05,\n",
       "  'epoch': 5.76,\n",
       "  'step': 121},\n",
       " {'loss': 0.139,\n",
       "  'learning_rate': 5.6514285714285714e-05,\n",
       "  'epoch': 5.81,\n",
       "  'step': 122},\n",
       " {'loss': 0.1349,\n",
       "  'learning_rate': 5.648571428571429e-05,\n",
       "  'epoch': 5.86,\n",
       "  'step': 123},\n",
       " {'loss': 0.1164,\n",
       "  'learning_rate': 5.645714285714286e-05,\n",
       "  'epoch': 5.9,\n",
       "  'step': 124},\n",
       " {'loss': 0.1264,\n",
       "  'learning_rate': 5.642857142857143e-05,\n",
       "  'epoch': 5.95,\n",
       "  'step': 125},\n",
       " {'loss': 0.1357,\n",
       "  'learning_rate': 5.6399999999999995e-05,\n",
       "  'epoch': 6.0,\n",
       "  'step': 126},\n",
       " {'loss': 0.1287,\n",
       "  'learning_rate': 5.6371428571428576e-05,\n",
       "  'epoch': 6.05,\n",
       "  'step': 127},\n",
       " {'loss': 0.1483,\n",
       "  'learning_rate': 5.634285714285714e-05,\n",
       "  'epoch': 6.1,\n",
       "  'step': 128},\n",
       " {'loss': 0.1197,\n",
       "  'learning_rate': 5.6314285714285716e-05,\n",
       "  'epoch': 6.14,\n",
       "  'step': 129},\n",
       " {'loss': 0.1511,\n",
       "  'learning_rate': 5.628571428571429e-05,\n",
       "  'epoch': 6.19,\n",
       "  'step': 130},\n",
       " {'loss': 0.1163,\n",
       "  'learning_rate': 5.625714285714286e-05,\n",
       "  'epoch': 6.24,\n",
       "  'step': 131},\n",
       " {'loss': 0.125,\n",
       "  'learning_rate': 5.622857142857143e-05,\n",
       "  'epoch': 6.29,\n",
       "  'step': 132},\n",
       " {'loss': 0.1442, 'learning_rate': 5.62e-05, 'epoch': 6.33, 'step': 133},\n",
       " {'loss': 0.1363,\n",
       "  'learning_rate': 5.617142857142858e-05,\n",
       "  'epoch': 6.38,\n",
       "  'step': 134},\n",
       " {'loss': 0.1477,\n",
       "  'learning_rate': 5.6142857142857145e-05,\n",
       "  'epoch': 6.43,\n",
       "  'step': 135},\n",
       " {'loss': 0.1432,\n",
       "  'learning_rate': 5.611428571428571e-05,\n",
       "  'epoch': 6.48,\n",
       "  'step': 136},\n",
       " {'loss': 0.1231,\n",
       "  'learning_rate': 5.608571428571429e-05,\n",
       "  'epoch': 6.52,\n",
       "  'step': 137},\n",
       " {'loss': 0.1273,\n",
       "  'learning_rate': 5.605714285714286e-05,\n",
       "  'epoch': 6.57,\n",
       "  'step': 138},\n",
       " {'loss': 0.1325,\n",
       "  'learning_rate': 5.6028571428571426e-05,\n",
       "  'epoch': 6.62,\n",
       "  'step': 139},\n",
       " {'loss': 0.1193, 'learning_rate': 5.6e-05, 'epoch': 6.67, 'step': 140},\n",
       " {'eval_loss': 0.12075065076351166,\n",
       "  'eval_mean_iou': 0.9097763514751521,\n",
       "  'eval_mean_accuracy': 0.9712723770608139,\n",
       "  'eval_overall_accuracy': 0.996117484270085,\n",
       "  'eval_per_category_iou': [0.9960458525387459, 0.8235068504115584],\n",
       "  'eval_per_category_accuracy': [0.9971075434479976, 0.9454372106736303],\n",
       "  'eval_runtime': 78.554,\n",
       "  'eval_samples_per_second': 0.662,\n",
       "  'eval_steps_per_second': 0.14,\n",
       "  'epoch': 6.67,\n",
       "  'step': 140},\n",
       " {'loss': 0.1158,\n",
       "  'learning_rate': 5.597142857142857e-05,\n",
       "  'epoch': 6.71,\n",
       "  'step': 141},\n",
       " {'loss': 0.1346,\n",
       "  'learning_rate': 5.5942857142857146e-05,\n",
       "  'epoch': 6.76,\n",
       "  'step': 142},\n",
       " {'loss': 0.1544,\n",
       "  'learning_rate': 5.591428571428571e-05,\n",
       "  'epoch': 6.81,\n",
       "  'step': 143},\n",
       " {'loss': 0.1153,\n",
       "  'learning_rate': 5.588571428571429e-05,\n",
       "  'epoch': 6.86,\n",
       "  'step': 144},\n",
       " {'loss': 0.1128,\n",
       "  'learning_rate': 5.585714285714286e-05,\n",
       "  'epoch': 6.9,\n",
       "  'step': 145},\n",
       " {'loss': 0.1133,\n",
       "  'learning_rate': 5.582857142857143e-05,\n",
       "  'epoch': 6.95,\n",
       "  'step': 146},\n",
       " {'loss': 0.1075, 'learning_rate': 5.58e-05, 'epoch': 7.0, 'step': 147},\n",
       " {'loss': 0.109,\n",
       "  'learning_rate': 5.5771428571428575e-05,\n",
       "  'epoch': 7.05,\n",
       "  'step': 148},\n",
       " {'loss': 0.1097,\n",
       "  'learning_rate': 5.574285714285714e-05,\n",
       "  'epoch': 7.1,\n",
       "  'step': 149},\n",
       " {'loss': 0.1142,\n",
       "  'learning_rate': 5.5714285714285715e-05,\n",
       "  'epoch': 7.14,\n",
       "  'step': 150},\n",
       " {'loss': 0.1277,\n",
       "  'learning_rate': 5.568571428571429e-05,\n",
       "  'epoch': 7.19,\n",
       "  'step': 151},\n",
       " {'loss': 0.1073,\n",
       "  'learning_rate': 5.5657142857142856e-05,\n",
       "  'epoch': 7.24,\n",
       "  'step': 152},\n",
       " {'loss': 0.0978,\n",
       "  'learning_rate': 5.562857142857143e-05,\n",
       "  'epoch': 7.29,\n",
       "  'step': 153},\n",
       " {'loss': 0.1059, 'learning_rate': 5.56e-05, 'epoch': 7.33, 'step': 154},\n",
       " {'loss': 0.1393,\n",
       "  'learning_rate': 5.557142857142858e-05,\n",
       "  'epoch': 7.38,\n",
       "  'step': 155},\n",
       " {'loss': 0.1201,\n",
       "  'learning_rate': 5.5542857142857143e-05,\n",
       "  'epoch': 7.43,\n",
       "  'step': 156},\n",
       " {'loss': 0.143,\n",
       "  'learning_rate': 5.551428571428571e-05,\n",
       "  'epoch': 7.48,\n",
       "  'step': 157},\n",
       " {'loss': 0.1051,\n",
       "  'learning_rate': 5.548571428571429e-05,\n",
       "  'epoch': 7.52,\n",
       "  'step': 158},\n",
       " {'loss': 0.112,\n",
       "  'learning_rate': 5.545714285714286e-05,\n",
       "  'epoch': 7.57,\n",
       "  'step': 159},\n",
       " {'loss': 0.1044,\n",
       "  'learning_rate': 5.542857142857143e-05,\n",
       "  'epoch': 7.62,\n",
       "  'step': 160},\n",
       " {'eval_loss': 0.08657090365886688,\n",
       "  'eval_mean_iou': 0.912101317711005,\n",
       "  'eval_mean_accuracy': 0.9701259793823384,\n",
       "  'eval_overall_accuracy': 0.996247344109499,\n",
       "  'eval_per_category_iou': [0.9961782927416254, 0.8280243426803846],\n",
       "  'eval_per_category_accuracy': [0.9972882612071752, 0.9429636975575015],\n",
       "  'eval_runtime': 80.4919,\n",
       "  'eval_samples_per_second': 0.646,\n",
       "  'eval_steps_per_second': 0.137,\n",
       "  'epoch': 7.62,\n",
       "  'step': 160},\n",
       " {'loss': 0.1164,\n",
       "  'learning_rate': 5.5400000000000005e-05,\n",
       "  'epoch': 7.67,\n",
       "  'step': 161},\n",
       " {'loss': 0.1076,\n",
       "  'learning_rate': 5.537142857142857e-05,\n",
       "  'epoch': 7.71,\n",
       "  'step': 162},\n",
       " {'loss': 0.0923,\n",
       "  'learning_rate': 5.5342857142857145e-05,\n",
       "  'epoch': 7.76,\n",
       "  'step': 163},\n",
       " {'loss': 0.0896,\n",
       "  'learning_rate': 5.531428571428571e-05,\n",
       "  'epoch': 7.81,\n",
       "  'step': 164},\n",
       " {'loss': 0.1107,\n",
       "  'learning_rate': 5.5285714285714286e-05,\n",
       "  'epoch': 7.86,\n",
       "  'step': 165},\n",
       " {'loss': 0.1481,\n",
       "  'learning_rate': 5.525714285714286e-05,\n",
       "  'epoch': 7.9,\n",
       "  'step': 166},\n",
       " {'loss': 0.103,\n",
       "  'learning_rate': 5.5228571428571426e-05,\n",
       "  'epoch': 7.95,\n",
       "  'step': 167},\n",
       " {'loss': 0.0983,\n",
       "  'learning_rate': 5.520000000000001e-05,\n",
       "  'epoch': 8.0,\n",
       "  'step': 168},\n",
       " {'loss': 0.0952,\n",
       "  'learning_rate': 5.5171428571428574e-05,\n",
       "  'epoch': 8.05,\n",
       "  'step': 169},\n",
       " {'loss': 0.1033,\n",
       "  'learning_rate': 5.514285714285714e-05,\n",
       "  'epoch': 8.1,\n",
       "  'step': 170},\n",
       " {'loss': 0.1031,\n",
       "  'learning_rate': 5.5114285714285714e-05,\n",
       "  'epoch': 8.14,\n",
       "  'step': 171},\n",
       " {'loss': 0.1125,\n",
       "  'learning_rate': 5.508571428571429e-05,\n",
       "  'epoch': 8.19,\n",
       "  'step': 172},\n",
       " {'loss': 0.0938,\n",
       "  'learning_rate': 5.505714285714286e-05,\n",
       "  'epoch': 8.24,\n",
       "  'step': 173},\n",
       " {'loss': 0.0924,\n",
       "  'learning_rate': 5.502857142857143e-05,\n",
       "  'epoch': 8.29,\n",
       "  'step': 174},\n",
       " {'loss': 0.0809, 'learning_rate': 5.5e-05, 'epoch': 8.33, 'step': 175},\n",
       " {'loss': 0.0846,\n",
       "  'learning_rate': 5.4971428571428576e-05,\n",
       "  'epoch': 8.38,\n",
       "  'step': 176},\n",
       " {'loss': 0.0907,\n",
       "  'learning_rate': 5.494285714285714e-05,\n",
       "  'epoch': 8.43,\n",
       "  'step': 177},\n",
       " {'loss': 0.0895,\n",
       "  'learning_rate': 5.491428571428571e-05,\n",
       "  'epoch': 8.48,\n",
       "  'step': 178},\n",
       " {'loss': 0.101,\n",
       "  'learning_rate': 5.488571428571429e-05,\n",
       "  'epoch': 8.52,\n",
       "  'step': 179},\n",
       " {'loss': 0.0872,\n",
       "  'learning_rate': 5.4857142857142857e-05,\n",
       "  'epoch': 8.57,\n",
       "  'step': 180},\n",
       " {'eval_loss': 0.059239260852336884,\n",
       "  'eval_mean_iou': 0.9189829083266465,\n",
       "  'eval_mean_accuracy': 0.9624389925807797,\n",
       "  'eval_overall_accuracy': 0.9966517437902052,\n",
       "  'eval_per_category_iou': [0.9965912046402102, 0.841374612013083],\n",
       "  'eval_per_category_accuracy': [0.998015096664927, 0.9268628884966325],\n",
       "  'eval_runtime': 81.9271,\n",
       "  'eval_samples_per_second': 0.635,\n",
       "  'eval_steps_per_second': 0.134,\n",
       "  'epoch': 8.57,\n",
       "  'step': 180},\n",
       " {'loss': 0.0912,\n",
       "  'learning_rate': 5.482857142857143e-05,\n",
       "  'epoch': 8.62,\n",
       "  'step': 181},\n",
       " {'loss': 0.0814,\n",
       "  'learning_rate': 5.4800000000000004e-05,\n",
       "  'epoch': 8.67,\n",
       "  'step': 182},\n",
       " {'loss': 0.0838,\n",
       "  'learning_rate': 5.477142857142857e-05,\n",
       "  'epoch': 8.71,\n",
       "  'step': 183},\n",
       " {'loss': 0.0908,\n",
       "  'learning_rate': 5.4742857142857144e-05,\n",
       "  'epoch': 8.76,\n",
       "  'step': 184},\n",
       " {'loss': 0.1024,\n",
       "  'learning_rate': 5.471428571428571e-05,\n",
       "  'epoch': 8.81,\n",
       "  'step': 185},\n",
       " {'loss': 0.0878,\n",
       "  'learning_rate': 5.468571428571429e-05,\n",
       "  'epoch': 8.86,\n",
       "  'step': 186},\n",
       " {'loss': 0.0931,\n",
       "  'learning_rate': 5.465714285714286e-05,\n",
       "  'epoch': 8.9,\n",
       "  'step': 187},\n",
       " {'loss': 0.0941,\n",
       "  'learning_rate': 5.4628571428571425e-05,\n",
       "  'epoch': 8.95,\n",
       "  'step': 188},\n",
       " {'loss': 0.0812,\n",
       "  'learning_rate': 5.4600000000000006e-05,\n",
       "  'epoch': 9.0,\n",
       "  'step': 189},\n",
       " {'loss': 0.0795,\n",
       "  'learning_rate': 5.457142857142857e-05,\n",
       "  'epoch': 9.05,\n",
       "  'step': 190},\n",
       " {'loss': 0.0891,\n",
       "  'learning_rate': 5.454285714285714e-05,\n",
       "  'epoch': 9.1,\n",
       "  'step': 191},\n",
       " {'loss': 0.0793,\n",
       "  'learning_rate': 5.451428571428571e-05,\n",
       "  'epoch': 9.14,\n",
       "  'step': 192},\n",
       " {'loss': 0.0852,\n",
       "  'learning_rate': 5.448571428571429e-05,\n",
       "  'epoch': 9.19,\n",
       "  'step': 193},\n",
       " {'loss': 0.1275,\n",
       "  'learning_rate': 5.445714285714286e-05,\n",
       "  'epoch': 9.24,\n",
       "  'step': 194},\n",
       " {'loss': 0.0827,\n",
       "  'learning_rate': 5.442857142857143e-05,\n",
       "  'epoch': 9.29,\n",
       "  'step': 195},\n",
       " {'loss': 0.0803, 'learning_rate': 5.44e-05, 'epoch': 9.33, 'step': 196},\n",
       " {'loss': 0.101,\n",
       "  'learning_rate': 5.4371428571428575e-05,\n",
       "  'epoch': 9.38,\n",
       "  'step': 197},\n",
       " {'loss': 0.0991,\n",
       "  'learning_rate': 5.434285714285714e-05,\n",
       "  'epoch': 9.43,\n",
       "  'step': 198},\n",
       " {'loss': 0.0817,\n",
       "  'learning_rate': 5.431428571428572e-05,\n",
       "  'epoch': 9.48,\n",
       "  'step': 199},\n",
       " {'loss': 0.1069,\n",
       "  'learning_rate': 5.428571428571429e-05,\n",
       "  'epoch': 9.52,\n",
       "  'step': 200},\n",
       " {'eval_loss': 0.10796001553535461,\n",
       "  'eval_mean_iou': 0.9127377909427064,\n",
       "  'eval_mean_accuracy': 0.9864323888578859,\n",
       "  'eval_overall_accuracy': 0.9961519668263136,\n",
       "  'eval_per_category_iou': [0.9960786075853213, 0.8293969743000914],\n",
       "  'eval_per_category_accuracy': [0.9965392848319081, 0.9763254928838636],\n",
       "  'eval_runtime': 79.5041,\n",
       "  'eval_samples_per_second': 0.654,\n",
       "  'eval_steps_per_second': 0.138,\n",
       "  'epoch': 9.52,\n",
       "  'step': 200},\n",
       " {'loss': 0.0866,\n",
       "  'learning_rate': 5.4257142857142856e-05,\n",
       "  'epoch': 9.57,\n",
       "  'step': 201},\n",
       " {'loss': 0.0922,\n",
       "  'learning_rate': 5.422857142857143e-05,\n",
       "  'epoch': 9.62,\n",
       "  'step': 202},\n",
       " {'loss': 0.0899, 'learning_rate': 5.42e-05, 'epoch': 9.67, 'step': 203},\n",
       " {'loss': 0.0883,\n",
       "  'learning_rate': 5.417142857142857e-05,\n",
       "  'epoch': 9.71,\n",
       "  'step': 204},\n",
       " {'loss': 0.0712,\n",
       "  'learning_rate': 5.414285714285714e-05,\n",
       "  'epoch': 9.76,\n",
       "  'step': 205},\n",
       " {'loss': 0.0746,\n",
       "  'learning_rate': 5.411428571428572e-05,\n",
       "  'epoch': 9.81,\n",
       "  'step': 206},\n",
       " {'loss': 0.0807,\n",
       "  'learning_rate': 5.408571428571429e-05,\n",
       "  'epoch': 9.86,\n",
       "  'step': 207},\n",
       " {'loss': 0.0927,\n",
       "  'learning_rate': 5.405714285714286e-05,\n",
       "  'epoch': 9.9,\n",
       "  'step': 208},\n",
       " {'loss': 0.0965,\n",
       "  'learning_rate': 5.4028571428571424e-05,\n",
       "  'epoch': 9.95,\n",
       "  'step': 209},\n",
       " {'loss': 0.069,\n",
       "  'learning_rate': 5.4000000000000005e-05,\n",
       "  'epoch': 10.0,\n",
       "  'step': 210},\n",
       " {'loss': 0.0736,\n",
       "  'learning_rate': 5.397142857142857e-05,\n",
       "  'epoch': 10.05,\n",
       "  'step': 211},\n",
       " {'loss': 0.0831,\n",
       "  'learning_rate': 5.3942857142857145e-05,\n",
       "  'epoch': 10.1,\n",
       "  'step': 212},\n",
       " {'loss': 0.1003,\n",
       "  'learning_rate': 5.391428571428572e-05,\n",
       "  'epoch': 10.14,\n",
       "  'step': 213},\n",
       " {'loss': 0.0722,\n",
       "  'learning_rate': 5.3885714285714286e-05,\n",
       "  'epoch': 10.19,\n",
       "  'step': 214},\n",
       " {'loss': 0.0911,\n",
       "  'learning_rate': 5.385714285714286e-05,\n",
       "  'epoch': 10.24,\n",
       "  'step': 215},\n",
       " {'loss': 0.079,\n",
       "  'learning_rate': 5.3828571428571426e-05,\n",
       "  'epoch': 10.29,\n",
       "  'step': 216},\n",
       " {'loss': 0.0854, 'learning_rate': 5.38e-05, 'epoch': 10.33, 'step': 217},\n",
       " {'loss': 0.0828,\n",
       "  'learning_rate': 5.3771428571428574e-05,\n",
       "  'epoch': 10.38,\n",
       "  'step': 218},\n",
       " {'loss': 0.0765,\n",
       "  'learning_rate': 5.374285714285714e-05,\n",
       "  'epoch': 10.43,\n",
       "  'step': 219},\n",
       " {'loss': 0.0898,\n",
       "  'learning_rate': 5.371428571428572e-05,\n",
       "  'epoch': 10.48,\n",
       "  'step': 220},\n",
       " {'eval_loss': 0.07735849916934967,\n",
       "  'eval_mean_iou': 0.921613331824578,\n",
       "  'eval_mean_accuracy': 0.9737663452971971,\n",
       "  'eval_overall_accuracy': 0.9967016334460252,\n",
       "  'eval_per_category_iou': [0.9966404854643102, 0.8465861781848459],\n",
       "  'eval_per_category_accuracy': [0.9976155877444935, 0.9499171028499006],\n",
       "  'eval_runtime': 80.962,\n",
       "  'eval_samples_per_second': 0.642,\n",
       "  'eval_steps_per_second': 0.136,\n",
       "  'epoch': 10.48,\n",
       "  'step': 220},\n",
       " {'loss': 0.0853,\n",
       "  'learning_rate': 5.368571428571429e-05,\n",
       "  'epoch': 10.52,\n",
       "  'step': 221},\n",
       " {'loss': 0.0816,\n",
       "  'learning_rate': 5.3657142857142855e-05,\n",
       "  'epoch': 10.57,\n",
       "  'step': 222},\n",
       " {'loss': 0.077,\n",
       "  'learning_rate': 5.362857142857143e-05,\n",
       "  'epoch': 10.62,\n",
       "  'step': 223},\n",
       " {'loss': 0.0659, 'learning_rate': 5.36e-05, 'epoch': 10.67, 'step': 224},\n",
       " {'loss': 0.0751,\n",
       "  'learning_rate': 5.3571428571428575e-05,\n",
       "  'epoch': 10.71,\n",
       "  'step': 225},\n",
       " {'loss': 0.074,\n",
       "  'learning_rate': 5.354285714285714e-05,\n",
       "  'epoch': 10.76,\n",
       "  'step': 226},\n",
       " {'loss': 0.0825,\n",
       "  'learning_rate': 5.3514285714285716e-05,\n",
       "  'epoch': 10.81,\n",
       "  'step': 227},\n",
       " {'loss': 0.0653,\n",
       "  'learning_rate': 5.348571428571429e-05,\n",
       "  'epoch': 10.86,\n",
       "  'step': 228},\n",
       " {'loss': 0.1062,\n",
       "  'learning_rate': 5.3457142857142856e-05,\n",
       "  'epoch': 10.9,\n",
       "  'step': 229},\n",
       " {'loss': 0.0774,\n",
       "  'learning_rate': 5.342857142857142e-05,\n",
       "  'epoch': 10.95,\n",
       "  'step': 230},\n",
       " {'loss': 0.0619,\n",
       "  'learning_rate': 5.3400000000000004e-05,\n",
       "  'epoch': 11.0,\n",
       "  'step': 231},\n",
       " {'loss': 0.0597,\n",
       "  'learning_rate': 5.337142857142857e-05,\n",
       "  'epoch': 11.05,\n",
       "  'step': 232},\n",
       " {'loss': 0.0701,\n",
       "  'learning_rate': 5.3342857142857144e-05,\n",
       "  'epoch': 11.1,\n",
       "  'step': 233},\n",
       " {'loss': 0.0728,\n",
       "  'learning_rate': 5.331428571428572e-05,\n",
       "  'epoch': 11.14,\n",
       "  'step': 234},\n",
       " {'loss': 0.0709,\n",
       "  'learning_rate': 5.3285714285714285e-05,\n",
       "  'epoch': 11.19,\n",
       "  'step': 235},\n",
       " {'loss': 0.0892,\n",
       "  'learning_rate': 5.325714285714286e-05,\n",
       "  'epoch': 11.24,\n",
       "  'step': 236},\n",
       " {'loss': 0.0655,\n",
       "  'learning_rate': 5.322857142857143e-05,\n",
       "  'epoch': 11.29,\n",
       "  'step': 237},\n",
       " {'loss': 0.104,\n",
       "  'learning_rate': 5.3200000000000006e-05,\n",
       "  'epoch': 11.33,\n",
       "  'step': 238},\n",
       " {'loss': 0.075,\n",
       "  'learning_rate': 5.317142857142857e-05,\n",
       "  'epoch': 11.38,\n",
       "  'step': 239},\n",
       " {'loss': 0.0625,\n",
       "  'learning_rate': 5.314285714285714e-05,\n",
       "  'epoch': 11.43,\n",
       "  'step': 240},\n",
       " {'eval_loss': 0.05498785525560379,\n",
       "  'eval_mean_iou': 0.9077829715742993,\n",
       "  'eval_mean_accuracy': 0.9868653895531887,\n",
       "  'eval_overall_accuracy': 0.9958819757477579,\n",
       "  'eval_per_category_iou': [0.9958033739889188, 0.8197625691596798],\n",
       "  'eval_per_category_accuracy': [0.996241280050218, 0.9774894990561594],\n",
       "  'eval_runtime': 80.7972,\n",
       "  'eval_samples_per_second': 0.644,\n",
       "  'eval_steps_per_second': 0.136,\n",
       "  'epoch': 11.43,\n",
       "  'step': 240},\n",
       " {'loss': 0.0713,\n",
       "  'learning_rate': 5.311428571428572e-05,\n",
       "  'epoch': 11.48,\n",
       "  'step': 241},\n",
       " {'loss': 0.0757,\n",
       "  'learning_rate': 5.308571428571429e-05,\n",
       "  'epoch': 11.52,\n",
       "  'step': 242},\n",
       " {'loss': 0.0635,\n",
       "  'learning_rate': 5.3057142857142854e-05,\n",
       "  'epoch': 11.57,\n",
       "  'step': 243},\n",
       " {'loss': 0.0658,\n",
       "  'learning_rate': 5.3028571428571434e-05,\n",
       "  'epoch': 11.62,\n",
       "  'step': 244},\n",
       " {'loss': 0.0592, 'learning_rate': 5.3e-05, 'epoch': 11.67, 'step': 245},\n",
       " {'loss': 0.0706,\n",
       "  'learning_rate': 5.2971428571428574e-05,\n",
       "  'epoch': 11.71,\n",
       "  'step': 246},\n",
       " {'loss': 0.0651,\n",
       "  'learning_rate': 5.294285714285714e-05,\n",
       "  'epoch': 11.76,\n",
       "  'step': 247},\n",
       " {'loss': 0.0686,\n",
       "  'learning_rate': 5.2914285714285715e-05,\n",
       "  'epoch': 11.81,\n",
       "  'step': 248},\n",
       " {'loss': 0.0963,\n",
       "  'learning_rate': 5.288571428571429e-05,\n",
       "  'epoch': 11.86,\n",
       "  'step': 249},\n",
       " {'loss': 0.0649,\n",
       "  'learning_rate': 5.2857142857142855e-05,\n",
       "  'epoch': 11.9,\n",
       "  'step': 250},\n",
       " {'loss': 0.0809,\n",
       "  'learning_rate': 5.2828571428571436e-05,\n",
       "  'epoch': 11.95,\n",
       "  'step': 251},\n",
       " {'loss': 0.0767, 'learning_rate': 5.28e-05, 'epoch': 12.0, 'step': 252},\n",
       " {'loss': 0.07,\n",
       "  'learning_rate': 5.277142857142857e-05,\n",
       "  'epoch': 12.05,\n",
       "  'step': 253},\n",
       " {'loss': 0.0623,\n",
       "  'learning_rate': 5.274285714285714e-05,\n",
       "  'epoch': 12.1,\n",
       "  'step': 254},\n",
       " {'loss': 0.0698,\n",
       "  'learning_rate': 5.271428571428572e-05,\n",
       "  'epoch': 12.14,\n",
       "  'step': 255},\n",
       " {'loss': 0.0591,\n",
       "  'learning_rate': 5.2685714285714284e-05,\n",
       "  'epoch': 12.19,\n",
       "  'step': 256},\n",
       " {'loss': 0.0885,\n",
       "  'learning_rate': 5.265714285714286e-05,\n",
       "  'epoch': 12.24,\n",
       "  'step': 257},\n",
       " {'loss': 0.0775,\n",
       "  'learning_rate': 5.262857142857143e-05,\n",
       "  'epoch': 12.29,\n",
       "  'step': 258},\n",
       " {'loss': 0.0729,\n",
       "  'learning_rate': 5.2600000000000005e-05,\n",
       "  'epoch': 12.33,\n",
       "  'step': 259},\n",
       " {'loss': 0.0875,\n",
       "  'learning_rate': 5.257142857142857e-05,\n",
       "  'epoch': 12.38,\n",
       "  'step': 260},\n",
       " {'eval_loss': 0.06317801773548126,\n",
       "  'eval_mean_iou': 0.9362878055025121,\n",
       "  'eval_mean_accuracy': 0.979182718514175,\n",
       "  'eval_overall_accuracy': 0.9973774181809645,\n",
       "  'eval_per_category_iou': [0.997328259023591, 0.8752473519814333],\n",
       "  'eval_per_category_accuracy': [0.9981024635286354, 0.9602629734997148],\n",
       "  'eval_runtime': 80.6728,\n",
       "  'eval_samples_per_second': 0.645,\n",
       "  'eval_steps_per_second': 0.136,\n",
       "  'epoch': 12.38,\n",
       "  'step': 260},\n",
       " {'loss': 0.0689,\n",
       "  'learning_rate': 5.254285714285714e-05,\n",
       "  'epoch': 12.43,\n",
       "  'step': 261},\n",
       " {'loss': 0.0541,\n",
       "  'learning_rate': 5.251428571428572e-05,\n",
       "  'epoch': 12.48,\n",
       "  'step': 262},\n",
       " {'loss': 0.0672,\n",
       "  'learning_rate': 5.2485714285714286e-05,\n",
       "  'epoch': 12.52,\n",
       "  'step': 263},\n",
       " {'loss': 0.0636,\n",
       "  'learning_rate': 5.245714285714286e-05,\n",
       "  'epoch': 12.57,\n",
       "  'step': 264},\n",
       " {'loss': 0.0696,\n",
       "  'learning_rate': 5.242857142857143e-05,\n",
       "  'epoch': 12.62,\n",
       "  'step': 265},\n",
       " {'loss': 0.0888, 'learning_rate': 5.24e-05, 'epoch': 12.67, 'step': 266},\n",
       " {'loss': 0.0727,\n",
       "  'learning_rate': 5.237142857142857e-05,\n",
       "  'epoch': 12.71,\n",
       "  'step': 267},\n",
       " {'loss': 0.0674,\n",
       "  'learning_rate': 5.234285714285714e-05,\n",
       "  'epoch': 12.76,\n",
       "  'step': 268},\n",
       " {'loss': 0.0546,\n",
       "  'learning_rate': 5.231428571428572e-05,\n",
       "  'epoch': 12.81,\n",
       "  'step': 269},\n",
       " {'loss': 0.0489,\n",
       "  'learning_rate': 5.228571428571429e-05,\n",
       "  'epoch': 12.86,\n",
       "  'step': 270},\n",
       " {'loss': 0.0759,\n",
       "  'learning_rate': 5.2257142857142854e-05,\n",
       "  'epoch': 12.9,\n",
       "  'step': 271},\n",
       " {'loss': 0.0684,\n",
       "  'learning_rate': 5.2228571428571435e-05,\n",
       "  'epoch': 12.95,\n",
       "  'step': 272},\n",
       " {'loss': 0.0553, 'learning_rate': 5.22e-05, 'epoch': 13.0, 'step': 273},\n",
       " {'loss': 0.058,\n",
       "  'learning_rate': 5.217142857142857e-05,\n",
       "  'epoch': 13.05,\n",
       "  'step': 274},\n",
       " {'loss': 0.0572,\n",
       "  'learning_rate': 5.214285714285714e-05,\n",
       "  'epoch': 13.1,\n",
       "  'step': 275},\n",
       " {'loss': 0.0561,\n",
       "  'learning_rate': 5.2114285714285716e-05,\n",
       "  'epoch': 13.14,\n",
       "  'step': 276},\n",
       " {'loss': 0.0569,\n",
       "  'learning_rate': 5.208571428571429e-05,\n",
       "  'epoch': 13.19,\n",
       "  'step': 277},\n",
       " {'loss': 0.0725,\n",
       "  'learning_rate': 5.2057142857142856e-05,\n",
       "  'epoch': 13.24,\n",
       "  'step': 278},\n",
       " {'loss': 0.0579,\n",
       "  'learning_rate': 5.202857142857143e-05,\n",
       "  'epoch': 13.29,\n",
       "  'step': 279},\n",
       " {'loss': 0.0547,\n",
       "  'learning_rate': 5.2000000000000004e-05,\n",
       "  'epoch': 13.33,\n",
       "  'step': 280},\n",
       " {'eval_loss': 0.055956728756427765,\n",
       "  'eval_mean_iou': 0.934510554838714,\n",
       "  'eval_mean_accuracy': 0.9750410127840679,\n",
       "  'eval_overall_accuracy': 0.9973168169225712,\n",
       "  'eval_per_category_iou': [0.9972669691792709, 0.8717541404981572],\n",
       "  'eval_per_category_accuracy': [0.9982044912701579, 0.951877534297978],\n",
       "  'eval_runtime': 80.1244,\n",
       "  'eval_samples_per_second': 0.649,\n",
       "  'eval_steps_per_second': 0.137,\n",
       "  'epoch': 13.33,\n",
       "  'step': 280},\n",
       " {'loss': 0.0571,\n",
       "  'learning_rate': 5.197142857142857e-05,\n",
       "  'epoch': 13.38,\n",
       "  'step': 281},\n",
       " {'loss': 0.0525,\n",
       "  'learning_rate': 5.194285714285715e-05,\n",
       "  'epoch': 13.43,\n",
       "  'step': 282},\n",
       " {'loss': 0.0572,\n",
       "  'learning_rate': 5.191428571428572e-05,\n",
       "  'epoch': 13.48,\n",
       "  'step': 283},\n",
       " {'loss': 0.0473,\n",
       "  'learning_rate': 5.1885714285714285e-05,\n",
       "  'epoch': 13.52,\n",
       "  'step': 284},\n",
       " {'loss': 0.0539,\n",
       "  'learning_rate': 5.185714285714286e-05,\n",
       "  'epoch': 13.57,\n",
       "  'step': 285},\n",
       " {'loss': 0.0738,\n",
       "  'learning_rate': 5.182857142857143e-05,\n",
       "  'epoch': 13.62,\n",
       "  'step': 286},\n",
       " {'loss': 0.0522, 'learning_rate': 5.18e-05, 'epoch': 13.67, 'step': 287},\n",
       " {'loss': 0.0524,\n",
       "  'learning_rate': 5.177142857142857e-05,\n",
       "  'epoch': 13.71,\n",
       "  'step': 288},\n",
       " {'loss': 0.0455,\n",
       "  'learning_rate': 5.1742857142857146e-05,\n",
       "  'epoch': 13.76,\n",
       "  'step': 289},\n",
       " {'loss': 0.0591,\n",
       "  'learning_rate': 5.171428571428572e-05,\n",
       "  'epoch': 13.81,\n",
       "  'step': 290},\n",
       " {'loss': 0.0611,\n",
       "  'learning_rate': 5.1685714285714286e-05,\n",
       "  'epoch': 13.86,\n",
       "  'step': 291},\n",
       " {'loss': 0.0656,\n",
       "  'learning_rate': 5.165714285714285e-05,\n",
       "  'epoch': 13.9,\n",
       "  'step': 292},\n",
       " {'loss': 0.0874,\n",
       "  'learning_rate': 5.1628571428571434e-05,\n",
       "  'epoch': 13.95,\n",
       "  'step': 293},\n",
       " {'loss': 0.0812, 'learning_rate': 5.16e-05, 'epoch': 14.0, 'step': 294},\n",
       " {'loss': 0.0465,\n",
       "  'learning_rate': 5.1571428571428574e-05,\n",
       "  'epoch': 14.05,\n",
       "  'step': 295},\n",
       " {'loss': 0.0507,\n",
       "  'learning_rate': 5.154285714285715e-05,\n",
       "  'epoch': 14.1,\n",
       "  'step': 296},\n",
       " {'loss': 0.0544,\n",
       "  'learning_rate': 5.1514285714285715e-05,\n",
       "  'epoch': 14.14,\n",
       "  'step': 297},\n",
       " {'loss': 0.064,\n",
       "  'learning_rate': 5.148571428571429e-05,\n",
       "  'epoch': 14.19,\n",
       "  'step': 298},\n",
       " {'loss': 0.0647,\n",
       "  'learning_rate': 5.1457142857142855e-05,\n",
       "  'epoch': 14.24,\n",
       "  'step': 299},\n",
       " {'loss': 0.0527,\n",
       "  'learning_rate': 5.142857142857143e-05,\n",
       "  'epoch': 14.29,\n",
       "  'step': 300},\n",
       " {'eval_loss': 0.05088498443365097,\n",
       "  'eval_mean_iou': 0.9307715609860564,\n",
       "  'eval_mean_accuracy': 0.9829267360398979,\n",
       "  'eval_overall_accuracy': 0.9970923868385219,\n",
       "  'eval_per_category_iou': [0.9970374260898323, 0.8645056958822805],\n",
       "  'eval_per_category_accuracy': [0.9976568775636434, 0.9681965945161525],\n",
       "  'eval_runtime': 79.8855,\n",
       "  'eval_samples_per_second': 0.651,\n",
       "  'eval_steps_per_second': 0.138,\n",
       "  'epoch': 14.29,\n",
       "  'step': 300},\n",
       " {'loss': 0.0527, 'learning_rate': 5.14e-05, 'epoch': 14.33, 'step': 301},\n",
       " {'loss': 0.0484,\n",
       "  'learning_rate': 5.137142857142857e-05,\n",
       "  'epoch': 14.38,\n",
       "  'step': 302},\n",
       " {'loss': 0.0508,\n",
       "  'learning_rate': 5.134285714285715e-05,\n",
       "  'epoch': 14.43,\n",
       "  'step': 303},\n",
       " {'loss': 0.054,\n",
       "  'learning_rate': 5.131428571428572e-05,\n",
       "  'epoch': 14.48,\n",
       "  'step': 304},\n",
       " {'loss': 0.0474,\n",
       "  'learning_rate': 5.1285714285714284e-05,\n",
       "  'epoch': 14.52,\n",
       "  'step': 305},\n",
       " {'loss': 0.048,\n",
       "  'learning_rate': 5.125714285714286e-05,\n",
       "  'epoch': 14.57,\n",
       "  'step': 306},\n",
       " {'loss': 0.05,\n",
       "  'learning_rate': 5.122857142857143e-05,\n",
       "  'epoch': 14.62,\n",
       "  'step': 307},\n",
       " {'loss': 0.0498,\n",
       "  'learning_rate': 5.1200000000000004e-05,\n",
       "  'epoch': 14.67,\n",
       "  'step': 308},\n",
       " {'loss': 0.0498,\n",
       "  'learning_rate': 5.117142857142857e-05,\n",
       "  'epoch': 14.71,\n",
       "  'step': 309},\n",
       " {'loss': 0.0474,\n",
       "  'learning_rate': 5.1142857142857145e-05,\n",
       "  'epoch': 14.76,\n",
       "  'step': 310},\n",
       " {'loss': 0.0473,\n",
       "  'learning_rate': 5.111428571428572e-05,\n",
       "  'epoch': 14.81,\n",
       "  'step': 311},\n",
       " {'loss': 0.051,\n",
       "  'learning_rate': 5.1085714285714285e-05,\n",
       "  'epoch': 14.86,\n",
       "  'step': 312},\n",
       " {'loss': 0.0641,\n",
       "  'learning_rate': 5.105714285714285e-05,\n",
       "  'epoch': 14.9,\n",
       "  'step': 313},\n",
       " {'loss': 0.0557,\n",
       "  'learning_rate': 5.102857142857143e-05,\n",
       "  'epoch': 14.95,\n",
       "  'step': 314},\n",
       " {'loss': 0.053, 'learning_rate': 5.1e-05, 'epoch': 15.0, 'step': 315},\n",
       " {'loss': 0.0578,\n",
       "  'learning_rate': 5.097142857142857e-05,\n",
       "  'epoch': 15.05,\n",
       "  'step': 316},\n",
       " {'loss': 0.0521,\n",
       "  'learning_rate': 5.094285714285715e-05,\n",
       "  'epoch': 15.1,\n",
       "  'step': 317},\n",
       " {'loss': 0.0511,\n",
       "  'learning_rate': 5.0914285714285714e-05,\n",
       "  'epoch': 15.14,\n",
       "  'step': 318},\n",
       " {'loss': 0.0509,\n",
       "  'learning_rate': 5.088571428571429e-05,\n",
       "  'epoch': 15.19,\n",
       "  'step': 319},\n",
       " {'loss': 0.0448,\n",
       "  'learning_rate': 5.0857142857142854e-05,\n",
       "  'epoch': 15.24,\n",
       "  'step': 320},\n",
       " {'eval_loss': 0.07112085074186325,\n",
       "  'eval_mean_iou': 0.9328264628398137,\n",
       "  'eval_mean_accuracy': 0.9865668884684428,\n",
       "  'eval_overall_accuracy': 0.9971706695778748,\n",
       "  'eval_per_category_iou': [0.9971167751664056, 0.8685361505132217],\n",
       "  'eval_per_category_accuracy': [0.9975932224257873, 0.9755405545110982],\n",
       "  'eval_runtime': 76.8576,\n",
       "  'eval_samples_per_second': 0.677,\n",
       "  'eval_steps_per_second': 0.143,\n",
       "  'epoch': 15.24,\n",
       "  'step': 320},\n",
       " {'loss': 0.049,\n",
       "  'learning_rate': 5.0828571428571435e-05,\n",
       "  'epoch': 15.29,\n",
       "  'step': 321},\n",
       " {'loss': 0.0556, 'learning_rate': 5.08e-05, 'epoch': 15.33, 'step': 322},\n",
       " {'loss': 0.0438,\n",
       "  'learning_rate': 5.077142857142857e-05,\n",
       "  'epoch': 15.38,\n",
       "  'step': 323},\n",
       " {'loss': 0.0528,\n",
       "  'learning_rate': 5.074285714285715e-05,\n",
       "  'epoch': 15.43,\n",
       "  'step': 324},\n",
       " {'loss': 0.0431,\n",
       "  'learning_rate': 5.0714285714285716e-05,\n",
       "  'epoch': 15.48,\n",
       "  'step': 325},\n",
       " {'loss': 0.0692,\n",
       "  'learning_rate': 5.068571428571428e-05,\n",
       "  'epoch': 15.52,\n",
       "  'step': 326},\n",
       " {'loss': 0.0512,\n",
       "  'learning_rate': 5.065714285714286e-05,\n",
       "  'epoch': 15.57,\n",
       "  'step': 327},\n",
       " {'loss': 0.0449,\n",
       "  'learning_rate': 5.062857142857143e-05,\n",
       "  'epoch': 15.62,\n",
       "  'step': 328},\n",
       " {'loss': 0.0375,\n",
       "  'learning_rate': 5.0600000000000003e-05,\n",
       "  'epoch': 15.67,\n",
       "  'step': 329},\n",
       " {'loss': 0.0641,\n",
       "  'learning_rate': 5.057142857142857e-05,\n",
       "  'epoch': 15.71,\n",
       "  'step': 330},\n",
       " {'loss': 0.0472,\n",
       "  'learning_rate': 5.0542857142857144e-05,\n",
       "  'epoch': 15.76,\n",
       "  'step': 331},\n",
       " {'loss': 0.0523,\n",
       "  'learning_rate': 5.051428571428572e-05,\n",
       "  'epoch': 15.81,\n",
       "  'step': 332},\n",
       " {'loss': 0.0439,\n",
       "  'learning_rate': 5.0485714285714284e-05,\n",
       "  'epoch': 15.86,\n",
       "  'step': 333},\n",
       " {'loss': 0.0436,\n",
       "  'learning_rate': 5.0457142857142865e-05,\n",
       "  'epoch': 15.9,\n",
       "  'step': 334},\n",
       " {'loss': 0.0548,\n",
       "  'learning_rate': 5.042857142857143e-05,\n",
       "  'epoch': 15.95,\n",
       "  'step': 335},\n",
       " {'loss': 0.0512, 'learning_rate': 5.04e-05, 'epoch': 16.0, 'step': 336},\n",
       " {'loss': 0.042,\n",
       "  'learning_rate': 5.037142857142857e-05,\n",
       "  'epoch': 16.05,\n",
       "  'step': 337},\n",
       " {'loss': 0.048,\n",
       "  'learning_rate': 5.0342857142857146e-05,\n",
       "  'epoch': 16.1,\n",
       "  'step': 338},\n",
       " {'loss': 0.046,\n",
       "  'learning_rate': 5.031428571428571e-05,\n",
       "  'epoch': 16.14,\n",
       "  'step': 339},\n",
       " {'loss': 0.0415,\n",
       "  'learning_rate': 5.0285714285714286e-05,\n",
       "  'epoch': 16.19,\n",
       "  'step': 340},\n",
       " {'eval_loss': 0.028337061405181885,\n",
       "  'eval_mean_iou': 0.9416629368597839,\n",
       "  'eval_mean_accuracy': 0.9769692468725798,\n",
       "  'eval_overall_accuracy': 0.9976380916326243,\n",
       "  'eval_per_category_iou': [0.9975940434695428, 0.8857318302500249],\n",
       "  'eval_per_category_accuracy': [0.9984617298354773, 0.9554767639096823],\n",
       "  'eval_runtime': 77.5293,\n",
       "  'eval_samples_per_second': 0.671,\n",
       "  'eval_steps_per_second': 0.142,\n",
       "  'epoch': 16.19,\n",
       "  'step': 340},\n",
       " {'loss': 0.0694,\n",
       "  'learning_rate': 5.025714285714286e-05,\n",
       "  'epoch': 16.24,\n",
       "  'step': 341},\n",
       " {'loss': 0.0739,\n",
       "  'learning_rate': 5.0228571428571434e-05,\n",
       "  'epoch': 16.29,\n",
       "  'step': 342},\n",
       " {'loss': 0.0439, 'learning_rate': 5.02e-05, 'epoch': 16.33, 'step': 343},\n",
       " {'loss': 0.0506,\n",
       "  'learning_rate': 5.017142857142857e-05,\n",
       "  'epoch': 16.38,\n",
       "  'step': 344},\n",
       " {'loss': 0.0553,\n",
       "  'learning_rate': 5.014285714285715e-05,\n",
       "  'epoch': 16.43,\n",
       "  'step': 345},\n",
       " {'loss': 0.0485,\n",
       "  'learning_rate': 5.0114285714285715e-05,\n",
       "  'epoch': 16.48,\n",
       "  'step': 346},\n",
       " {'loss': 0.0382,\n",
       "  'learning_rate': 5.008571428571429e-05,\n",
       "  'epoch': 16.52,\n",
       "  'step': 347},\n",
       " {'loss': 0.043,\n",
       "  'learning_rate': 5.005714285714286e-05,\n",
       "  'epoch': 16.57,\n",
       "  'step': 348},\n",
       " {'loss': 0.0412,\n",
       "  'learning_rate': 5.002857142857143e-05,\n",
       "  'epoch': 16.62,\n",
       "  'step': 349},\n",
       " {'loss': 0.0423, 'learning_rate': 5e-05, 'epoch': 16.67, 'step': 350},\n",
       " {'loss': 0.0427,\n",
       "  'learning_rate': 4.997142857142857e-05,\n",
       "  'epoch': 16.71,\n",
       "  'step': 351},\n",
       " {'loss': 0.0427,\n",
       "  'learning_rate': 4.994285714285714e-05,\n",
       "  'epoch': 16.76,\n",
       "  'step': 352},\n",
       " {'loss': 0.0429,\n",
       "  'learning_rate': 4.9914285714285717e-05,\n",
       "  'epoch': 16.81,\n",
       "  'step': 353},\n",
       " {'loss': 0.0445,\n",
       "  'learning_rate': 4.9885714285714283e-05,\n",
       "  'epoch': 16.86,\n",
       "  'step': 354},\n",
       " {'loss': 0.0486,\n",
       "  'learning_rate': 4.9857142857142864e-05,\n",
       "  'epoch': 16.9,\n",
       "  'step': 355},\n",
       " {'loss': 0.0437,\n",
       "  'learning_rate': 4.982857142857143e-05,\n",
       "  'epoch': 16.95,\n",
       "  'step': 356},\n",
       " {'loss': 0.067, 'learning_rate': 4.98e-05, 'epoch': 17.0, 'step': 357},\n",
       " {'loss': 0.0468,\n",
       "  'learning_rate': 4.977142857142857e-05,\n",
       "  'epoch': 17.05,\n",
       "  'step': 358},\n",
       " {'loss': 0.0487,\n",
       "  'learning_rate': 4.9742857142857145e-05,\n",
       "  'epoch': 17.1,\n",
       "  'step': 359},\n",
       " {'loss': 0.0449,\n",
       "  'learning_rate': 4.971428571428572e-05,\n",
       "  'epoch': 17.14,\n",
       "  'step': 360},\n",
       " {'eval_loss': 0.02526102401316166,\n",
       "  'eval_mean_iou': 0.9455209571250429,\n",
       "  'eval_mean_accuracy': 0.972574880971815,\n",
       "  'eval_overall_accuracy': 0.9978330281260271,\n",
       "  'eval_per_category_iou': [0.9977930102776409, 0.8932489039724448],\n",
       "  'eval_per_category_accuracy': [0.9988395466407778, 0.9463102153028522],\n",
       "  'eval_runtime': 76.9079,\n",
       "  'eval_samples_per_second': 0.676,\n",
       "  'eval_steps_per_second': 0.143,\n",
       "  'epoch': 17.14,\n",
       "  'step': 360},\n",
       " {'loss': 0.0393,\n",
       "  'learning_rate': 4.9685714285714285e-05,\n",
       "  'epoch': 17.19,\n",
       "  'step': 361},\n",
       " {'loss': 0.0434,\n",
       "  'learning_rate': 4.965714285714286e-05,\n",
       "  'epoch': 17.24,\n",
       "  'step': 362},\n",
       " {'loss': 0.0385,\n",
       "  'learning_rate': 4.962857142857143e-05,\n",
       "  'epoch': 17.29,\n",
       "  'step': 363},\n",
       " {'loss': 0.0577, 'learning_rate': 4.96e-05, 'epoch': 17.33, 'step': 364},\n",
       " {'loss': 0.0503,\n",
       "  'learning_rate': 4.957142857142857e-05,\n",
       "  'epoch': 17.38,\n",
       "  'step': 365},\n",
       " {'loss': 0.0378,\n",
       "  'learning_rate': 4.954285714285715e-05,\n",
       "  'epoch': 17.43,\n",
       "  'step': 366},\n",
       " {'loss': 0.0353,\n",
       "  'learning_rate': 4.9514285714285714e-05,\n",
       "  'epoch': 17.48,\n",
       "  'step': 367},\n",
       " {'loss': 0.0427,\n",
       "  'learning_rate': 4.948571428571429e-05,\n",
       "  'epoch': 17.52,\n",
       "  'step': 368},\n",
       " {'loss': 0.0564,\n",
       "  'learning_rate': 4.945714285714286e-05,\n",
       "  'epoch': 17.57,\n",
       "  'step': 369},\n",
       " {'loss': 0.0389,\n",
       "  'learning_rate': 4.942857142857143e-05,\n",
       "  'epoch': 17.62,\n",
       "  'step': 370},\n",
       " {'loss': 0.0361, 'learning_rate': 4.94e-05, 'epoch': 17.67, 'step': 371},\n",
       " {'loss': 0.0351,\n",
       "  'learning_rate': 4.9371428571428575e-05,\n",
       "  'epoch': 17.71,\n",
       "  'step': 372},\n",
       " {'loss': 0.0415,\n",
       "  'learning_rate': 4.934285714285715e-05,\n",
       "  'epoch': 17.76,\n",
       "  'step': 373},\n",
       " {'loss': 0.0391,\n",
       "  'learning_rate': 4.9314285714285716e-05,\n",
       "  'epoch': 17.81,\n",
       "  'step': 374},\n",
       " {'loss': 0.0458,\n",
       "  'learning_rate': 4.928571428571428e-05,\n",
       "  'epoch': 17.86,\n",
       "  'step': 375},\n",
       " {'loss': 0.0416,\n",
       "  'learning_rate': 4.925714285714286e-05,\n",
       "  'epoch': 17.9,\n",
       "  'step': 376},\n",
       " {'loss': 0.0376,\n",
       "  'learning_rate': 4.922857142857143e-05,\n",
       "  'epoch': 17.95,\n",
       "  'step': 377},\n",
       " {'loss': 0.0537,\n",
       "  'learning_rate': 4.9199999999999997e-05,\n",
       "  'epoch': 18.0,\n",
       "  'step': 378},\n",
       " {'loss': 0.0558,\n",
       "  'learning_rate': 4.917142857142858e-05,\n",
       "  'epoch': 18.05,\n",
       "  'step': 379},\n",
       " {'loss': 0.0457,\n",
       "  'learning_rate': 4.9142857142857144e-05,\n",
       "  'epoch': 18.1,\n",
       "  'step': 380},\n",
       " {'eval_loss': 0.04560868442058563,\n",
       "  'eval_mean_iou': 0.9450200438639619,\n",
       "  'eval_mean_accuracy': 0.981099174624632,\n",
       "  'eval_overall_accuracy': 0.9977713263605202,\n",
       "  'eval_per_category_iou': [0.9977293957256549, 0.8923106920022689],\n",
       "  'eval_per_category_accuracy': [0.9984356992973176, 0.9637626499519465],\n",
       "  'eval_runtime': 77.1759,\n",
       "  'eval_samples_per_second': 0.674,\n",
       "  'eval_steps_per_second': 0.143,\n",
       "  'epoch': 18.1,\n",
       "  'step': 380},\n",
       " {'loss': 0.042,\n",
       "  'learning_rate': 4.911428571428572e-05,\n",
       "  'epoch': 18.14,\n",
       "  'step': 381},\n",
       " {'loss': 0.0436,\n",
       "  'learning_rate': 4.9085714285714284e-05,\n",
       "  'epoch': 18.19,\n",
       "  'step': 382},\n",
       " {'loss': 0.0432,\n",
       "  'learning_rate': 4.905714285714286e-05,\n",
       "  'epoch': 18.24,\n",
       "  'step': 383},\n",
       " {'loss': 0.0353,\n",
       "  'learning_rate': 4.902857142857143e-05,\n",
       "  'epoch': 18.29,\n",
       "  'step': 384},\n",
       " {'loss': 0.0422, 'learning_rate': 4.9e-05, 'epoch': 18.33, 'step': 385},\n",
       " {'loss': 0.0358,\n",
       "  'learning_rate': 4.897142857142858e-05,\n",
       "  'epoch': 18.38,\n",
       "  'step': 386},\n",
       " {'loss': 0.0352,\n",
       "  'learning_rate': 4.8942857142857146e-05,\n",
       "  'epoch': 18.43,\n",
       "  'step': 387},\n",
       " {'loss': 0.0418,\n",
       "  'learning_rate': 4.891428571428571e-05,\n",
       "  'epoch': 18.48,\n",
       "  'step': 388},\n",
       " {'loss': 0.0393,\n",
       "  'learning_rate': 4.8885714285714286e-05,\n",
       "  'epoch': 18.52,\n",
       "  'step': 389},\n",
       " {'loss': 0.0354,\n",
       "  'learning_rate': 4.885714285714286e-05,\n",
       "  'epoch': 18.57,\n",
       "  'step': 390},\n",
       " {'loss': 0.0364,\n",
       "  'learning_rate': 4.882857142857143e-05,\n",
       "  'epoch': 18.62,\n",
       "  'step': 391},\n",
       " {'loss': 0.0361, 'learning_rate': 4.88e-05, 'epoch': 18.67, 'step': 392},\n",
       " {'loss': 0.0339,\n",
       "  'learning_rate': 4.8771428571428574e-05,\n",
       "  'epoch': 18.71,\n",
       "  'step': 393},\n",
       " {'loss': 0.0348,\n",
       "  'learning_rate': 4.874285714285715e-05,\n",
       "  'epoch': 18.76,\n",
       "  'step': 394},\n",
       " {'loss': 0.0383,\n",
       "  'learning_rate': 4.8714285714285714e-05,\n",
       "  'epoch': 18.81,\n",
       "  'step': 395},\n",
       " {'loss': 0.0378,\n",
       "  'learning_rate': 4.868571428571428e-05,\n",
       "  'epoch': 18.86,\n",
       "  'step': 396},\n",
       " {'loss': 0.035,\n",
       "  'learning_rate': 4.865714285714286e-05,\n",
       "  'epoch': 18.9,\n",
       "  'step': 397},\n",
       " {'loss': 0.0371,\n",
       "  'learning_rate': 4.862857142857143e-05,\n",
       "  'epoch': 18.95,\n",
       "  'step': 398},\n",
       " {'loss': 0.0397, 'learning_rate': 4.86e-05, 'epoch': 19.0, 'step': 399},\n",
       " {'loss': 0.0303,\n",
       "  'learning_rate': 4.8571428571428576e-05,\n",
       "  'epoch': 19.05,\n",
       "  'step': 400},\n",
       " {'eval_loss': 0.03521692007780075,\n",
       "  'eval_mean_iou': 0.9469430985153933,\n",
       "  'eval_mean_accuracy': 0.9846475137031576,\n",
       "  'eval_overall_accuracy': 0.9978425658543457,\n",
       "  'eval_per_category_iou': [0.9978016680888119, 0.8960845289419747],\n",
       "  'eval_per_category_accuracy': [0.9983683789400081, 0.970926648466307],\n",
       "  'eval_runtime': 76.9218,\n",
       "  'eval_samples_per_second': 0.676,\n",
       "  'eval_steps_per_second': 0.143,\n",
       "  'epoch': 19.05,\n",
       "  'step': 400},\n",
       " {'loss': 0.0398,\n",
       "  'learning_rate': 4.854285714285714e-05,\n",
       "  'epoch': 19.1,\n",
       "  'step': 401},\n",
       " {'loss': 0.0408,\n",
       "  'learning_rate': 4.8514285714285716e-05,\n",
       "  'epoch': 19.14,\n",
       "  'step': 402},\n",
       " {'loss': 0.0327,\n",
       "  'learning_rate': 4.848571428571428e-05,\n",
       "  'epoch': 19.19,\n",
       "  'step': 403},\n",
       " {'loss': 0.0304,\n",
       "  'learning_rate': 4.845714285714286e-05,\n",
       "  'epoch': 19.24,\n",
       "  'step': 404},\n",
       " {'loss': 0.0388,\n",
       "  'learning_rate': 4.842857142857143e-05,\n",
       "  'epoch': 19.29,\n",
       "  'step': 405},\n",
       " {'loss': 0.0453, 'learning_rate': 4.84e-05, 'epoch': 19.33, 'step': 406},\n",
       " {'loss': 0.0322,\n",
       "  'learning_rate': 4.837142857142858e-05,\n",
       "  'epoch': 19.38,\n",
       "  'step': 407},\n",
       " {'loss': 0.0339,\n",
       "  'learning_rate': 4.8342857142857145e-05,\n",
       "  'epoch': 19.43,\n",
       "  'step': 408},\n",
       " {'loss': 0.0312,\n",
       "  'learning_rate': 4.831428571428571e-05,\n",
       "  'epoch': 19.48,\n",
       "  'step': 409},\n",
       " {'loss': 0.0474,\n",
       "  'learning_rate': 4.828571428571429e-05,\n",
       "  'epoch': 19.52,\n",
       "  'step': 410},\n",
       " {'loss': 0.0347,\n",
       "  'learning_rate': 4.825714285714286e-05,\n",
       "  'epoch': 19.57,\n",
       "  'step': 411},\n",
       " {'loss': 0.0315,\n",
       "  'learning_rate': 4.822857142857143e-05,\n",
       "  'epoch': 19.62,\n",
       "  'step': 412},\n",
       " {'loss': 0.0519, 'learning_rate': 4.82e-05, 'epoch': 19.67, 'step': 413},\n",
       " {'loss': 0.0369,\n",
       "  'learning_rate': 4.817142857142857e-05,\n",
       "  'epoch': 19.71,\n",
       "  'step': 414},\n",
       " {'loss': 0.0289,\n",
       "  'learning_rate': 4.8142857142857147e-05,\n",
       "  'epoch': 19.76,\n",
       "  'step': 415},\n",
       " {'loss': 0.0385,\n",
       "  'learning_rate': 4.8114285714285713e-05,\n",
       "  'epoch': 19.81,\n",
       "  'step': 416},\n",
       " {'loss': 0.031,\n",
       "  'learning_rate': 4.808571428571429e-05,\n",
       "  'epoch': 19.86,\n",
       "  'step': 417},\n",
       " {'loss': 0.0328,\n",
       "  'learning_rate': 4.805714285714286e-05,\n",
       "  'epoch': 19.9,\n",
       "  'step': 418},\n",
       " {'loss': 0.0341,\n",
       "  'learning_rate': 4.802857142857143e-05,\n",
       "  'epoch': 19.95,\n",
       "  'step': 419},\n",
       " {'loss': 0.0325, 'learning_rate': 4.8e-05, 'epoch': 20.0, 'step': 420},\n",
       " {'eval_loss': 0.03197423368692398,\n",
       "  'eval_mean_iou': 0.9481100681558784,\n",
       "  'eval_mean_accuracy': 0.9855434264433641,\n",
       "  'eval_overall_accuracy': 0.9978915017373339,\n",
       "  'eval_per_category_iou': [0.9978514571051735, 0.8983686792065833],\n",
       "  'eval_per_category_accuracy': [0.9983835634206012, 0.972703289466127],\n",
       "  'eval_runtime': 81.46,\n",
       "  'eval_samples_per_second': 0.638,\n",
       "  'eval_steps_per_second': 0.135,\n",
       "  'epoch': 20.0,\n",
       "  'step': 420},\n",
       " {'train_runtime': 3055.5717,\n",
       "  'train_samples_per_second': 3.436,\n",
       "  'train_steps_per_second': 0.687,\n",
       "  'total_flos': 3.68087065952256e+16,\n",
       "  'train_loss': 0.133953789098277,\n",
       "  'epoch': 20.0,\n",
       "  'step': 420}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model, so that it can be used for inference later.\n",
    "# Save the log history, so that it can be used for plotting later.\n",
    "trainer.save_model('models/' + model_type + '/' + crop)\n",
    "with open('models/' + model_type + '/' + crop + '/log_history.json', 'w') as file:\n",
    "    log_history = trainer.state.log_history\n",
    "    json.dump(log_history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:13<00:00,  6.72s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs = trainer.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:18<00:00,  7.13s/it]\n"
     ]
    }
   ],
   "source": [
    "test_metric = trainer.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.027685143053531647,\n",
       " 'eval_mean_iou': 0.9514935731094303,\n",
       " 'eval_mean_accuracy': 0.9739695790575061,\n",
       " 'eval_overall_accuracy': 0.997216919396627,\n",
       " 'eval_per_category_iou': [0.9971403494393721, 0.9058467967794884],\n",
       " 'eval_per_category_accuracy': [0.99860670276049, 0.9493324553545223],\n",
       " 'eval_runtime': 80.4715,\n",
       " 'eval_samples_per_second': 0.659,\n",
       " 'eval_steps_per_second': 0.137,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1144, 1600)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open('./WE3DS/annotations/segmentation/SegmentationLabel/img_00000.png')\n",
    "image.size[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PredictionOutput' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m upsampled_ouputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49minterpolate(\n\u001b[0;32m      2\u001b[0m     outputs,\n\u001b[0;32m      3\u001b[0m     size\u001b[39m=\u001b[39;49mimage\u001b[39m.\u001b[39;49msize[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[0;32m      4\u001b[0m     mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbilinear\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     align_corners\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m y_pred \u001b[39m=\u001b[39m upsampled_ouputs\u001b[39m.\u001b[39mpredictions\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kate\\AppData\\Local\\miniconda3\\envs\\master\\Lib\\site-packages\\torch\\nn\\functional.py:3856\u001b[0m, in \u001b[0;36minterpolate\u001b[1;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[0;32m   3853\u001b[0m     \u001b[39mif\u001b[39;00m align_corners \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3854\u001b[0m         align_corners \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 3856\u001b[0m dim \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mdim() \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m  \u001b[39m# Number of spatial dimensions.\u001b[39;00m\n\u001b[0;32m   3858\u001b[0m \u001b[39m# Process size and scale_factor.  Validate that exactly one is set.\u001b[39;00m\n\u001b[0;32m   3859\u001b[0m \u001b[39m# Validate its length if it is a list, or expand it if it is a scalar.\u001b[39;00m\n\u001b[0;32m   3860\u001b[0m \u001b[39m# After this block, exactly one of output_size and scale_factors will\u001b[39;00m\n\u001b[0;32m   3861\u001b[0m \u001b[39m# be non-None, and it will be a list (or tuple).\u001b[39;00m\n\u001b[0;32m   3862\u001b[0m \u001b[39mif\u001b[39;00m size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m scale_factor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PredictionOutput' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "# upsampled_ouputs = torch.nn.functional.interpolate(\n",
    "#     outputs,\n",
    "#     size=image.size[::-1],\n",
    "#     mode=\"bilinear\",\n",
    "#     align_corners=False,\n",
    "# )\n",
    "# y_pred = upsampled_ouputs.predictions.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting following unique classes:  [0 1]\n",
      "(53, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting following unique classes: \", np.unique(y_pred))\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AcceleratedOptimizer (\n",
       "Parameter Group 0\n",
       "    betas: (0.9, 0.999)\n",
       "    correct_bias: True\n",
       "    eps: 1e-08\n",
       "    initial_lr: 6e-05\n",
       "    lr: 4.8e-05\n",
       "    weight_decay: 0.0\n",
       "\n",
       "Parameter Group 1\n",
       "    betas: (0.9, 0.999)\n",
       "    correct_bias: True\n",
       "    eps: 1e-08\n",
       "    initial_lr: 6e-05\n",
       "    lr: 4.8e-05\n",
       "    weight_decay: 0.0\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.optimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce GTX 960\n",
      "CUDA version: 11.7\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('CUDA version:', torch.version.cuda)\n",
    "    print('Memory Usage:') \n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/miniconda3/envs/master/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import datasets\n",
    "import evaluate\n",
    "import torch\n",
    "import json\n",
    "import codecs\n",
    "import os\n",
    "from os import sys\n",
    "\n",
    "from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation, TrainingArguments, Trainer, EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('./src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from data_prepossessing import create_datasets_for_plants, get_labels\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/miniconda3/envs/master/lib/python3.11/site-packages/transformers/models/segformer/image_processing_segformer.py:101: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SegformerImageProcessor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_reduce_labels\": false,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"SegformerFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_processor_type\": \"SegformerImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 512,\n",
       "    \"width\": 512\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = \"nvidia/mit-b0\"\n",
    "image_processor = SegformerImageProcessor.from_pretrained(checkpoint)\n",
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transforms(example_batch):\n",
    "    images = [x for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"annotation\"]]\n",
    "    inputs = image_processor(images, labels, return_tensors=\"pt\")\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"mean_iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(num_labels, eval_pred):\n",
    "    with torch.no_grad():\n",
    "        logits, labels = eval_pred\n",
    "        logits_tensor = torch.from_numpy(logits)\n",
    "        logits_tensor = torch.nn.functional.interpolate(\n",
    "            logits_tensor,\n",
    "            size=labels.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        ).argmax(dim=1)\n",
    "\n",
    "        pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "        metrics = metric.compute(\n",
    "            predictions=pred_labels,\n",
    "            references=labels,\n",
    "            num_labels=num_labels,\n",
    "            ignore_index=255,\n",
    "            reduce_labels=False,\n",
    "        )\n",
    "        for key, value in metrics.items():\n",
    "            if type(value) is np.ndarray:\n",
    "                metrics[key] = value.tolist()\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"segformer-b0-scene-parse-150\",\n",
    "    learning_rate=6e-5,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    save_total_limit=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=1,\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_trainer(model, num_labels, train_ds, test_ds) :\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=test_ds,\n",
    "        compute_metrics=lambda eval_pred: compute_metrics(num_labels, eval_pred),\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "\tmodel_type = \"multiclass\"\n",
    "\tcrop = \"broad_bean\" \n",
    "\tid2label, label2id = get_labels(crop, model_type)\n",
    "\treturn AutoModelForSemanticSegmentation.from_pretrained(checkpoint, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigopt_hp_space(trial):\n",
    "    return [\n",
    "        {\"bounds\": {\"min\": 1e-6, \"max\": 1e-4}, \"name\": \"learning_rate\", \"type\": \"double\"}\n",
    "    ]\n",
    "\n",
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "optuna.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_trainer_for_hp_search(num_labels, train_ds, test_ds) :\n",
    "    trainer = Trainer(\n",
    "        model_init=model_init,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=test_ds,\n",
    "        compute_metrics=lambda eval_pred: compute_metrics(num_labels, eval_pred),\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "\n",
    "    best_trial = trainer.hyperparameter_search(\n",
    "        direction=\"minimize\",\n",
    "        backend=\"sigopt\",\n",
    "        hp_space=optuna_hp_space,\n",
    "        n_trials=20,\n",
    "    )\n",
    "\n",
    "    return best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img_00173.png', 'img_00174.png', 'img_00175.png', 'img_00176.png', 'img_00177.png', 'img_00178.png', 'img_00672.png', 'img_00673.png', 'img_00674.png', 'img_00675.png', 'img_00676.png', 'img_00677.png', 'img_00678.png', 'img_00679.png', 'img_00680.png', 'img_00681.png', 'img_00682.png', 'img_00683.png', 'img_00684.png', 'img_00882.png', 'img_00883.png', 'img_00884.png', 'img_00885.png', 'img_00886.png', 'img_00887.png', 'img_00938.png', 'img_00980.png', 'img_00981.png', 'img_00982.png', 'img_00983.png', 'img_00984.png', 'img_00985.png', 'img_00986.png', 'img_00987.png', 'img_00988.png', 'img_00989.png', 'img_01070.png', 'img_01071.png', 'img_01072.png', 'img_01073.png', 'img_01074.png', 'img_01075.png', 'img_01076.png', 'img_01077.png', 'img_01078.png', 'img_01079.png', 'img_01219.png', 'img_01220.png', 'img_01221.png', 'img_01222.png', 'img_01223.png', 'img_01224.png', 'img_01225.png', 'img_01226.png', 'img_01227.png', 'img_01228.png', 'img_01279.png', 'img_01280.png', 'img_01281.png', 'img_01282.png', 'img_01283.png', 'img_01284.png', 'img_01285.png', 'img_01286.png', 'img_01287.png', 'img_01288.png', 'img_01455.png', 'img_01456.png', 'img_01457.png', 'img_01458.png', 'img_01459.png', 'img_01460.png', 'img_01461.png', 'img_01462.png', 'img_01463.png', 'img_01464.png', 'img_01465.png', 'img_01466.png', 'img_01467.png', 'img_01468.png', 'img_01469.png', 'img_01825.png', 'img_01826.png', 'img_01827.png', 'img_01828.png', 'img_01829.png', 'img_01830.png', 'img_01831.png', 'img_01832.png', 'img_01833.png', 'img_01834.png', 'img_01835.png', 'img_01836.png', 'img_01837.png', 'img_01928.png', 'img_01929.png', 'img_01930.png', 'img_01931.png', 'img_01932.png', 'img_01933.png', 'img_01934.png', 'img_01935.png', 'img_01936.png', 'img_01937.png', 'img_01938.png', 'img_01939.png', 'img_01940.png', 'img_01941.png', 'img_01942.png', 'img_01943.png', 'img_01944.png', 'img_01945.png', 'img_01946.png', 'img_01947.png', 'img_01948.png', 'img_01949.png', 'img_01950.png', 'img_01951.png', 'img_01952.png', 'img_01953.png', 'img_01954.png', 'img_01955.png', 'img_02099.png', 'img_02100.png', 'img_02101.png', 'img_02102.png', 'img_02103.png', 'img_02104.png', 'img_02105.png', 'img_02106.png', 'img_02107.png', 'img_02108.png', 'img_02109.png', 'img_02110.png', 'img_02111.png', 'img_02112.png', 'img_02113.png', 'img_02114.png', 'img_02115.png', 'img_02116.png', 'img_02117.png', 'img_02118.png', 'img_02119.png', 'img_02120.png', 'img_02121.png', 'img_02122.png', 'img_02123.png', 'img_02124.png', 'img_02125.png', 'img_02126.png', 'img_02127.png', 'img_02128.png', 'img_02129.png', 'img_02130.png', 'img_02131.png', 'img_02132.png', 'img_02133.png', 'img_02134.png', 'img_02135.png', 'img_02136.png', 'img_02137.png', 'img_02138.png', 'img_02139.png', 'img_02140.png', 'img_02348.png', 'img_02349.png', 'img_02350.png', 'img_02351.png', 'img_02352.png', 'img_02353.png', 'img_02354.png', 'img_02355.png', 'img_02356.png', 'img_02357.png', 'img_02358.png', 'img_02359.png', 'img_02360.png', 'img_02361.png', 'img_02362.png', 'img_02363.png', 'img_02364.png', 'img_02365.png', 'img_02366.png', 'img_02367.png', 'img_02368.png', 'img_02369.png', 'img_02370.png', 'img_02371.png', 'img_02372.png', 'img_02373.png', 'img_02374.png', 'img_02375.png', 'img_02376.png', 'img_02377.png', 'img_02378.png', 'img_02379.png', 'img_02380.png', 'img_02381.png', 'img_02382.png', 'img_02383.png', 'img_02384.png', 'img_02385.png', 'img_02543.png', 'img_02544.png', 'img_02545.png', 'img_02546.png', 'img_02547.png', 'img_02548.png', 'img_02549.png', 'img_02550.png']\n",
      "Number of plant images for plant broad_bean : 210\n",
      "['img_01804.png', 'img_01807.png', 'img_01790.png', 'img_01803.png', 'img_01793.png', 'img_01797.png', 'img_01798.png', 'img_01796.png', 'img_01799.png', 'img_01795.png', 'img_01791.png', 'img_01802.png', 'img_01806.png', 'img_01789.png', 'img_01805.png', 'img_01800.png', 'img_01794.png', 'img_01801.png', 'img_01792.png', 'img_01788.png']\n",
      "Number of plant images for plant corn_spurry : 20\n",
      "['img_01768.png', 'img_01767.png', 'img_01796.png']\n",
      "Number of plant images for plant red-root_amaranth : 3\n",
      "['img_01812.png', 'img_01809.png', 'img_01815.png', 'img_01810.png', 'img_01808.png', 'img_01813.png', 'img_01814.png', 'img_01811.png']\n",
      "Number of plant images for plant red_fingergrass : 8\n",
      "['img_00434.png', 'img_00203.png', 'img_00424.png', 'img_00717.png', 'img_00657.png', 'img_00430.png', 'img_00715.png', 'img_00420.png', 'img_00658.png', 'img_00209.png', 'img_00659.png', 'img_00419.png', 'img_00709.png', 'img_00713.png', 'img_00206.png', 'img_00429.png', 'img_00712.png', 'img_00421.png', 'img_00710.png', 'img_00204.png', 'img_00431.png', 'img_00435.png', 'img_00208.png', 'img_00714.png', 'img_00716.png']\n",
      "Number of plant images for plant common_wild_oat : 25\n",
      "['img_00618.png', 'img_00078.png', 'img_00612.png', 'img_01764.png', 'img_01195.png', 'img_01271.png', 'img_00447.png', 'img_01762.png', 'img_00856.png', 'img_00613.png', 'img_00223.png', 'img_01198.png', 'img_01758.png', 'img_00373.png', 'img_01189.png', 'img_00614.png', 'img_01264.png', 'img_01192.png', 'img_01266.png', 'img_01270.png', 'img_00804.png', 'img_00569.png', 'img_01753.png', 'img_00374.png', 'img_00959.png', 'img_00364.png', 'img_01751.png', 'img_00620.png', 'img_01048.png', 'img_00857.png', 'img_00936.png', 'img_01196.png', 'img_01191.png', 'img_01143.png', 'img_00810.png', 'img_01752.png', 'img_00359.png', 'img_01871.png', 'img_00558.png', 'img_01263.png', 'img_00376.png', 'img_00450.png', 'img_00122.png', 'img_00858.png', 'img_00362.png', 'img_01194.png', 'img_00952.png', 'img_00378.png', 'img_01262.png', 'img_01755.png', 'img_00076.png', 'img_00954.png', 'img_00617.png', 'img_00371.png', 'img_00609.png', 'img_00118.png', 'img_00950.png', 'img_01197.png', 'img_00228.png', 'img_01754.png', 'img_00957.png', 'img_00457.png', 'img_01042.png', 'img_00466.png', 'img_00821.png', 'img_00465.png', 'img_00956.png', 'img_00073.png', 'img_00219.png', 'img_00556.png', 'img_00372.png', 'img_00224.png', 'img_01193.png', 'img_00367.png', 'img_01767.png', 'img_00608.png', 'img_01147.png', 'img_00079.png', 'img_00081.png', 'img_00368.png', 'img_01044.png', 'img_01259.png', 'img_00365.png', 'img_00082.png', 'img_00069.png', 'img_00859.png', 'img_01260.png', 'img_01190.png', 'img_01268.png', 'img_00448.png', 'img_01045.png', 'img_00440.png', 'img_00363.png', 'img_00369.png', 'img_00726.png', 'img_00452.png', 'img_00955.png', 'img_01148.png', 'img_00555.png', 'img_00812.png', 'img_01040.png', 'img_00370.png', 'img_00953.png', 'img_00222.png', 'img_01146.png', 'img_00123.png', 'img_01763.png', 'img_00075.png', 'img_00068.png', 'img_00449.png', 'img_01765.png', 'img_01766.png', 'img_00451.png', 'img_00907.png', 'img_01768.png', 'img_00456.png', 'img_01142.png', 'img_00377.png', 'img_00619.png', 'img_00611.png', 'img_00077.png', 'img_01759.png', 'img_01761.png', 'img_00360.png', 'img_01041.png', 'img_00086.png', 'img_01750.png', 'img_00951.png', 'img_01141.png', 'img_00561.png', 'img_00375.png', 'img_00615.png', 'img_00855.png', 'img_01046.png', 'img_01043.png', 'img_01757.png', 'img_00121.png', 'img_01049.png', 'img_01873.png', 'img_00454.png', 'img_00958.png', 'img_01756.png', 'img_01265.png', 'img_01145.png', 'img_01140.png', 'img_01760.png', 'img_01047.png', 'img_01267.png', 'img_00361.png', 'img_01877.png', 'img_00366.png', 'img_00811.png', 'img_00080.png', 'img_01261.png', 'img_00729.png', 'img_00070.png', 'img_00116.png', 'img_00567.png', 'img_00610.png', 'img_00616.png', 'img_00225.png', 'img_01144.png']\n",
      "Number of plant images for plant cornflower : 162\n",
      "['img_01993.png', 'img_00753.png', 'img_01719.png', 'img_01714.png', 'img_01348.png', 'img_01724.png', 'img_01128.png', 'img_02000.png', 'img_02001.png', 'img_00622.png', 'img_00636.png', 'img_01129.png', 'img_01104.png', 'img_01123.png', 'img_01109.png', 'img_01593.png', 'img_00759.png', 'img_01636.png', 'img_02194.png', 'img_00621.png', 'img_01633.png', 'img_01126.png', 'img_01249.png', 'img_01718.png', 'img_01251.png', 'img_01709.png', 'img_01349.png', 'img_01599.png', 'img_02490.png', 'img_02008.png', 'img_01256.png', 'img_01998.png', 'img_01175.png', 'img_02009.png', 'img_02492.png', 'img_00634.png', 'img_01721.png', 'img_01990.png', 'img_01997.png', 'img_02198.png', 'img_02495.png', 'img_01648.png', 'img_02193.png', 'img_01629.png', 'img_00627.png', 'img_01601.png', 'img_01992.png', 'img_01170.png', 'img_02012.png', 'img_00628.png', 'img_01580.png', 'img_01598.png', 'img_01177.png', 'img_00755.png', 'img_02203.png', 'img_01634.png', 'img_01632.png', 'img_02192.png', 'img_01005.png', 'img_02010.png', 'img_00626.png', 'img_01644.png', 'img_02005.png', 'img_01725.png', 'img_00639.png', 'img_00861.png', 'img_02190.png', 'img_00494.png', 'img_00863.png', 'img_01642.png', 'img_01647.png', 'img_02204.png', 'img_02202.png', 'img_01101.png', 'img_01720.png', 'img_01995.png', 'img_01646.png', 'img_00501.png', 'img_00270.png', 'img_01001.png', 'img_02011.png', 'img_01176.png', 'img_01246.png', 'img_00862.png', 'img_01102.png', 'img_01105.png', 'img_02195.png', 'img_02494.png', 'img_01108.png', 'img_01171.png', 'img_01637.png', 'img_00630.png', 'img_01178.png', 'img_02002.png', 'img_00631.png', 'img_01173.png', 'img_00272.png', 'img_01172.png', 'img_00262.png', 'img_00632.png', 'img_00758.png', 'img_00768.png', 'img_01258.png', 'img_01641.png', 'img_00866.png', 'img_01354.png', 'img_00624.png', 'img_00635.png', 'img_01723.png', 'img_02493.png', 'img_01125.png', 'img_01645.png', 'img_01711.png', 'img_02191.png', 'img_01722.png', 'img_00770.png', 'img_00918.png', 'img_02003.png', 'img_00864.png', 'img_01994.png', 'img_01999.png', 'img_00867.png', 'img_01004.png', 'img_01107.png', 'img_01120.png', 'img_01252.png', 'img_01631.png', 'img_01006.png', 'img_01643.png', 'img_00629.png', 'img_00637.png', 'img_01638.png', 'img_01121.png', 'img_01710.png', 'img_02491.png', 'img_01124.png', 'img_01174.png', 'img_01639.png', 'img_01003.png', 'img_00503.png', 'img_01570.png', 'img_01715.png', 'img_00633.png', 'img_01253.png', 'img_00623.png', 'img_01356.png', 'img_01103.png', 'img_01000.png', 'img_00493.png', 'img_01002.png', 'img_02196.png', 'img_00756.png', 'img_01008.png', 'img_01712.png', 'img_01169.png', 'img_01243.png', 'img_01009.png', 'img_01122.png', 'img_02004.png', 'img_00261.png', 'img_00865.png', 'img_01713.png', 'img_01250.png', 'img_01592.png', 'img_02006.png', 'img_02201.png', 'img_01257.png', 'img_01127.png', 'img_02197.png', 'img_01989.png', 'img_01594.png', 'img_02489.png', 'img_01106.png', 'img_01254.png', 'img_01630.png', 'img_01596.png', 'img_00860.png', 'img_01640.png', 'img_01635.png', 'img_00638.png', 'img_00263.png', 'img_01717.png', 'img_00625.png', 'img_01255.png', 'img_00252.png', 'img_00253.png', 'img_01597.png', 'img_00750.png', 'img_01716.png', 'img_00492.png', 'img_01595.png', 'img_00752.png', 'img_01007.png', 'img_01100.png', 'img_01600.png', 'img_01996.png', 'img_02199.png', 'img_02007.png', 'img_02200.png', 'img_01991.png']\n",
      "Number of plant images for plant corn_cockle : 200\n",
      "['img_02477.png', 'img_02225.png', 'img_01702.png', 'img_01605.png', 'img_02214.png', 'img_02499.png', 'img_01619.png', 'img_01626.png', 'img_01858.png', 'img_01662.png', 'img_01682.png', 'img_02025.png', 'img_02213.png', 'img_01024.png', 'img_01745.png', 'img_01856.png', 'img_02470.png', 'img_01610.png', 'img_01021.png', 'img_02020.png', 'img_01733.png', 'img_01665.png', 'img_01660.png', 'img_02022.png', 'img_01863.png', 'img_02029.png', 'img_01670.png', 'img_01611.png', 'img_02224.png', 'img_01620.png', 'img_02015.png', 'img_02014.png', 'img_02027.png', 'img_01861.png', 'img_02021.png', 'img_01537.png', 'img_02496.png', 'img_01739.png', 'img_02497.png', 'img_02222.png', 'img_01669.png', 'img_02220.png', 'img_01731.png', 'img_02023.png', 'img_02500.png', 'img_01732.png', 'img_01025.png', 'img_01741.png', 'img_01740.png', 'img_01027.png', 'img_01699.png', 'img_01022.png', 'img_02215.png', 'img_02221.png', 'img_02476.png', 'img_01608.png', 'img_01707.png', 'img_02219.png', 'img_01744.png', 'img_01748.png', 'img_01625.png', 'img_02211.png', 'img_01737.png', 'img_02024.png', 'img_01543.png', 'img_01623.png', 'img_01627.png', 'img_01559.png', 'img_01747.png', 'img_01729.png', 'img_01602.png', 'img_01689.png', 'img_02216.png', 'img_02502.png', 'img_02488.png', 'img_01618.png', 'img_02207.png', 'img_02212.png', 'img_01651.png', 'img_02483.png', 'img_02223.png', 'img_02013.png', 'img_02454.png', 'img_01612.png', 'img_02228.png', 'img_01661.png', 'img_01742.png', 'img_02026.png', 'img_02018.png', 'img_01656.png', 'img_01730.png', 'img_02229.png', 'img_01604.png', 'img_01617.png', 'img_01726.png', 'img_02498.png', 'img_02218.png', 'img_01606.png', 'img_01653.png', 'img_01654.png', 'img_01734.png', 'img_02501.png', 'img_01650.png', 'img_01603.png', 'img_01613.png', 'img_01659.png', 'img_01749.png', 'img_01026.png', 'img_01607.png', 'img_01668.png', 'img_02030.png', 'img_01743.png', 'img_01609.png', 'img_01614.png', 'img_01663.png', 'img_01649.png', 'img_01622.png', 'img_02017.png', 'img_02208.png', 'img_02205.png', 'img_02217.png', 'img_01628.png', 'img_01738.png', 'img_01701.png', 'img_01736.png', 'img_01616.png', 'img_01652.png', 'img_02019.png', 'img_01615.png', 'img_02210.png', 'img_01664.png', 'img_01666.png', 'img_01023.png', 'img_02453.png', 'img_02028.png', 'img_01667.png', 'img_02226.png', 'img_01624.png', 'img_01028.png', 'img_02227.png', 'img_01735.png', 'img_02016.png', 'img_01621.png', 'img_01658.png', 'img_01728.png', 'img_01746.png', 'img_01020.png', 'img_01727.png', 'img_01655.png', 'img_01706.png', 'img_02209.png', 'img_01029.png', 'img_02206.png', 'img_01657.png']\n",
      "Number of plant images for plant milk_thistle : 154\n",
      "['img_01774.png', 'img_01777.png', 'img_01776.png', 'img_00937.png', 'img_01773.png', 'img_01278.png', 'img_01050.png', 'img_01271.png', 'img_01149.png', 'img_00964.png', 'img_01154.png', 'img_00963.png', 'img_00967.png', 'img_01202.png', 'img_01200.png', 'img_01272.png', 'img_01775.png', 'img_01056.png', 'img_01769.png', 'img_01201.png', 'img_01052.png', 'img_01053.png', 'img_01206.png', 'img_01057.png', 'img_00968.png', 'img_01208.png', 'img_01276.png', 'img_01771.png', 'img_01151.png', 'img_00960.png', 'img_01156.png', 'img_01270.png', 'img_00965.png', 'img_01772.png', 'img_01205.png', 'img_01203.png', 'img_01274.png', 'img_01269.png', 'img_01199.png', 'img_01157.png', 'img_01770.png', 'img_01153.png', 'img_01277.png', 'img_01055.png', 'img_01059.png', 'img_01273.png', 'img_01204.png', 'img_01275.png', 'img_01058.png', 'img_01152.png', 'img_01054.png', 'img_00966.png', 'img_01158.png', 'img_01207.png', 'img_00969.png', 'img_01155.png', 'img_00961.png', 'img_00962.png', 'img_01051.png', 'img_01150.png']\n",
      "Number of plant images for plant rye_brome : 60\n",
      "['img_01804.png', 'img_00652.png', 'img_00643.png', 'img_00649.png', 'img_00650.png', 'img_01787.png', 'img_01778.png', 'img_01785.png', 'img_01806.png', 'img_00651.png', 'img_01786.png', 'img_00645.png', 'img_00646.png', 'img_00644.png', 'img_01779.png', 'img_01781.png', 'img_00647.png', 'img_01782.png', 'img_01784.png', 'img_00648.png', 'img_01783.png', 'img_01780.png']\n",
      "Number of plant images for plant narrow-leaved_plantain : 22\n",
      "['img_00348.png', 'img_00546.png', 'img_00603.png', 'img_00342.png', 'img_00536.png', 'img_00606.png', 'img_00476.png', 'img_00528.png', 'img_00736.png', 'img_00469.png', 'img_00854.png', 'img_00482.png', 'img_00479.png', 'img_00148.png', 'img_00597.png', 'img_00542.png', 'img_00345.png', 'img_00146.png', 'img_00474.png', 'img_00796.png', 'img_00601.png', 'img_00797.png', 'img_00343.png', 'img_00529.png', 'img_00600.png', 'img_00357.png', 'img_00605.png', 'img_00147.png', 'img_00351.png', 'img_00341.png', 'img_00602.png', 'img_00908.png', 'img_00346.png', 'img_00532.png', 'img_00599.png', 'img_00486.png', 'img_00737.png', 'img_00349.png', 'img_00547.png', 'img_00742.png', 'img_00145.png', 'img_00344.png', 'img_00347.png', 'img_00350.png', 'img_00914.png', 'img_00852.png', 'img_00598.png', 'img_00149.png', 'img_00477.png', 'img_00096.png', 'img_00791.png', 'img_00468.png', 'img_00604.png', 'img_00607.png', 'img_00596.png', 'img_00595.png', 'img_00545.png', 'img_00478.png', 'img_00352.png', 'img_00353.png', 'img_00356.png', 'img_00745.png', 'img_00467.png', 'img_00358.png', 'img_00355.png', 'img_00853.png', 'img_00851.png', 'img_00354.png', 'img_00480.png', 'img_00850.png', 'img_00144.png', 'img_00150.png']\n",
      "Number of plant images for plant small-flower_geranium : 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.2.proj.weight', 'decode_head.classifier.weight', 'decode_head.linear_fuse.weight', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.bias', 'decode_head.batch_norm.weight', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.2.proj.bias', 'decode_head.classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'suggest_float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/kate/dev/master_thesis/03_segformer.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m id2label, label2id \u001b[39m=\u001b[39m get_labels(crop, model_type)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# model = model_init(id2label, label2id)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m best_trial \u001b[39m=\u001b[39m initialize_trainer_for_hp_search(\u001b[39mlen\u001b[39;49m(id2label), train_ds, val_ds)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m best_trial\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# trainer.train()\u001b[39;00m\n",
      "\u001b[1;32m/home/kate/dev/master_thesis/03_segformer.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minitialize_trainer_for_hp_search\u001b[39m(num_labels, train_ds, test_ds) :\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         model_init\u001b[39m=\u001b[39mmodel_init,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         callbacks\u001b[39m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     best_trial \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mhyperparameter_search(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         direction\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mminimize\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         backend\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msigopt\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         hp_space\u001b[39m=\u001b[39;49moptuna_hp_space,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         n_trials\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m best_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.11/site-packages/transformers/trainer.py:2575\u001b[0m, in \u001b[0;36mTrainer.hyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m   2572\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhp_name \u001b[39m=\u001b[39m hp_name\n\u001b[1;32m   2573\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_objective \u001b[39m=\u001b[39m default_compute_objective \u001b[39mif\u001b[39;00m compute_objective \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m compute_objective\n\u001b[0;32m-> 2575\u001b[0m best_run \u001b[39m=\u001b[39m backend_obj\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m, n_trials, direction, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2577\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhp_search_backend \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2578\u001b[0m \u001b[39mreturn\u001b[39;00m best_run\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.11/site-packages/transformers/hyperparameter_search.py:101\u001b[0m, in \u001b[0;36mSigOptBackend.run\u001b[0;34m(self, trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, trainer, n_trials: \u001b[39mint\u001b[39m, direction: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 101\u001b[0m     \u001b[39mreturn\u001b[39;00m run_hp_search_sigopt(trainer, n_trials, direction, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.11/site-packages/transformers/integrations/integration_utils.py:377\u001b[0m, in \u001b[0;36mrun_hp_search_sigopt\u001b[0;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mif\u001b[39;00m importlib\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mversion(\u001b[39m\"\u001b[39m\u001b[39msigopt\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m8.0.0\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    372\u001b[0m     sigopt\u001b[39m.\u001b[39mset_project(\u001b[39m\"\u001b[39m\u001b[39mhuggingface\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    374\u001b[0m     experiment \u001b[39m=\u001b[39m sigopt\u001b[39m.\u001b[39mcreate_experiment(\n\u001b[1;32m    375\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhuggingface-tune\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    376\u001b[0m         \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moffline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m--> 377\u001b[0m         parameters\u001b[39m=\u001b[39mtrainer\u001b[39m.\u001b[39;49mhp_space(\u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    378\u001b[0m         metrics\u001b[39m=\u001b[39m[{\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m: direction, \u001b[39m\"\u001b[39m\u001b[39mstrategy\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39moptimize\u001b[39m\u001b[39m\"\u001b[39m}],\n\u001b[1;32m    379\u001b[0m         parallel_bandwidth\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    380\u001b[0m         budget\u001b[39m=\u001b[39mn_trials,\n\u001b[1;32m    381\u001b[0m     )\n\u001b[1;32m    383\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcreated experiment: https://app.sigopt.com/experiment/\u001b[39m\u001b[39m{\u001b[39;00mexperiment\u001b[39m.\u001b[39mid\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    385\u001b[0m     \u001b[39mfor\u001b[39;00m run \u001b[39min\u001b[39;00m experiment\u001b[39m.\u001b[39mloop():\n",
      "\u001b[1;32m/home/kate/dev/master_thesis/03_segformer.ipynb Cell 15\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptuna_hp_space\u001b[39m(trial):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m\"\u001b[39m: trial\u001b[39m.\u001b[39;49msuggest_float(\u001b[39m\"\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1e-6\u001b[39m, \u001b[39m1e-4\u001b[39m, log\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'suggest_float'"
     ]
    }
   ],
   "source": [
    "model_type = \"multiclass\"\n",
    "crop = \"broad_bean\" \n",
    "model_plant_names = [crop] + weed_plants\n",
    "train_ds, val_ds, test_ds = create_datasets_for_plants(model_plant_names, model_type, crop)\n",
    "\n",
    "train_ds.set_transform(train_transforms)\n",
    "val_ds.set_transform(train_transforms)\n",
    "test_ds.set_transform(train_transforms)\n",
    "\n",
    "id2label, label2id = get_labels(crop, model_type)\n",
    "\n",
    "# model = model_init(id2label, label2id)\n",
    "best_trial = initialize_trainer_for_hp_search(len(id2label), train_ds, val_ds)\n",
    "best_trial\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_of_type_for_crop(model_type, crop):\n",
    "    model_plant_names = [crop] + weed_plants\n",
    "    train_ds, val_ds, test_ds = create_datasets_for_plants(model_plant_names, model_type, crop)\n",
    "\n",
    "    print(\"Training subset number of images: \" + str(train_ds.num_rows))\n",
    "    print(\"Validation subset number of images: \" + str(val_ds.num_rows))\n",
    "    print(\"Test subset number of images: \" + str(test_ds.num_rows))\n",
    "\n",
    "    train_ds.set_transform(train_transforms)\n",
    "    val_ds.set_transform(train_transforms)\n",
    "    test_ds.set_transform(train_transforms)\n",
    "\n",
    "    id2label, label2id = get_labels(crop, model_type)\n",
    "\n",
    "    print('Number of classes:', len(id2label))\n",
    "    print('id2label:', id2label)\n",
    "    print('label2id:', label2id)\n",
    "\n",
    "    model = AutoModelForSemanticSegmentation.from_pretrained(checkpoint, id2label=id2label, label2id=label2id)\n",
    "    trainer = initialize_trainer(model, len(id2label), train_ds, val_ds)\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the trained model, so that it can be used for inference later.\n",
    "    # Save the log history, so that it can be used for plotting later.\n",
    "    trainer.save_model('models/' + model_type + '/' + crop)\n",
    "    with open('models/' + model_type + '/' + crop + '/log_history.json', 'w') as file:\n",
    "        log_history = trainer.state.log_history\n",
    "        json.dump(log_history, file)\n",
    "\n",
    "    test_metric = trainer.evaluate(test_ds)\n",
    "    test_metric\n",
    "\n",
    "    with open('models/' + model_type + '/' + crop + '/test_metric.json', 'w') as file:\n",
    "        json.dump(test_metric, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img_00071.png', 'img_00072.png', 'img_00074.png', 'img_00083.png', 'img_00084.png', 'img_00085.png', 'img_00151.png', 'img_00152.png', 'img_00153.png', 'img_00154.png', 'img_00155.png', 'img_00156.png', 'img_00210.png', 'img_00211.png', 'img_00212.png', 'img_00213.png', 'img_00214.png', 'img_00215.png', 'img_00216.png', 'img_00217.png', 'img_00218.png', 'img_00220.png', 'img_00221.png', 'img_00226.png', 'img_00227.png', 'img_00229.png', 'img_00248.png', 'img_00249.png', 'img_00250.png', 'img_00251.png', 'img_00254.png', 'img_00255.png', 'img_00256.png', 'img_00257.png', 'img_00258.png', 'img_00259.png', 'img_00260.png', 'img_00264.png', 'img_00265.png', 'img_00266.png', 'img_00267.png', 'img_00268.png', 'img_00269.png', 'img_00271.png', 'img_00293.png', 'img_00294.png', 'img_00295.png', 'img_00296.png', 'img_00297.png', 'img_00298.png', 'img_00299.png', 'img_00300.png', 'img_00301.png', 'img_00302.png', 'img_00303.png', 'img_00379.png', 'img_00380.png', 'img_00381.png', 'img_00382.png', 'img_00383.png', 'img_00384.png', 'img_00385.png', 'img_00386.png', 'img_00387.png', 'img_00388.png', 'img_00389.png', 'img_00390.png', 'img_00391.png', 'img_00436.png', 'img_00437.png', 'img_00438.png', 'img_00439.png', 'img_00441.png', 'img_00442.png', 'img_00443.png', 'img_00444.png', 'img_00445.png', 'img_00446.png', 'img_00453.png', 'img_00455.png', 'img_00458.png', 'img_00459.png', 'img_00460.png', 'img_00461.png', 'img_00462.png', 'img_00463.png', 'img_00464.png', 'img_00489.png', 'img_00490.png', 'img_00491.png', 'img_00495.png', 'img_00496.png', 'img_00497.png', 'img_00498.png', 'img_00499.png', 'img_00500.png', 'img_00502.png', 'img_00525.png', 'img_00526.png', 'img_00527.png', 'img_00530.png', 'img_00531.png', 'img_00533.png', 'img_00534.png', 'img_00535.png', 'img_00537.png', 'img_00538.png', 'img_00539.png', 'img_00540.png', 'img_00541.png', 'img_00543.png', 'img_00544.png', 'img_00583.png', 'img_00584.png', 'img_00585.png', 'img_00586.png', 'img_00587.png', 'img_00588.png', 'img_00589.png', 'img_00590.png', 'img_00591.png', 'img_00592.png', 'img_00593.png', 'img_00660.png', 'img_00661.png', 'img_00662.png', 'img_00663.png', 'img_00664.png', 'img_00665.png', 'img_00666.png', 'img_00667.png', 'img_00668.png', 'img_00669.png', 'img_00670.png', 'img_00671.png', 'img_00718.png', 'img_00719.png', 'img_00720.png', 'img_00721.png', 'img_00722.png', 'img_00723.png', 'img_00724.png', 'img_00725.png', 'img_00727.png', 'img_00728.png', 'img_00730.png', 'img_00731.png', 'img_00732.png', 'img_00733.png', 'img_00734.png', 'img_00735.png', 'img_00746.png', 'img_00747.png', 'img_00748.png', 'img_00749.png', 'img_00751.png', 'img_00754.png', 'img_00757.png', 'img_00760.png', 'img_00761.png', 'img_00762.png', 'img_00763.png', 'img_00764.png', 'img_00765.png', 'img_00766.png', 'img_00767.png', 'img_00769.png', 'img_00789.png', 'img_00790.png', 'img_00792.png', 'img_00793.png', 'img_00794.png', 'img_00795.png', 'img_00798.png', 'img_00799.png', 'img_00800.png', 'img_00801.png', 'img_00802.png', 'img_00835.png', 'img_00836.png', 'img_00837.png', 'img_00839.png', 'img_00840.png', 'img_00842.png', 'img_00843.png', 'img_00844.png', 'img_00846.png', 'img_00874.png', 'img_00875.png', 'img_00876.png', 'img_00877.png', 'img_00878.png', 'img_00879.png', 'img_00880.png', 'img_00881.png', 'img_00901.png', 'img_00902.png', 'img_00903.png', 'img_00904.png', 'img_00905.png', 'img_00906.png', 'img_00915.png', 'img_00916.png', 'img_00917.png', 'img_00919.png', 'img_00920.png', 'img_00921.png', 'img_00922.png', 'img_00923.png', 'img_00924.png', 'img_00970.png', 'img_00971.png', 'img_00972.png', 'img_00973.png', 'img_00974.png', 'img_00975.png', 'img_00976.png', 'img_00977.png', 'img_00978.png', 'img_00979.png', 'img_01060.png', 'img_01061.png', 'img_01062.png', 'img_01063.png', 'img_01064.png', 'img_01065.png', 'img_01066.png', 'img_01067.png', 'img_01068.png', 'img_01069.png', 'img_01110.png', 'img_01111.png', 'img_01112.png', 'img_01113.png', 'img_01114.png', 'img_01115.png', 'img_01116.png', 'img_01117.png', 'img_01118.png', 'img_01119.png', 'img_01159.png', 'img_01160.png', 'img_01161.png', 'img_01162.png', 'img_01163.png', 'img_01164.png', 'img_01165.png', 'img_01166.png', 'img_01167.png', 'img_01168.png', 'img_01209.png', 'img_01210.png', 'img_01211.png', 'img_01212.png', 'img_01213.png', 'img_01214.png', 'img_01215.png', 'img_01216.png', 'img_01217.png', 'img_01218.png', 'img_01239.png', 'img_01240.png', 'img_01241.png', 'img_01242.png', 'img_01244.png', 'img_01245.png', 'img_01247.png', 'img_01248.png', 'img_01289.png', 'img_01290.png', 'img_01291.png', 'img_01292.png', 'img_01293.png', 'img_01294.png', 'img_01295.png', 'img_01296.png', 'img_01297.png', 'img_01298.png', 'img_01378.png', 'img_01379.png', 'img_01380.png', 'img_01381.png', 'img_01382.png', 'img_01383.png', 'img_01384.png', 'img_01385.png', 'img_01386.png', 'img_01387.png', 'img_01388.png', 'img_01389.png', 'img_01390.png', 'img_01391.png', 'img_01392.png', 'img_01393.png', 'img_01394.png', 'img_01395.png', 'img_01816.png', 'img_01817.png', 'img_01818.png', 'img_01819.png', 'img_01820.png', 'img_01865.png', 'img_01866.png', 'img_01867.png', 'img_01868.png', 'img_01869.png', 'img_01870.png', 'img_02068.png', 'img_02069.png', 'img_02070.png', 'img_02071.png', 'img_02072.png', 'img_02073.png', 'img_02074.png', 'img_02256.png', 'img_02257.png', 'img_02258.png', 'img_02259.png', 'img_02260.png', 'img_02261.png', 'img_02262.png', 'img_02263.png', 'img_02264.png', 'img_02265.png', 'img_02266.png', 'img_02267.png', 'img_02268.png', 'img_02269.png', 'img_02270.png', 'img_02271.png', 'img_02272.png', 'img_02273.png', 'img_02274.png', 'img_02275.png', 'img_02276.png', 'img_02277.png', 'img_02278.png', 'img_02279.png', 'img_02280.png', 'img_02281.png', 'img_02282.png', 'img_02283.png', 'img_02284.png', 'img_02285.png', 'img_02286.png', 'img_02287.png', 'img_02288.png', 'img_02289.png', 'img_02290.png', 'img_02291.png', 'img_02292.png', 'img_02293.png', 'img_02294.png', 'img_02446.png', 'img_02447.png', 'img_02448.png', 'img_02449.png', 'img_02450.png', 'img_02451.png', 'img_02452.png', 'img_02455.png', 'img_02456.png', 'img_02457.png', 'img_02458.png', 'img_02459.png', 'img_02460.png', 'img_02461.png', 'img_02462.png', 'img_02463.png', 'img_02464.png', 'img_02465.png', 'img_02466.png', 'img_02467.png', 'img_02468.png', 'img_02469.png', 'img_02471.png', 'img_02472.png', 'img_02473.png', 'img_02474.png', 'img_02475.png', 'img_02478.png', 'img_02479.png', 'img_02480.png', 'img_02481.png', 'img_02482.png', 'img_02484.png', 'img_02485.png', 'img_02486.png', 'img_02487.png', 'img_02503.png', 'img_02504.png', 'img_02505.png', 'img_02506.png', 'img_02507.png', 'img_02508.png', 'img_02509.png', 'img_02510.png', 'img_02511.png', 'img_02512.png', 'img_02513.png', 'img_02514.png', 'img_02515.png', 'img_02516.png', 'img_02517.png', 'img_02555.png', 'img_02556.png', 'img_02557.png', 'img_02558.png', 'img_02559.png', 'img_02560.png']\n",
      "Number of plant images for plant sugar_beet : 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img_01804.png', 'img_01807.png', 'img_01790.png', 'img_01803.png', 'img_01793.png', 'img_01797.png', 'img_01798.png', 'img_01796.png', 'img_01799.png', 'img_01795.png', 'img_01791.png', 'img_01802.png', 'img_01806.png', 'img_01789.png', 'img_01805.png', 'img_01800.png', 'img_01794.png', 'img_01801.png', 'img_01792.png', 'img_01788.png']\n",
      "Number of plant images for plant corn_spurry : 20\n",
      "['img_01768.png', 'img_01767.png', 'img_01796.png']\n",
      "Number of plant images for plant red-root_amaranth : 3\n",
      "['img_01812.png', 'img_01809.png', 'img_01815.png', 'img_01810.png', 'img_01808.png', 'img_01813.png', 'img_01814.png', 'img_01811.png']\n",
      "Number of plant images for plant red_fingergrass : 8\n",
      "['img_00434.png', 'img_00203.png', 'img_00424.png', 'img_00717.png', 'img_00657.png', 'img_00430.png', 'img_00715.png', 'img_00420.png', 'img_00658.png', 'img_00209.png', 'img_00659.png', 'img_00419.png', 'img_00709.png', 'img_00713.png', 'img_00206.png', 'img_00429.png', 'img_00712.png', 'img_00421.png', 'img_00710.png', 'img_00204.png', 'img_00431.png', 'img_00435.png', 'img_00208.png', 'img_00714.png', 'img_00716.png']\n",
      "Number of plant images for plant common_wild_oat : 25\n",
      "['img_00618.png', 'img_00078.png', 'img_00612.png', 'img_01764.png', 'img_01195.png', 'img_01271.png', 'img_00447.png', 'img_01762.png', 'img_00856.png', 'img_00613.png', 'img_00223.png', 'img_01198.png', 'img_01758.png', 'img_00373.png', 'img_01189.png', 'img_00614.png', 'img_01264.png', 'img_01192.png', 'img_01266.png', 'img_01270.png', 'img_00804.png', 'img_00569.png', 'img_01753.png', 'img_00374.png', 'img_00959.png', 'img_00364.png', 'img_01751.png', 'img_00620.png', 'img_01048.png', 'img_00857.png', 'img_00936.png', 'img_01196.png', 'img_01191.png', 'img_01143.png', 'img_00810.png', 'img_01752.png', 'img_00359.png', 'img_01871.png', 'img_00558.png', 'img_01263.png', 'img_00376.png', 'img_00450.png', 'img_00122.png', 'img_00858.png', 'img_00362.png', 'img_01194.png', 'img_00952.png', 'img_00378.png', 'img_01262.png', 'img_01755.png', 'img_00076.png', 'img_00954.png', 'img_00617.png', 'img_00371.png', 'img_00609.png', 'img_00118.png', 'img_00950.png', 'img_01197.png', 'img_00228.png', 'img_01754.png', 'img_00957.png', 'img_00457.png', 'img_01042.png', 'img_00466.png', 'img_00821.png', 'img_00465.png', 'img_00956.png', 'img_00073.png', 'img_00219.png', 'img_00556.png', 'img_00372.png', 'img_00224.png', 'img_01193.png', 'img_00367.png', 'img_01767.png', 'img_00608.png', 'img_01147.png', 'img_00079.png', 'img_00081.png', 'img_00368.png', 'img_01044.png', 'img_01259.png', 'img_00365.png', 'img_00082.png', 'img_00069.png', 'img_00859.png', 'img_01260.png', 'img_01190.png', 'img_01268.png', 'img_00448.png', 'img_01045.png', 'img_00440.png', 'img_00363.png', 'img_00369.png', 'img_00726.png', 'img_00452.png', 'img_00955.png', 'img_01148.png', 'img_00555.png', 'img_00812.png', 'img_01040.png', 'img_00370.png', 'img_00953.png', 'img_00222.png', 'img_01146.png', 'img_00123.png', 'img_01763.png', 'img_00075.png', 'img_00068.png', 'img_00449.png', 'img_01765.png', 'img_01766.png', 'img_00451.png', 'img_00907.png', 'img_01768.png', 'img_00456.png', 'img_01142.png', 'img_00377.png', 'img_00619.png', 'img_00611.png', 'img_00077.png', 'img_01759.png', 'img_01761.png', 'img_00360.png', 'img_01041.png', 'img_00086.png', 'img_01750.png', 'img_00951.png', 'img_01141.png', 'img_00561.png', 'img_00375.png', 'img_00615.png', 'img_00855.png', 'img_01046.png', 'img_01043.png', 'img_01757.png', 'img_00121.png', 'img_01049.png', 'img_01873.png', 'img_00454.png', 'img_00958.png', 'img_01756.png', 'img_01265.png', 'img_01145.png', 'img_01140.png', 'img_01760.png', 'img_01047.png', 'img_01267.png', 'img_00361.png', 'img_01877.png', 'img_00366.png', 'img_00811.png', 'img_00080.png', 'img_01261.png', 'img_00729.png', 'img_00070.png', 'img_00116.png', 'img_00567.png', 'img_00610.png', 'img_00616.png', 'img_00225.png', 'img_01144.png']\n",
      "Number of plant images for plant cornflower : 162\n",
      "['img_01993.png', 'img_00753.png', 'img_01719.png', 'img_01714.png', 'img_01348.png', 'img_01724.png', 'img_01128.png', 'img_02000.png', 'img_02001.png', 'img_00622.png', 'img_00636.png', 'img_01129.png', 'img_01104.png', 'img_01123.png', 'img_01109.png', 'img_01593.png', 'img_00759.png', 'img_01636.png', 'img_02194.png', 'img_00621.png', 'img_01633.png', 'img_01126.png', 'img_01249.png', 'img_01718.png', 'img_01251.png', 'img_01709.png', 'img_01349.png', 'img_01599.png', 'img_02490.png', 'img_02008.png', 'img_01256.png', 'img_01998.png', 'img_01175.png', 'img_02009.png', 'img_02492.png', 'img_00634.png', 'img_01721.png', 'img_01990.png', 'img_01997.png', 'img_02198.png', 'img_02495.png', 'img_01648.png', 'img_02193.png', 'img_01629.png', 'img_00627.png', 'img_01601.png', 'img_01992.png', 'img_01170.png', 'img_02012.png', 'img_00628.png', 'img_01580.png', 'img_01598.png', 'img_01177.png', 'img_00755.png', 'img_02203.png', 'img_01634.png', 'img_01632.png', 'img_02192.png', 'img_01005.png', 'img_02010.png', 'img_00626.png', 'img_01644.png', 'img_02005.png', 'img_01725.png', 'img_00639.png', 'img_00861.png', 'img_02190.png', 'img_00494.png', 'img_00863.png', 'img_01642.png', 'img_01647.png', 'img_02204.png', 'img_02202.png', 'img_01101.png', 'img_01720.png', 'img_01995.png', 'img_01646.png', 'img_00501.png', 'img_00270.png', 'img_01001.png', 'img_02011.png', 'img_01176.png', 'img_01246.png', 'img_00862.png', 'img_01102.png', 'img_01105.png', 'img_02195.png', 'img_02494.png', 'img_01108.png', 'img_01171.png', 'img_01637.png', 'img_00630.png', 'img_01178.png', 'img_02002.png', 'img_00631.png', 'img_01173.png', 'img_00272.png', 'img_01172.png', 'img_00262.png', 'img_00632.png', 'img_00758.png', 'img_00768.png', 'img_01258.png', 'img_01641.png', 'img_00866.png', 'img_01354.png', 'img_00624.png', 'img_00635.png', 'img_01723.png', 'img_02493.png', 'img_01125.png', 'img_01645.png', 'img_01711.png', 'img_02191.png', 'img_01722.png', 'img_00770.png', 'img_00918.png', 'img_02003.png', 'img_00864.png', 'img_01994.png', 'img_01999.png', 'img_00867.png', 'img_01004.png', 'img_01107.png', 'img_01120.png', 'img_01252.png', 'img_01631.png', 'img_01006.png', 'img_01643.png', 'img_00629.png', 'img_00637.png', 'img_01638.png', 'img_01121.png', 'img_01710.png', 'img_02491.png', 'img_01124.png', 'img_01174.png', 'img_01639.png', 'img_01003.png', 'img_00503.png', 'img_01570.png', 'img_01715.png', 'img_00633.png', 'img_01253.png', 'img_00623.png', 'img_01356.png', 'img_01103.png', 'img_01000.png', 'img_00493.png', 'img_01002.png', 'img_02196.png', 'img_00756.png', 'img_01008.png', 'img_01712.png', 'img_01169.png', 'img_01243.png', 'img_01009.png', 'img_01122.png', 'img_02004.png', 'img_00261.png', 'img_00865.png', 'img_01713.png', 'img_01250.png', 'img_01592.png', 'img_02006.png', 'img_02201.png', 'img_01257.png', 'img_01127.png', 'img_02197.png', 'img_01989.png', 'img_01594.png', 'img_02489.png', 'img_01106.png', 'img_01254.png', 'img_01630.png', 'img_01596.png', 'img_00860.png', 'img_01640.png', 'img_01635.png', 'img_00638.png', 'img_00263.png', 'img_01717.png', 'img_00625.png', 'img_01255.png', 'img_00252.png', 'img_00253.png', 'img_01597.png', 'img_00750.png', 'img_01716.png', 'img_00492.png', 'img_01595.png', 'img_00752.png', 'img_01007.png', 'img_01100.png', 'img_01600.png', 'img_01996.png', 'img_02199.png', 'img_02007.png', 'img_02200.png', 'img_01991.png']\n",
      "Number of plant images for plant corn_cockle : 200\n",
      "['img_02477.png', 'img_02225.png', 'img_01702.png', 'img_01605.png', 'img_02214.png', 'img_02499.png', 'img_01619.png', 'img_01626.png', 'img_01858.png', 'img_01662.png', 'img_01682.png', 'img_02025.png', 'img_02213.png', 'img_01024.png', 'img_01745.png', 'img_01856.png', 'img_02470.png', 'img_01610.png', 'img_01021.png', 'img_02020.png', 'img_01733.png', 'img_01665.png', 'img_01660.png', 'img_02022.png', 'img_01863.png', 'img_02029.png', 'img_01670.png', 'img_01611.png', 'img_02224.png', 'img_01620.png', 'img_02015.png', 'img_02014.png', 'img_02027.png', 'img_01861.png', 'img_02021.png', 'img_01537.png', 'img_02496.png', 'img_01739.png', 'img_02497.png', 'img_02222.png', 'img_01669.png', 'img_02220.png', 'img_01731.png', 'img_02023.png', 'img_02500.png', 'img_01732.png', 'img_01025.png', 'img_01741.png', 'img_01740.png', 'img_01027.png', 'img_01699.png', 'img_01022.png', 'img_02215.png', 'img_02221.png', 'img_02476.png', 'img_01608.png', 'img_01707.png', 'img_02219.png', 'img_01744.png', 'img_01748.png', 'img_01625.png', 'img_02211.png', 'img_01737.png', 'img_02024.png', 'img_01543.png', 'img_01623.png', 'img_01627.png', 'img_01559.png', 'img_01747.png', 'img_01729.png', 'img_01602.png', 'img_01689.png', 'img_02216.png', 'img_02502.png', 'img_02488.png', 'img_01618.png', 'img_02207.png', 'img_02212.png', 'img_01651.png', 'img_02483.png', 'img_02223.png', 'img_02013.png', 'img_02454.png', 'img_01612.png', 'img_02228.png', 'img_01661.png', 'img_01742.png', 'img_02026.png', 'img_02018.png', 'img_01656.png', 'img_01730.png', 'img_02229.png', 'img_01604.png', 'img_01617.png', 'img_01726.png', 'img_02498.png', 'img_02218.png', 'img_01606.png', 'img_01653.png', 'img_01654.png', 'img_01734.png', 'img_02501.png', 'img_01650.png', 'img_01603.png', 'img_01613.png', 'img_01659.png', 'img_01749.png', 'img_01026.png', 'img_01607.png', 'img_01668.png', 'img_02030.png', 'img_01743.png', 'img_01609.png', 'img_01614.png', 'img_01663.png', 'img_01649.png', 'img_01622.png', 'img_02017.png', 'img_02208.png', 'img_02205.png', 'img_02217.png', 'img_01628.png', 'img_01738.png', 'img_01701.png', 'img_01736.png', 'img_01616.png', 'img_01652.png', 'img_02019.png', 'img_01615.png', 'img_02210.png', 'img_01664.png', 'img_01666.png', 'img_01023.png', 'img_02453.png', 'img_02028.png', 'img_01667.png', 'img_02226.png', 'img_01624.png', 'img_01028.png', 'img_02227.png', 'img_01735.png', 'img_02016.png', 'img_01621.png', 'img_01658.png', 'img_01728.png', 'img_01746.png', 'img_01020.png', 'img_01727.png', 'img_01655.png', 'img_01706.png', 'img_02209.png', 'img_01029.png', 'img_02206.png', 'img_01657.png']\n",
      "Number of plant images for plant milk_thistle : 154\n",
      "['img_01774.png', 'img_01777.png', 'img_01776.png', 'img_00937.png', 'img_01773.png', 'img_01278.png', 'img_01050.png', 'img_01271.png', 'img_01149.png', 'img_00964.png', 'img_01154.png', 'img_00963.png', 'img_00967.png', 'img_01202.png', 'img_01200.png', 'img_01272.png', 'img_01775.png', 'img_01056.png', 'img_01769.png', 'img_01201.png', 'img_01052.png', 'img_01053.png', 'img_01206.png', 'img_01057.png', 'img_00968.png', 'img_01208.png', 'img_01276.png', 'img_01771.png', 'img_01151.png', 'img_00960.png', 'img_01156.png', 'img_01270.png', 'img_00965.png', 'img_01772.png', 'img_01205.png', 'img_01203.png', 'img_01274.png', 'img_01269.png', 'img_01199.png', 'img_01157.png', 'img_01770.png', 'img_01153.png', 'img_01277.png', 'img_01055.png', 'img_01059.png', 'img_01273.png', 'img_01204.png', 'img_01275.png', 'img_01058.png', 'img_01152.png', 'img_01054.png', 'img_00966.png', 'img_01158.png', 'img_01207.png', 'img_00969.png', 'img_01155.png', 'img_00961.png', 'img_00962.png', 'img_01051.png', 'img_01150.png']\n",
      "Number of plant images for plant rye_brome : 60\n",
      "['img_01804.png', 'img_00652.png', 'img_00643.png', 'img_00649.png', 'img_00650.png', 'img_01787.png', 'img_01778.png', 'img_01785.png', 'img_01806.png', 'img_00651.png', 'img_01786.png', 'img_00645.png', 'img_00646.png', 'img_00644.png', 'img_01779.png', 'img_01781.png', 'img_00647.png', 'img_01782.png', 'img_01784.png', 'img_00648.png', 'img_01783.png', 'img_01780.png']\n",
      "Number of plant images for plant narrow-leaved_plantain : 22\n",
      "['img_00348.png', 'img_00546.png', 'img_00603.png', 'img_00342.png', 'img_00536.png', 'img_00606.png', 'img_00476.png', 'img_00528.png', 'img_00736.png', 'img_00469.png', 'img_00854.png', 'img_00482.png', 'img_00479.png', 'img_00148.png', 'img_00597.png', 'img_00542.png', 'img_00345.png', 'img_00146.png', 'img_00474.png', 'img_00796.png', 'img_00601.png', 'img_00797.png', 'img_00343.png', 'img_00529.png', 'img_00600.png', 'img_00357.png', 'img_00605.png', 'img_00147.png', 'img_00351.png', 'img_00341.png', 'img_00602.png', 'img_00908.png', 'img_00346.png', 'img_00532.png', 'img_00599.png', 'img_00486.png', 'img_00737.png', 'img_00349.png', 'img_00547.png', 'img_00742.png', 'img_00145.png', 'img_00344.png', 'img_00347.png', 'img_00350.png', 'img_00914.png', 'img_00852.png', 'img_00598.png', 'img_00149.png', 'img_00477.png', 'img_00096.png', 'img_00791.png', 'img_00468.png', 'img_00604.png', 'img_00607.png', 'img_00596.png', 'img_00595.png', 'img_00545.png', 'img_00478.png', 'img_00352.png', 'img_00353.png', 'img_00356.png', 'img_00745.png', 'img_00467.png', 'img_00358.png', 'img_00355.png', 'img_00853.png', 'img_00851.png', 'img_00354.png', 'img_00480.png', 'img_00850.png', 'img_00144.png', 'img_00150.png']\n",
      "Number of plant images for plant small-flower_geranium : 72\n",
      "Training subset number of images: 567\n",
      "Validation subset number of images: 282\n",
      "Test subset number of images: 287\n",
      "Number of classes: 13\n",
      "id2label: {0: 'void', 1: 'soil', 2: 'sugar_beet', 3: 'corn_spurry', 4: 'red-root_amaranth', 5: 'red_fingergrass', 6: 'common_wild_oat', 7: 'cornflower', 8: 'corn_cockle', 9: 'milk_thistle', 10: 'rye_brome', 11: 'narrow-leaved_plantain', 12: 'small-flower_geranium'}\n",
      "label2id: {'void': 0, 'soil': 1, 'sugar_beet': 2, 'corn_spurry': 3, 'red-root_amaranth': 4, 'red_fingergrass': 5, 'common_wild_oat': 6, 'cornflower': 7, 'corn_cockle': 8, 'milk_thistle': 9, 'rye_brome': 10, 'narrow-leaved_plantain': 11, 'small-flower_geranium': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.batch_norm.bias', 'decode_head.linear_c.2.proj.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_var', 'decode_head.classifier.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.classifier.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.batch_norm.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_fuse.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.batch_norm.running_mean', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.3.proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "To use hyperparameter search, you need to pass your model through a model_init function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/kate/dev/master_thesis/03_segformer.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# train_model_of_type_for_crop(\"multiclass\", \"broad_bean\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_model_of_type_for_crop(\u001b[39m\"\u001b[39;49m\u001b[39mmulticlass\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msugar_beet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/home/kate/dev/master_thesis/03_segformer.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mlabel2id:\u001b[39m\u001b[39m'\u001b[39m, label2id)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSemanticSegmentation\u001b[39m.\u001b[39mfrom_pretrained(checkpoint, id2label\u001b[39m=\u001b[39mid2label, label2id\u001b[39m=\u001b[39mlabel2id)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m trainer \u001b[39m=\u001b[39m initialize_trainer(model, \u001b[39mlen\u001b[39;49m(id2label), train_ds, val_ds)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Save the trained model, so that it can be used for inference later.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Save the log history, so that it can be used for plotting later.\u001b[39;00m\n",
      "\u001b[1;32m/home/kate/dev/master_thesis/03_segformer.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minitialize_trainer\u001b[39m(model, num_labels, train_ds, test_ds) :\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         callbacks\u001b[39m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     best_trial \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mhyperparameter_search(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         direction\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mminimize\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         backend\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msigopt\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         hp_space\u001b[39m=\u001b[39;49msigopt_hp_space,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         n_trials\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kate/dev/master_thesis/03_segformer.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m best_trial, trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/master/lib/python3.11/site-packages/transformers/trainer.py:2567\u001b[0m, in \u001b[0;36mTrainer.hyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m   2565\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhp_search_backend \u001b[39m=\u001b[39m backend\n\u001b[1;32m   2566\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_init \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2567\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2568\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo use hyperparameter search, you need to pass your model through a model_init function.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2569\u001b[0m     )\n\u001b[1;32m   2571\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhp_space \u001b[39m=\u001b[39m backend_obj\u001b[39m.\u001b[39mdefault_hp_space \u001b[39mif\u001b[39;00m hp_space \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m hp_space\n\u001b[1;32m   2572\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhp_name \u001b[39m=\u001b[39m hp_name\n",
      "\u001b[0;31mRuntimeError\u001b[0m: To use hyperparameter search, you need to pass your model through a model_init function."
     ]
    }
   ],
   "source": [
    "train_model_of_type_for_crop(\"multiclass\", \"broad_bean\")\n",
    "# train_model_of_type_for_crop(\"multiclass\", \"sugar_beet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# from typing import NoReturn\n",
    "\n",
    "# def shutdown_windows() -> NoReturn:\n",
    "#     subprocess.run([\"shutdown\", \"/s\", \"/t\", \"0\"])\n",
    "\n",
    "# shutdown_windows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
